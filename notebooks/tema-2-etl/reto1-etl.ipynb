{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Reto 1: Extract Transform Load\n",
                "Página web de la API Rest: [website](http://static.53.217.107.91.clients.your-server.de)\n",
                "\n",
                "En dicho enlace se ofrece la información de los diferentes endpoints de la API."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Instalación de paquetes necesarios\n",
                "Instalamos la librería de Python del curso, que contiene los módulos y funciones necesarios para el desarrollo del ejercicio"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-09-29T21:54:35.407430Z",
                    "iopub.status.busy": "2024-09-29T21:54:35.406544Z",
                    "iopub.status.idle": "2024-09-29T21:55:37.472380Z",
                    "shell.execute_reply": "2024-09-29T21:55:37.471075Z",
                    "shell.execute_reply.started": "2024-09-29T21:54:35.407379Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "!pip install git+https://github.com/donielix/esic-bigdata-iv-blackops.git > /dev/null"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Importación de paquetes necesarios\n",
                "Estas funciones auxiliares definidas dentro del paquete `blackops` nos ayudarán a realizar las peticiones web abstrayéndonos de la complejidad añadida de extraer y añadir los Bearer Tokens a las cabeceras de cada petición web. Para saber como funcionan (qué parámetros de entrada esperan y qué salida devuelven), pueden consultar su documentación"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "execution": {
                    "iopub.execute_input": "2024-09-29T21:55:37.475090Z",
                    "iopub.status.busy": "2024-09-29T21:55:37.474678Z",
                    "iopub.status.idle": "2024-09-29T21:55:37.657082Z",
                    "shell.execute_reply": "2024-09-29T21:55:37.656012Z",
                    "shell.execute_reply.started": "2024-09-29T21:55:37.475049Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from blackops.utils.catalog import start_spark_session\n",
                "from blackops.utils.io import save_json, get_token, get_api_data\n",
                "import pyspark.sql.functions as f"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Inicialización de la sesión de Spark\n",
                "Inicializamos la sesión de Spark haciendo uso de la función auxiliar `start_spark_session`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-09-29T21:55:37.659132Z",
                    "iopub.status.busy": "2024-09-29T21:55:37.658542Z",
                    "iopub.status.idle": "2024-09-29T21:55:45.546813Z",
                    "shell.execute_reply": "2024-09-29T21:55:45.545445Z",
                    "shell.execute_reply.started": "2024-09-29T21:55:37.659093Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "spark = start_spark_session()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Inicialización de variables globales\n",
                "Aquí se ofrece una variable global que contiene la url base de la API, para que puedas reutilizarla en las distintas funciones. Recuerda que esta es solo la URL base, y debes concatenarla con los diferentes endpoints para obtener los datos requeridos, haciendo uso o bien del operador `+` o de las f-strings (`f\"key -> {value}\"`), como se ha visto en clase."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "API_URL = \"http://static.53.217.107.91.clients.your-server.de\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Respuestas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Apartado 1 - Extracción y almacenamiento de los datos en crudo\n",
                "En este apartado, debes extraer la información de la API REST y guardar el resultado de cada endpoint en un fichero `.json` dentro de la carpeta `data/`. Es decir, al final de este apartado, en la ruta del disco duro deben encontrarse los siguientes ficheros (uno por cada endpoint de la API):\n",
                "\n",
                "```bash\n",
                ".\n",
                "├── data/\n",
                "│   ├── incidentes.json\n",
                "│   ├── usuarios.json\n",
                "│   ├── equipos_afectados.json\n",
                "```\n",
                "\n",
                "Para ello, puedes hacer uso de las funciones auxiliares `get_api_data`, `get_token` y `save_json`.\n",
                "\n",
                "- La función `get_api_data` devuelve la información de un determinado endpoint, en forma de diccionario. En su primer argumento, debes pasarle el endpoint exacto del que quieres obtener la información (asegurate de que su ruta es la adecuada). También acepta un segundo argumento para pasarle la información del token de autenticación, necesario para aquellos endpoints que requieran de autenticación.\n",
                "\n",
                "- La función `get_token` devuelve el token necesario para la autenticación. Como argumentos de entrada deben pasársele la URL correspondiente al endpoint de autenticación (login), con el usuario y contraseña adecuados (consultar en la web de la prueba, [website](http://static.53.217.107.91.clients.your-server.de)).\n",
                "\n",
                "- La función `save_json` acepta como entrada un diccionario de Python con la información recogida de la API y una ruta. Lo que hará será guardar la información en dicha ruta del disco. Esta función no devuelve nada, asi que no es necesario almacenar su output en ninguna variable\n",
                "\n",
                "**Nota**: Para mostrar la ayuda adicional (documentación) de una función en Python, puedes incorporar un signo de interrogación (?) al final del objeto; por ejemplo: `save_json?`.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# INSERTAR CÓDIGO\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Comprobemos que los ficheros requeridos están en la carpeta pedida con el siguiente comando (no hace falta editar esta celda)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!ls -alh data/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Apartado 2 - Lectura y transformación de los ficheros JSON\n",
                "Una vez has almacenado todos los JSON con la información de la API REST en la carpeta correspondiente, debes leer cada uno de los ficheros con `pyspark`, y emplear las transformaciones correspondientes para obtener unas tablas bien estructuradas con todos los campos relevantes. El comando para leer ficheros JSON con pyspark es `spark.read.json`. Puedes consultar el ejemplo tratado en clase, en [este enlace](https://github.com/donielix/esic-bigdata-iv-blackops/blob/main/notebooks/tema-2-etl/introduccion-spark.ipynb).\n",
                "\n",
                "Comienza simplemente leyendo los ficheros y almacenándolos cada uno en su variable correspondiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# INSERTAR CÓDIGO\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Apartado 3 - Union de todas las tablas\n",
                "Por último, une los campos relevantes de todas las tablas de este modelo de datos, y muestra una tabla el número de incidentes detectados por cada departamento y sistema operativo. Es decir, una tabla como:\n",
                "\n",
                "| departamento | sistema_operativo | n_incidentes |\n",
                "|--------------|-------------------|--------------|\n",
                "|              |                   |              |\n",
                "\n",
                "Finalmente, guarda esta tabla en el catálogo como una tabla de tipo Delta, haciendo uso de la instrucción:\n",
                "\n",
                "```tabla.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"incidentes_por_departamento\")```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# INSERTAR CÓDIGO\n"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "none",
            "dataSources": [],
            "isGpuEnabled": false,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
