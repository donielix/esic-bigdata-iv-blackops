{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introducción\n",
                "En este Notebook aprenderemos las operaciones básicas más utilizadas en PySpark, incluyendo un ejercicio práctico en el que realizaremos una pequeña ETL (Extract Transform Load) para extraer unos datos desde una API y los volcaremos en el catálogo de datos de Spark.\n",
                "\n",
                "No olvidemos que Apache Spark es una herramienta para el procesamiento distribuido de datos, es decir, está pensada para ser desplegada en un clúster (un conjunto de computadores) de modo que todas las operaciones de transformación de datos sean ejecutadas a lo largo de los diferentes nodos de este clúster de manera paralela. Sin embargo, nosotros no vamos a ejecutar este notebook sobre ningún clúster, ya que ello implicaría un cierto coste económico, lo que no es necesario para el pequeño volúmen de datos que manejaremos en este curso introductorio.\n",
                "\n",
                "Por ello, a lo largo de este Notebook, la arquitectura de Spark únicamente consistirá de un driver, que se corresponderá con proceso del Sistema Operativo encargado de ejecutar el propio Notebook. No habrá ningún otro worker.\n",
                "\n",
                "Cabe mencionar también que Apache Spark, aunque potencialmente puede correr bajo cualquier sistema operativo, se encuentra especialmente diseñado para entornos Linux, que es el sistema operativo más extendido entre servidores. Por ello se encomienda al alumno a ejecutar este Notebook en un sistema Linux (puede utilizarse WSL en el caso de disponer de Windows); tanto Google Colab como Kaggle utilizan Linux internamente, así que ambas plataformas son perfectamente válidas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Instalación de paquetes\n",
                "En el caso de estar ejecutando este Notebook a través de una plataforma Cloud como Google Colab o Kaggle, será necesario instalar el paquete de Python desarrollado en este repositorio. Como se trata de un repositorio público, el gestor de paquetes de Python, `pip`, puede instalarlo directamente utilizando la herramienta de control de versiones más popular, `git`. \n",
                "\n",
                "Para ello, descomenta el siguiente código y ejecútalo (únicamente si tu entorno de ejecución es Cloud):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install git+https://github.com/donielix/esic-bigdata-iv-blackops.git > /dev/null"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Importación de módulos requeridos\n",
                "En primer lugar necesitamos importar las funciones y objetos requeridos para el desarrollo del Notebook.\n",
                "\n",
                "- `SparkSession`: objeto necesario para la interacción con la herramienta de Spark a través de Python. Es el punto de entrada principal.\n",
                "- `pyspark.sql.functions`: funciones de SQL que ofrece pyspark, necesarias para las transformaciones de los datos en la ETL. Dado que esta colección de funciones SQL es utilizada recurrentemente, importamos el módulo completo con un alias que denotamos por `f`. Ello facilitará posteriormente el acceso a sus funciones utilizando el acceso a los atributos mediante un signo de puntuación, propio de Python.\n",
                "- `fetch_api, save_json`: estas funciones están definidas dentro de nuestra propia librería llamada `blackops`, dentro de este mismo repositorio. Contienen el código necesario para extraer y almacenar los datos de la API. Notar cómo la ruta de importación sigue el arbol de carpetas del repositorio.\n",
                "- `date, timedelta`: funciones para crear objetos de tipo fecha y timestamp dentro de Python.\n",
                "- `random`: módulo utilizado para la generación de datos aleatorios. Así podremos crear una colección de datos de manera aleatoria, sin tener que introducir cada registro a mano.\n",
                "- `DeltaTable`: objeto para interaccionar con tablas de tipo Delta. Se trata de un formato ampliamente utilizado en Spark, que ofrece muchas funcionalidades añadidas a nuestro catálogo de datos, como por ejemplo la posibilidad de revertir cambios."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "import pyspark.sql.functions as f\n",
                "from blackops.crawlers.wallapop.functions import fetch_api\n",
                "from blackops.utils.io import save_json\n",
                "from blackops.utils.catalog import get_detailed_tables_info\n",
                "from datetime import date, timedelta\n",
                "import random\n",
                "from delta import DeltaTable"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Establecemos una semilla para la generación de números aleatorios. De esta manera, los resultados serán reproducibles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "random.seed(45)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inicialización de la sesión de Spark\n",
                "\n",
                "Establecemos ahora la comunicación con el motor de Spark desde Python, a través del objeto `SparkSession` de la librería `pyspark`.\n",
                "\n",
                "Como ya hemos comentado, en este caso no estamos utilizando un clúster, sino que haremos uso de una arquitectura local. El propio Jupyter Notebook ejercerá como Driver, como Master y como Ejecutor de las tareas, y ello se explicita en el método `.master(\"local[*]\")`.\n",
                "\n",
                "Adicionalmente, estamos instalando dependencias externas como la librería Delta, que incorpora utilidades muy importantes para el manejo de las tablas en nuestro catálogo de datos (histórico de versiones de tablas, omisión de ficheros innecesarios en la lectura, etc.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/08 17:22:32 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.1.38 instead (on interface enp3s0)\n",
                        "24/10/08 17:22:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ":: loading settings :: url = jar:file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/.venv/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ivy Default Cache set to: /home/dadiego/.ivy2/cache\n",
                        "The jars for the packages stored in: /home/dadiego/.ivy2/jars\n",
                        "io.delta#delta-spark_2.12 added as a dependency\n",
                        ":: resolving dependencies :: org.apache.spark#spark-submit-parent-eb659fa6-3503-482a-a023-1476a6b511a8;1.0\n",
                        "\tconfs: [default]\n",
                        "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
                        "\tfound io.delta#delta-storage;3.2.0 in central\n",
                        "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
                        ":: resolution report :: resolve 124ms :: artifacts dl 7ms\n",
                        "\t:: modules in use:\n",
                        "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
                        "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
                        "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
                        "\t---------------------------------------------------------------------\n",
                        "\t|                  |            modules            ||   artifacts   |\n",
                        "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
                        "\t---------------------------------------------------------------------\n",
                        "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
                        "\t---------------------------------------------------------------------\n",
                        ":: retrieving :: org.apache.spark#spark-submit-parent-eb659fa6-3503-482a-a023-1476a6b511a8\n",
                        "\tconfs: [default]\n",
                        "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
                        "24/10/08 17:22:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
                    ]
                }
            ],
            "source": [
                "spark = (\n",
                "    SparkSession.Builder()\n",
                "    .master(\"local[*]\")\n",
                "    .config(\n",
                "        map={\n",
                "            \"spark.driver.memory\": \"8g\",\n",
                "            \"spark.jars.packages\": \"io.delta:delta-spark_2.12:3.2.0\",\n",
                "            \"spark.sql.extensions\": \"io.delta.sql.DeltaSparkSessionExtension\",\n",
                "            \"spark.sql.catalog.spark_catalog\": \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
                "            \"spark.databricks.delta.retentionDurationCheck.enabled\": \"false\",\n",
                "            \"spark.sql.catalogImplementation\": \"hive\",\n",
                "            \"spark.sql.repl.eagerEval.enabled\": \"true\",\n",
                "            \"spark.sql.repl.eagerEval.truncate\": \"100\",\n",
                "        }\n",
                "    )\n",
                "    .getOrCreate()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez se ha inicializado la sesión, podemos acceder a la web `localhost:4040` para consultar la interfaz de administración que ofrece Spark. Allí, se podrá monitorizar las tareas que se mandan desde el Driver.\n",
                "\n",
                "**Nota**: Si al inicializar la sesión de Spark obtenemos algún error en el que se nos indica que la variable `JAVA_HOME` no existe, lo más probable es que no tengamos instalado Java en nuestro sistema, y necesitamos instalarlo ya que Spark depende de Java para su funcionamiento. Para ello, en Linux podemos utilizar el gestor de paquetes: `sudo apt update && sudo apt install openjdk-17-jdk -y`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Creación de un DataFrame de Spark\n",
                "\n",
                "En Spark podemos crear directamente un Dataframe a partir de una lista de datos, o bien de un Dataframe de pandas. Para ello se puede utilizar el método `spark.createDataFrame`.\n",
                "Debemos especificar tanto los datos como el esquema que tiene el Dataframe (sus columnas y sus tipos).\n",
                "\n",
                "En este caso hacemos uso del paquete `random` para generar datos aleatorios (pero reproducibles, al haber establecido una semilla)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Podemos especificar el esquema del DataFrame usando una cadena de texto\n",
                "schema = \"id INT, nombre STRING, edad INT, salario FLOAT, es_empleado BOOLEAN, fecha_contratacion DATE, departamento STRING\"\n",
                "\n",
                "# Crear una lista de datos ficticios\n",
                "nombres = [\n",
                "    \"Juan\",\n",
                "    \"María\",\n",
                "    \"Pedro\",\n",
                "    \"Ana\",\n",
                "    \"Luis\",\n",
                "    \"Carla\",\n",
                "    \"Miguel\",\n",
                "    \"Sara\",\n",
                "    \"David\",\n",
                "    \"Laura\",\n",
                "]\n",
                "departamentos = [\"Ventas\", \"Marketing\", \"Finanzas\", \"IT\", \"RRHH\"]\n",
                "\n",
                "data = [\n",
                "    (\n",
                "        i,  # id\n",
                "        random.choice(nombres),  # nombre\n",
                "        random.randint(22, 60),  # edad\n",
                "        round(random.uniform(20000, 80000), 2),  # salario\n",
                "        random.choice([True, False]),  # es_empleado\n",
                "        date(2024, 10, 1)\n",
                "        - timedelta(days=random.randint(0, 3650)),  # fecha_contratacion\n",
                "        random.choice(departamentos),  # departamento\n",
                "    )\n",
                "    for i in range(1, 31)  # Genera 30 registros aleatorios\n",
                "]\n",
                "\n",
                "# Crear el DataFrame usando el esquema en string\n",
                "df = spark.createDataFrame(data, schema)\n",
                "\n",
                "# Creamos una vista temporal del DataFrame en el catálogo, para poder hacer consultas en SQL.\n",
                "df.createOrReplaceTempView(\"empleados\")\n",
                "\n",
                "# Mostramos el DataFrame resultante por pantalla\n",
                "display(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Recordemos que Spark procesa los datos de manera distribuida, en lo que se conoce como particiones. Por eso, aunque nosotros visualicemos la tabla anterior en su conjunto, cuando la ejecución sucede en un clúster, sucederá que unos registros de este DataFrame estarán almacenados en un computador y otros residirán en otro distinto. Podemos comprobar cuántas particiones existen en nuestra tabla con el siguiente comando"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "16"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.rdd.getNumPartitions()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Incluso podemos ver a qué partición corresponde cada registro"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th><th>id_particion</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td><td>0</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td><td>1</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td><td>1</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td><td>2</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td><td>2</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td><td>3</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td><td>3</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td><td>4</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td><td>4</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td><td>5</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td><td>5</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td><td>6</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td><td>6</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td><td>7</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td><td>7</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td><td>8</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td><td>9</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td><td>9</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td><td>10</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td><td>10</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|id_particion|\n",
                            "+---+------+----+--------+-----------+------------------+------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|           0|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|           1|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|           1|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|           2|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|           2|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|           3|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|           3|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|           4|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|           4|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|           5|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|           5|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|           6|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|           6|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|           7|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|           7|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|           8|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|           9|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|           9|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|          10|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|          10|\n",
                            "+---+------+----+--------+-----------+------------------+------------+------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.withColumn(\"id_particion\", f.spark_partition_id())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Operaciones de transformación\n",
                "\n",
                "La sintaxis de Spark es muy similar a la del lenguaje SQL, de hecho, admite la introducción de comandos SQL para realizar las transformaciones de los datos. Vamos a ver algunas de las operaciones más habituales.\n",
                "\n",
                "### Select\n",
                "\n",
                "La operación más sencilla consiste en seleccionar simplemente un subconjunto de los datos, sin ninguna otra operación de transformación o filtro añadido. Por ejemplo, seleccionemos únicamente los campos `id` y `nombre`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>8</td><td>David</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td></tr>\n",
                            "<tr><td>12</td><td>David</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+\n",
                            "| id|nombre|\n",
                            "+---+------+\n",
                            "|  1|  Luis|\n",
                            "|  2|  Juan|\n",
                            "|  3|  Luis|\n",
                            "|  4| Pedro|\n",
                            "|  5|Miguel|\n",
                            "|  6|  Luis|\n",
                            "|  7| María|\n",
                            "|  8| David|\n",
                            "|  9|  Sara|\n",
                            "| 10|   Ana|\n",
                            "| 11|Miguel|\n",
                            "| 12| David|\n",
                            "| 13| Laura|\n",
                            "| 14| Pedro|\n",
                            "| 15| María|\n",
                            "| 16|  Sara|\n",
                            "| 17|   Ana|\n",
                            "| 18|  Sara|\n",
                            "| 19| María|\n",
                            "| 20| Pedro|\n",
                            "+---+------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.select(\"id\", \"nombre\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Al igual que en SQL estándar, podemos no solo seleccionar unas columnas sino aplicarles alguna función de transformación dentro del propio comando SELECT, y renombrarlas utilizando un alias.\n",
                "\n",
                "Las funciones SQL en Spark están contenidas en el módulo `pyspark.sql.functions`, que hemos importado al principio y lo hemos almacenado en un objeto con alias `f` (por sencillez de uso).\n",
                "\n",
                "Vamos a seleccionar en este caso los mismos campos que en el ejemplo anterior, sin embargo, al campo `nombre` le vamos a aplicar una transformación para visualizar el nombre en mayúsculas, y al resultado lo renombraremos `nombre_en_mayusculas`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre_en_mayusculas</th></tr>\n",
                            "<tr><td>1</td><td>LUIS</td></tr>\n",
                            "<tr><td>2</td><td>JUAN</td></tr>\n",
                            "<tr><td>3</td><td>LUIS</td></tr>\n",
                            "<tr><td>4</td><td>PEDRO</td></tr>\n",
                            "<tr><td>5</td><td>MIGUEL</td></tr>\n",
                            "<tr><td>6</td><td>LUIS</td></tr>\n",
                            "<tr><td>7</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>8</td><td>DAVID</td></tr>\n",
                            "<tr><td>9</td><td>SARA</td></tr>\n",
                            "<tr><td>10</td><td>ANA</td></tr>\n",
                            "<tr><td>11</td><td>MIGUEL</td></tr>\n",
                            "<tr><td>12</td><td>DAVID</td></tr>\n",
                            "<tr><td>13</td><td>LAURA</td></tr>\n",
                            "<tr><td>14</td><td>PEDRO</td></tr>\n",
                            "<tr><td>15</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>16</td><td>SARA</td></tr>\n",
                            "<tr><td>17</td><td>ANA</td></tr>\n",
                            "<tr><td>18</td><td>SARA</td></tr>\n",
                            "<tr><td>19</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>20</td><td>PEDRO</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+--------------------+\n",
                            "| id|nombre_en_mayusculas|\n",
                            "+---+--------------------+\n",
                            "|  1|                LUIS|\n",
                            "|  2|                JUAN|\n",
                            "|  3|                LUIS|\n",
                            "|  4|               PEDRO|\n",
                            "|  5|              MIGUEL|\n",
                            "|  6|                LUIS|\n",
                            "|  7|               MARÍA|\n",
                            "|  8|               DAVID|\n",
                            "|  9|                SARA|\n",
                            "| 10|                 ANA|\n",
                            "| 11|              MIGUEL|\n",
                            "| 12|               DAVID|\n",
                            "| 13|               LAURA|\n",
                            "| 14|               PEDRO|\n",
                            "| 15|               MARÍA|\n",
                            "| 16|                SARA|\n",
                            "| 17|                 ANA|\n",
                            "| 18|                SARA|\n",
                            "| 19|               MARÍA|\n",
                            "| 20|               PEDRO|\n",
                            "+---+--------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.select(\"id\", f.upper(\"nombre\").alias(\"nombre_en_mayusculas\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### WithColumn\n",
                "Podemos añadir campos nuevos derivados a partir de otros campos utilizando el método `withColumn`. Este comando conservará todas las columnas de la tabla, y añadirá una adicional, con las transformaciones que le indiquemos.\n",
                "\n",
                "Por ejemplo, en nuestra tabla disponemos del campo `edad`, pero supongamos que nos interesa, para nuestra analítica, disponer de un campo con el año de nacimiento. En tal caso, podríamos concatenar dos funciones SQL: con la primera, `current_date`, extraemos la fecha actual, y sobre dicha fecha aplicamos la función `year` para extraer el año. Finalmente, a este año actual le restamos la edad que tiene el usuario para así calcular su año de nacimiento. Cada usuario dispondrá así de un año de nacimiento (transformación fila a fila)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th><th>a&ntilde;o_nacimiento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td><td>1976</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td><td>1998</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td><td>2000</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td><td>1989</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td><td>1993</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td><td>1980</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td><td>2001</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td><td>1968</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td><td>1979</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td><td>1971</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td><td>1978</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td><td>1997</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td><td>2001</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td><td>1991</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td><td>2002</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td><td>1974</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td><td>1971</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td><td>1996</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td><td>1998</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td><td>1997</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|año_nacimiento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|          1976|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|          1998|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|          2000|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|          1989|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|          1993|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|          1980|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|          2001|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|          1968|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|          1979|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|          1971|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|          1978|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|          1997|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|          2001|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|          1991|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|          2002|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|          1974|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|          1971|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|          1996|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|          1998|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|          1997|\n",
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.withColumn(\"año_nacimiento\", f.year(f.current_date()) - f.col(\"edad\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Filter\n",
                "\n",
                "Podemos filtrar los datos de acuerdo a alguna condición especificada. Esta sentencia se corresponde con el comando `WHERE` en SQL. Por ejemplo, queremos obtener únicamente los datos de los empleados. \n",
                "\n",
                "Recordemos que en Python el operador de igualdad es `==`.\n",
                "\n",
                "Para poder realizar operaciones con columnas, necesitamos especificar que se trata de una columna del DataFrame haciendo uso de la función `col`, puesto que si no lo que estaríamos es comparando un string con un booleano (`\"es_empleado\" == True`), que será siempre igual a `False`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td></tr>\n",
                            "<tr><td>23</td><td>Carla</td><td>50</td><td>73172.89</td><td>true</td><td>2015-08-21</td><td>IT</td></tr>\n",
                            "<tr><td>25</td><td>Sara</td><td>59</td><td>59973.55</td><td>true</td><td>2018-04-23</td><td>Marketing</td></tr>\n",
                            "<tr><td>29</td><td>Miguel</td><td>37</td><td>69922.06</td><td>true</td><td>2023-10-26</td><td>Finanzas</td></tr>\n",
                            "<tr><td>30</td><td>Luis</td><td>27</td><td>70247.43</td><td>true</td><td>2020-05-23</td><td>Finanzas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|\n",
                            "| 23| Carla|  50|73172.89|       true|        2015-08-21|          IT|\n",
                            "| 25|  Sara|  59|59973.55|       true|        2018-04-23|   Marketing|\n",
                            "| 29|Miguel|  37|69922.06|       true|        2023-10-26|    Finanzas|\n",
                            "| 30|  Luis|  27|70247.43|       true|        2020-05-23|    Finanzas|\n",
                            "+---+------+----+--------+-----------+------------------+------------+"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(f.col(\"es_empleado\") == True)\n",
                "\n",
                "# Si hacemos df.filter(\"es_empleado\" == True) obtendremos un error porque los tipos no son los esperados."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Agrupaciones\n",
                "\n",
                "Utilizando el comando group by, podemos agrupar nuestro dataset según los valores de una o varias columnas y posteriormente realizar una operación de agregación sobre cada conjunto, para así obtener estadísticas descriptivas de nuestros datos.\n",
                "\n",
                "Por ejemplo, podemos obtener el número de empleados en marketing, con lo cual debemos agrupar por departamento y realizar una operación de agregación de suma. Estas operaciones se denominan \"de agregación\" o \"de reducción\" porque actúan sobre un conjunto de filas (todas aquellas que comparten el mismo valor del grupo) y devuelven un único valor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>salario_total</th></tr>\n",
                            "<tr><td>Finanzas</td><td>524206.53515625</td></tr>\n",
                            "<tr><td>Ventas</td><td>421618.7890625</td></tr>\n",
                            "<tr><td>RRHH</td><td>292734.91015625</td></tr>\n",
                            "<tr><td>IT</td><td>355377.107421875</td></tr>\n",
                            "<tr><td>Marketing</td><td>122665.44140625</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+----------------+\n",
                            "|departamento|   salario_total|\n",
                            "+------------+----------------+\n",
                            "|    Finanzas| 524206.53515625|\n",
                            "|      Ventas|  421618.7890625|\n",
                            "|        RRHH| 292734.91015625|\n",
                            "|          IT|355377.107421875|\n",
                            "|   Marketing| 122665.44140625|\n",
                            "+------------+----------------+"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.groupBy(\"departamento\").agg(f.sum(\"salario\").alias(\"salario_total\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Combinaciones\n",
                "Naturalmente, la riqueza de PySpark es que podemos combinar filtros con agrupaciones, adición de columnas, cambios de tipos, etc para que nuestro dato final quede pulido.\n",
                "\n",
                "Al contrario que en Pandas, todas las operaciones de transformación en Spark son *lazy*, es decir, no se evalúan hasta que se pide una acción (resultado). Esto permite que el catalizador de Spark optimice toda la cadena de consultas de la manera más apropiada antes de ser ejecutadas.\n",
                "\n",
                "Veamos un ejemplo de consulta algo más avanzada: supongamos que queremos conocer cuál es el departamento del que más gente se ha ido a partir de 2017 para unos ciertos intervalos de meses: enero a mayo, junio a septiembre y octubre a diciembre. En este caso podemos comenzar aplicando unos filtros para quedarnos únicamente con registros de los que actualmente ya no son empleados y su fecha de contratación es igual o posterior a 2017. Después de aplicar dicho filtro, podemos añadir dos columnas transitorias para extraer el mes de la fecha de contratación y establecer los intervalos pedidos, utilizando la función `when`, que es esquivalente al `CASE` de SQL. Finalmente, agrupamos por estas categorías de mes y agregamos cogiendo la moda (el valor más repetido de un conjunto de datos)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>categoria_mes</th><th>departamento_mas_repetido</th></tr>\n",
                            "<tr><td>octubre-diciembre</td><td>RRHH</td></tr>\n",
                            "<tr><td>junio-septiembre</td><td>Marketing</td></tr>\n",
                            "<tr><td>enero-mayo</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-----------------+-------------------------+\n",
                            "|    categoria_mes|departamento_mas_repetido|\n",
                            "+-----------------+-------------------------+\n",
                            "|octubre-diciembre|                     RRHH|\n",
                            "| junio-septiembre|                Marketing|\n",
                            "|       enero-mayo|                   Ventas|\n",
                            "+-----------------+-------------------------+"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(\n",
                "    (f.col(\"es_empleado\") == False) & (f.year(\"fecha_contratacion\") >= 2017)\n",
                ").withColumn(\"mes_contratacion\", f.month(\"fecha_contratacion\")).withColumn(\n",
                "    \"categoria_mes\",\n",
                "    f.when(f.col(\"mes_contratacion\").between(1, 5), f.lit(\"enero-mayo\"))\n",
                "    .when(f.col(\"mes_contratacion\").between(6, 9), f.lit(\"junio-septiembre\"))\n",
                "    .otherwise(f.lit(\"octubre-diciembre\")),\n",
                ").groupBy(\n",
                "    \"categoria_mes\"\n",
                ").agg(\n",
                "    f.mode(\"departamento\").alias(\"departamento_mas_repetido\")\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "La consulta equivalente en Spark SQL en este caso sería la siguiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>categoria_mes</th><th>departamento_mas_repetido</th></tr>\n",
                            "<tr><td>octubre-diciembre</td><td>RRHH</td></tr>\n",
                            "<tr><td>junio-septiembre</td><td>Marketing</td></tr>\n",
                            "<tr><td>enero-mayo</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-----------------+-------------------------+\n",
                            "|    categoria_mes|departamento_mas_repetido|\n",
                            "+-----------------+-------------------------+\n",
                            "|octubre-diciembre|                     RRHH|\n",
                            "| junio-septiembre|                Marketing|\n",
                            "|       enero-mayo|                   Ventas|\n",
                            "+-----------------+-------------------------+"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "spark.sql(\n",
                "    \"\"\"\n",
                "    SELECT\n",
                "        CASE\n",
                "            WHEN MONTH(fecha_contratacion) BETWEEN 1 AND 5 THEN 'enero-mayo'\n",
                "            WHEN MONTH(fecha_contratacion) BETWEEN 6 AND 9 THEN 'junio-septiembre'\n",
                "            ELSE 'octubre-diciembre'\n",
                "        END AS categoria_mes,\n",
                "        MODE(departamento) AS departamento_mas_repetido\n",
                "\n",
                "    FROM empleados\n",
                "    WHERE\n",
                "        es_empleado = false AND\n",
                "        YEAR(fecha_contratacion) >= 2017\n",
                "    GROUP BY categoria_mes\n",
                "    \"\"\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como se puede comprobar, se obtienen exactamente los mismos resultados.\n",
                "\n",
                "Disgreguemos la consulta compleja de pyspark en componentes, para ver los resultados de aplicar cada una de las transformaciones. Empezamos con el filtro para quedarnos con registros de personas que ya no son empleadas y que fueron contratadas a partir del año 2017"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td></tr>\n",
                            "<tr><td>21</td><td>Luis</td><td>46</td><td>65993.36</td><td>false</td><td>2022-12-04</td><td>RRHH</td></tr>\n",
                            "<tr><td>22</td><td>Juan</td><td>26</td><td>39267.68</td><td>false</td><td>2022-02-16</td><td>Finanzas</td></tr>\n",
                            "<tr><td>24</td><td>David</td><td>56</td><td>62486.47</td><td>false</td><td>2018-02-17</td><td>Ventas</td></tr>\n",
                            "<tr><td>26</td><td>Ana</td><td>25</td><td>22953.8</td><td>false</td><td>2018-05-11</td><td>Finanzas</td></tr>\n",
                            "<tr><td>27</td><td>Carla</td><td>50</td><td>68186.09</td><td>false</td><td>2018-02-04</td><td>Ventas</td></tr>\n",
                            "<tr><td>28</td><td>Miguel</td><td>51</td><td>64634.71</td><td>false</td><td>2018-05-29</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|\n",
                            "| 21|  Luis|  46|65993.36|      false|        2022-12-04|        RRHH|\n",
                            "| 22|  Juan|  26|39267.68|      false|        2022-02-16|    Finanzas|\n",
                            "| 24| David|  56|62486.47|      false|        2018-02-17|      Ventas|\n",
                            "| 26|   Ana|  25| 22953.8|      false|        2018-05-11|    Finanzas|\n",
                            "| 27| Carla|  50|68186.09|      false|        2018-02-04|      Ventas|\n",
                            "| 28|Miguel|  51|64634.71|      false|        2018-05-29|      Ventas|\n",
                            "+---+------+----+--------+-----------+------------------+------------+"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(\n",
                "    (f.col(\"es_empleado\") == False) & (f.year(\"fecha_contratacion\") >= 2017)\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Posteriormente, con el comando `withColumn`, estamos añadiendo un nuevo campo que extrae el mes a partir de la fecha de contratación"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th><th>mes_contratacion</th></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td><td>11</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td><td>9</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td><td>2</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td><td>1</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td><td>6</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td><td>3</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td><td>3</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td><td>10</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td><td>1</td></tr>\n",
                            "<tr><td>21</td><td>Luis</td><td>46</td><td>65993.36</td><td>false</td><td>2022-12-04</td><td>RRHH</td><td>12</td></tr>\n",
                            "<tr><td>22</td><td>Juan</td><td>26</td><td>39267.68</td><td>false</td><td>2022-02-16</td><td>Finanzas</td><td>2</td></tr>\n",
                            "<tr><td>24</td><td>David</td><td>56</td><td>62486.47</td><td>false</td><td>2018-02-17</td><td>Ventas</td><td>2</td></tr>\n",
                            "<tr><td>26</td><td>Ana</td><td>25</td><td>22953.8</td><td>false</td><td>2018-05-11</td><td>Finanzas</td><td>5</td></tr>\n",
                            "<tr><td>27</td><td>Carla</td><td>50</td><td>68186.09</td><td>false</td><td>2018-02-04</td><td>Ventas</td><td>2</td></tr>\n",
                            "<tr><td>28</td><td>Miguel</td><td>51</td><td>64634.71</td><td>false</td><td>2018-05-29</td><td>Ventas</td><td>5</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+----------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|mes_contratacion|\n",
                            "+---+------+----+--------+-----------+------------------+------------+----------------+\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|              11|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|               9|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|               2|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|               1|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|               6|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|               3|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|               3|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|              10|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|               1|\n",
                            "| 21|  Luis|  46|65993.36|      false|        2022-12-04|        RRHH|              12|\n",
                            "| 22|  Juan|  26|39267.68|      false|        2022-02-16|    Finanzas|               2|\n",
                            "| 24| David|  56|62486.47|      false|        2018-02-17|      Ventas|               2|\n",
                            "| 26|   Ana|  25| 22953.8|      false|        2018-05-11|    Finanzas|               5|\n",
                            "| 27| Carla|  50|68186.09|      false|        2018-02-04|      Ventas|               2|\n",
                            "| 28|Miguel|  51|64634.71|      false|        2018-05-29|      Ventas|               5|\n",
                            "+---+------+----+--------+-----------+------------------+------------+----------------+"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(\n",
                "    (f.col(\"es_empleado\") == False) & (f.year(\"fecha_contratacion\") >= 2017)\n",
                ").withColumn(\"mes_contratacion\", f.month(\"fecha_contratacion\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tras esto, de nuevo con el método `withColumn`, añadimos otra columna que establecerá la categoría del mes, en función del campo `mes_contratacion` anteriormente calculado, y el resultado será el siguiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th><th>mes_contratacion</th><th>categoria_mes</th></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td><td>11</td><td>octubre-diciembre</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td><td>9</td><td>junio-septiembre</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td><td>2</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td><td>1</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td><td>6</td><td>junio-septiembre</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td><td>3</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td><td>3</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td><td>10</td><td>octubre-diciembre</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td><td>1</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>21</td><td>Luis</td><td>46</td><td>65993.36</td><td>false</td><td>2022-12-04</td><td>RRHH</td><td>12</td><td>octubre-diciembre</td></tr>\n",
                            "<tr><td>22</td><td>Juan</td><td>26</td><td>39267.68</td><td>false</td><td>2022-02-16</td><td>Finanzas</td><td>2</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>24</td><td>David</td><td>56</td><td>62486.47</td><td>false</td><td>2018-02-17</td><td>Ventas</td><td>2</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>26</td><td>Ana</td><td>25</td><td>22953.8</td><td>false</td><td>2018-05-11</td><td>Finanzas</td><td>5</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>27</td><td>Carla</td><td>50</td><td>68186.09</td><td>false</td><td>2018-02-04</td><td>Ventas</td><td>2</td><td>enero-mayo</td></tr>\n",
                            "<tr><td>28</td><td>Miguel</td><td>51</td><td>64634.71</td><td>false</td><td>2018-05-29</td><td>Ventas</td><td>5</td><td>enero-mayo</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+----------------+-----------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|mes_contratacion|    categoria_mes|\n",
                            "+---+------+----+--------+-----------+------------------+------------+----------------+-----------------+\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|              11|octubre-diciembre|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|               9| junio-septiembre|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|               2|       enero-mayo|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|               1|       enero-mayo|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|               6| junio-septiembre|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|               3|       enero-mayo|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|               3|       enero-mayo|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|              10|octubre-diciembre|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|               1|       enero-mayo|\n",
                            "| 21|  Luis|  46|65993.36|      false|        2022-12-04|        RRHH|              12|octubre-diciembre|\n",
                            "| 22|  Juan|  26|39267.68|      false|        2022-02-16|    Finanzas|               2|       enero-mayo|\n",
                            "| 24| David|  56|62486.47|      false|        2018-02-17|      Ventas|               2|       enero-mayo|\n",
                            "| 26|   Ana|  25| 22953.8|      false|        2018-05-11|    Finanzas|               5|       enero-mayo|\n",
                            "| 27| Carla|  50|68186.09|      false|        2018-02-04|      Ventas|               2|       enero-mayo|\n",
                            "| 28|Miguel|  51|64634.71|      false|        2018-05-29|      Ventas|               5|       enero-mayo|\n",
                            "+---+------+----+--------+-----------+------------------+------------+----------------+-----------------+"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(\n",
                "    (f.col(\"es_empleado\") == False) & (f.year(\"fecha_contratacion\") >= 2017)\n",
                ").withColumn(\"mes_contratacion\", f.month(\"fecha_contratacion\")).withColumn(\n",
                "    \"categoria_mes\",\n",
                "    f.when(f.col(\"mes_contratacion\").between(1, 5), f.lit(\"enero-mayo\"))\n",
                "    .when(f.col(\"mes_contratacion\").between(6, 9), f.lit(\"junio-septiembre\"))\n",
                "    .otherwise(f.lit(\"octubre-diciembre\")),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Por último, sobre este último DataFrame, se hace una agrupación según la categoría del mes recientemente calculada, y se computa la moda del campo `departamento` para cada agrupación, obteniendo así la tabla final que hemos visto arriba"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Joins\n",
                "Al igual que las operaciones de transformación, otro comando importante es el de JOIN, que nos permite establecer links entre campos de diferentes columnas, lo cual resulta fundamental para el análisis desde diferentes fuentes de datos.\n",
                "\n",
                "Un análisis detallado y extenso de los diferentes tipos de Joins en Pyspark puede verse [aquí](https://sparkbyexamples.com/pyspark/pyspark-join-explained-with-examples/).\n",
                "\n",
                "Esquemáticamente tenemos los siguientes tipos de JOINs:\n",
                "\n",
                "![tipos de joins](joins.png \"Tipos de Joins\")\n",
                "\n",
                "Por poner un ejemplo, creemos un segundo dataframe con información añadida de los departamentos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>departamento</th><th>descripcion</th></tr>\n",
                            "<tr><td>1</td><td>Finanzas</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>2</td><td>Ventas</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------------+------------------------------------------------------------------------+\n",
                            "| id|departamento|                                                             descripcion|\n",
                            "+---+------------+------------------------------------------------------------------------+\n",
                            "|  1|    Finanzas|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|  2|      Ventas|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "+---+------------+------------------------------------------------------------------------+"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "departamentos = spark.createDataFrame(\n",
                "    [\n",
                "        (\n",
                "            1,\n",
                "            \"Finanzas\",\n",
                "            \"Departamento encargado de elaborar informes financieros trimestrales\",\n",
                "        ),\n",
                "        (\n",
                "            2,\n",
                "            \"Ventas\",\n",
                "            \"Departamento encargado de contactar con proveedores y registrar el stock\",\n",
                "        ),\n",
                "    ], schema=\"id int, departamento string, descripcion string\"\n",
                ")\n",
                "display(departamentos)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Y ahora vamos a unir nuestra tabla de origen con esta tabla de información extendida por departamento. El campo de unión lógicamente será la columna `\"departamento\"`.\n",
                "\n",
                "Empecemos con un INNER JOIN. En este caso, únicamente se mostrarán los departamentos de Finanzas y Ventas, ya que son los únicos registros comunes a ambas tablas (el resto de departamentos no está presente en la tabla `departamentos`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>id</th><th>descripcion</th></tr>\n",
                            "<tr><td>Finanzas</td><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>22</td><td>Juan</td><td>26</td><td>39267.68</td><td>false</td><td>2022-02-16</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>26</td><td>Ana</td><td>25</td><td>22953.8</td><td>false</td><td>2018-05-11</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>29</td><td>Miguel</td><td>37</td><td>69922.06</td><td>true</td><td>2023-10-26</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>30</td><td>Luis</td><td>27</td><td>70247.43</td><td>true</td><td>2020-05-23</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>24</td><td>David</td><td>56</td><td>62486.47</td><td>false</td><td>2018-02-17</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>27</td><td>Carla</td><td>50</td><td>68186.09</td><td>false</td><td>2018-02-04</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>28</td><td>Miguel</td><td>51</td><td>64634.71</td><td>false</td><td>2018-05-29</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion| id|                                                             descripcion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+\n",
                            "|    Finanzas|  1|  Luis|  48|49281.69|       true|        2021-05-09|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  3|  Luis|  24|73947.68|       true|        2023-03-28|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  5|Miguel|  31|62027.07|       true|        2022-10-27|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 13| Laura|  23|57455.18|      false|        2021-03-08|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 15| María|  22|57444.64|      false|        2017-10-22|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 17|   Ana|  53| 21659.3|       true|        2018-01-19|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 22|  Juan|  26|39267.68|      false|        2022-02-16|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 26|   Ana|  25| 22953.8|      false|        2018-05-11|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 29|Miguel|  37|69922.06|       true|        2023-10-26|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 30|  Luis|  27|70247.43|       true|        2020-05-23|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas|  2|  Juan|  26|49055.36|       true|        2021-07-27|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  8| David|  56|72059.12|      false|        2018-02-06|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  9|  Sara|  45|74705.86|      false|        2023-01-02|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 18|  Sara|  28|30491.18|       true|        2015-12-13|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 24| David|  56|62486.47|      false|        2018-02-17|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 27| Carla|  50|68186.09|      false|        2018-02-04|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 28|Miguel|  51|64634.71|      false|        2018-05-29|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"inner\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora haremos un LEFT JOIN. En este caso se mostrarán todos los registros de la tabla de origen, con todos los departamentos por tanto. Y si existe un departamento equivalente en la tabla derecha, se mostrará también su información adicional. En caso de no existir un match (cuando el departamento no sea el de ventas o finanzas), dicha información adicional será nula"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>id</th><th>descripcion</th></tr>\n",
                            "<tr><td>Finanzas</td><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Finanzas</td><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>RRHH</td><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Ventas</td><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Marketing</td><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>RRHH</td><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>IT</td><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>RRHH</td><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>IT</td><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>RRHH</td><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>NULL</td><td>NULL</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion|  id|                                                             descripcion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "|    Finanzas|  1|  Luis|  48|49281.69|       true|        2021-05-09|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  3|  Luis|  24|73947.68|       true|        2023-03-28|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas|  2|  Juan|  26|49055.36|       true|        2021-07-27|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|    Finanzas|  5|Miguel|  31|62027.07|       true|        2022-10-27|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|        RRHH|  4| Pedro|  35|79554.92|      false|        2023-11-29|NULL|                                                                    NULL|\n",
                            "|          IT|  6|  Luis|  44|66505.58|      false|        2023-09-13|NULL|                                                                    NULL|\n",
                            "|          IT|  7| María|  23|65070.76|      false|        2015-12-18|NULL|                                                                    NULL|\n",
                            "|      Ventas|  8| David|  56|72059.12|      false|        2018-02-06|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  9|  Sara|  45|74705.86|      false|        2023-01-02|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|   Marketing| 10|   Ana|  53|62691.89|      false|        2021-06-16|NULL|                                                                    NULL|\n",
                            "|          IT| 11|Miguel|  46|70126.54|       true|        2018-03-14|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 13| Laura|  23|57455.18|      false|        2021-03-08|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|        RRHH| 12| David|  27|53608.56|       true|        2014-11-09|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 15| María|  22|57444.64|      false|        2017-10-22|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|          IT| 14| Pedro|  33|20602.28|      false|        2024-03-12|NULL|                                                                    NULL|\n",
                            "|        RRHH| 16|  Sara|  50|32029.18|      false|        2022-01-13|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 17|   Ana|  53| 21659.3|       true|        2018-01-19|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas| 18|  Sara|  28|30491.18|       true|        2015-12-13|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|          IT| 20| Pedro|  27|59899.06|      false|        2015-02-25|NULL|                                                                    NULL|\n",
                            "|        RRHH| 19| María|  26|61548.89|      false|        2015-11-03|NULL|                                                                    NULL|\n",
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"left\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Por último, veamos el caso del LEFT ANTI JOIN. En este caso, se mostrarán únicamente los registros de la tabla origen que no tienen un match con los de la tabla de departamentos; es decir, aquellos registros del dataframe cuyo departamento no es ventas ni finanzas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th></tr>\n",
                            "<tr><td>RRHH</td><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td></tr>\n",
                            "<tr><td>IT</td><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td></tr>\n",
                            "<tr><td>IT</td><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td></tr>\n",
                            "<tr><td>Marketing</td><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td></tr>\n",
                            "<tr><td>IT</td><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td></tr>\n",
                            "<tr><td>RRHH</td><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td></tr>\n",
                            "<tr><td>IT</td><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td></tr>\n",
                            "<tr><td>RRHH</td><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td></tr>\n",
                            "<tr><td>IT</td><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td></tr>\n",
                            "<tr><td>RRHH</td><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td></tr>\n",
                            "<tr><td>RRHH</td><td>21</td><td>Luis</td><td>46</td><td>65993.36</td><td>false</td><td>2022-12-04</td></tr>\n",
                            "<tr><td>IT</td><td>23</td><td>Carla</td><td>50</td><td>73172.89</td><td>true</td><td>2015-08-21</td></tr>\n",
                            "<tr><td>Marketing</td><td>25</td><td>Sara</td><td>59</td><td>59973.55</td><td>true</td><td>2018-04-23</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+\n",
                            "|        RRHH|  4| Pedro|  35|79554.92|      false|        2023-11-29|\n",
                            "|          IT|  6|  Luis|  44|66505.58|      false|        2023-09-13|\n",
                            "|          IT|  7| María|  23|65070.76|      false|        2015-12-18|\n",
                            "|   Marketing| 10|   Ana|  53|62691.89|      false|        2021-06-16|\n",
                            "|          IT| 11|Miguel|  46|70126.54|       true|        2018-03-14|\n",
                            "|        RRHH| 12| David|  27|53608.56|       true|        2014-11-09|\n",
                            "|          IT| 14| Pedro|  33|20602.28|      false|        2024-03-12|\n",
                            "|        RRHH| 16|  Sara|  50|32029.18|      false|        2022-01-13|\n",
                            "|          IT| 20| Pedro|  27|59899.06|      false|        2015-02-25|\n",
                            "|        RRHH| 19| María|  26|61548.89|      false|        2015-11-03|\n",
                            "|        RRHH| 21|  Luis|  46|65993.36|      false|        2022-12-04|\n",
                            "|          IT| 23| Carla|  50|73172.89|       true|        2015-08-21|\n",
                            "|   Marketing| 25|  Sara|  59|59973.55|       true|        2018-04-23|\n",
                            "+------------+---+------+----+--------+-----------+------------------+"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"leftanti\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Caso práctico: Extracción de datos de Wallapop\n",
                "Vamos a construir un pequeño ejemplo de una ETL (Extraction Transform Load). Extraeremos datos en crudo desde la API REST de Wallapop, los guardamos en una carpeta de almacenamiento, los leemos con spark, realizamos algunas transformaciones y almacenamos la tabla resultante en nuestro catálogo de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    json_data = fetch_api(product=\"portátil\")\n",
                "    save_json(obj=json_data, path=\"data/wallapop.json\", indent=4)\n",
                "except Exception as e:\n",
                "    print(f\"Warning: No ha sido posible descargar los datos de la API: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos previsualizar cuál es la estructura de nuestro fichero JSON utilizando el comando externo `cat` de nuestra terminal (válido únicamente en sistemas Unix, con `jq` instalado).\n",
                "\n",
                "Si no está instalado `jq`, puede instalarse mediante `sudo apt update && sudo apt install jq -y`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1;39m{\n",
                        "  \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "    \u001b[0m\u001b[34;1m\"section\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "      \u001b[0m\u001b[34;1m\"payload\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "        \u001b[0m\u001b[34;1m\"order\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"most_relevance\"\u001b[0m\u001b[1;39m,\n",
                        "        \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Find what you want\"\u001b[0m\u001b[1;39m,\n",
                        "        \u001b[0m\u001b[34;1m\"items\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
                        "          \u001b[1;39m{\n",
                        "            \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"8j34odd1ey69\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"user_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"kp61on7oqxj5\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"IVEOPPE teclado portatil\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"IVEOPPE teclado portatil samsung galaxy TAB a9 + carcasa\\na estrenar\\nprecio en amazon: 30,99€\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"category_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m24200\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"price\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "              \u001b[0m\u001b[34;1m\"amount\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m15\u001b[0m\u001b[1;39m,\n",
                        "              \u001b[0m\u001b[34;1m\"currency\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"EUR\"\u001b[0m\u001b[1;39m\n",
                        "            \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"images\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
                        "              \u001b[1;39m{\n",
                        "                \u001b[0m\u001b[34;1m\"average_color\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"13C1AC\"\u001b[0m\u001b[1;39m,\n"
                    ]
                }
            ],
            "source": [
                "%%sh\n",
                "cat data/wallapop.json | jq -C | head -20"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez determinada la estructura que tiene nuestro fichero JSON de información, notamos que los datos que queremos obtener se encuentran dentro de la ruta `data -> section -> payload -> items`. Dicha ruta se corresponde con un array (lista) de items, que son los productos de Wallapop; cada uno de ellos tiene unos campos, algunos simples como `id`, `user_id`, y otros compuestos como `price -> amount` o `price -> currency`.\n",
                "\n",
                "En primer lugar, observemos que si leemos el fichero JSON directamente no obtenemos una estructura muy amigable\n",
                "\n",
                "*Nota*: el argumento `multiLine=True` se introduce para especificar que el fichero JSON de entrada que estamos tratando de leer abarca múltiples líneas, y no una sola. De esta manera nos evitaremos errores de lectura."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "|                                              data|                                              meta|\n",
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "|{{{[{{none}, 24200, 1728317203080, IVEOPPE tecl...|{eyJhbGciOiJIUzI1NiJ9.eyJwYXJhbXMiOnsic2VhcmNoU...|\n",
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop = spark.read.json(\"data/wallapop.json\", multiLine=True)\n",
                "wallapop.show(truncate=50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esto es porque nos ha cogido las dos primeras claves más externas de nuestro fichero JSON, que son los campos `\"data\"` y `\"meta\"`.\n",
                "\n",
                "Observemos qué estructura hemos cargado haciendo un `printSchema` de nuestro DataFrame. De esta manera obtendremos información de los campos y sus tipos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- data: struct (nullable = true)\n",
                        " |    |-- section: struct (nullable = true)\n",
                        " |    |    |-- payload: struct (nullable = true)\n",
                        " |    |    |    |-- items: array (nullable = true)\n",
                        " |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |-- bump: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- type: string (nullable = true)\n",
                        " |    |    |    |    |    |-- category_id: long (nullable = true)\n",
                        " |    |    |    |    |    |-- created_at: long (nullable = true)\n",
                        " |    |    |    |    |    |-- description: string (nullable = true)\n",
                        " |    |    |    |    |    |-- discount: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- percentage: long (nullable = true)\n",
                        " |    |    |    |    |    |    |-- previous_price: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- amount: double (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- currency: string (nullable = true)\n",
                        " |    |    |    |    |    |-- favorited: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- id: string (nullable = true)\n",
                        " |    |    |    |    |    |-- images: array (nullable = true)\n",
                        " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |    |    |-- average_color: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- urls: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- big: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- medium: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- small: string (nullable = true)\n",
                        " |    |    |    |    |    |-- is_favoriteable: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- is_refurbished: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- location: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- city: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- country_code: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- latitude: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- longitude: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- postal_code: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- region: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- region2: string (nullable = true)\n",
                        " |    |    |    |    |    |-- modified_at: long (nullable = true)\n",
                        " |    |    |    |    |    |-- price: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- amount: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- currency: string (nullable = true)\n",
                        " |    |    |    |    |    |-- reserved: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- shipping: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- cost_configuration_id: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- item_is_shippable: boolean (nullable = true)\n",
                        " |    |    |    |    |    |    |-- user_allows_shipping: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- taxonomy: array (nullable = true)\n",
                        " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |    |    |-- icon: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- id: long (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- name: string (nullable = true)\n",
                        " |    |    |    |    |    |-- title: string (nullable = true)\n",
                        " |    |    |    |    |    |-- user_id: string (nullable = true)\n",
                        " |    |    |    |    |    |-- web_slug: string (nullable = true)\n",
                        " |    |    |    |-- order: string (nullable = true)\n",
                        " |    |    |    |-- title: string (nullable = true)\n",
                        " |    |    |-- type: string (nullable = true)\n",
                        " |    |-- tracking: struct (nullable = true)\n",
                        " |    |    |-- location: struct (nullable = true)\n",
                        " |    |    |    |-- country_code: string (nullable = true)\n",
                        " |    |    |    |-- latitude: double (nullable = true)\n",
                        " |    |    |    |-- longitude: double (nullable = true)\n",
                        " |    |    |-- variant: string (nullable = true)\n",
                        " |-- meta: struct (nullable = true)\n",
                        " |    |-- next_page: string (nullable = true)\n",
                        " |    |-- next_section_type: string (nullable = true)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.printSchema()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora, para navegar a través de nuestro fichero JSON, podemos utilizar la sintáxis por puntos; es decir, para obtener el campo deseado `\"items\"`, que contiene la información de todos los productos, debemos acceder mediante `data.section.payload.items`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|                                                                                               items|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|[{{none}, 24200, 1728317203080, IVEOPPE teclado portatil samsung galaxy TAB a9 + carcasa\\na estre...|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.select(\"data.section.payload.items\").show(truncate=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sin embargo, seguimos sin apreciar una estructura legible. Esto es porque se nos está mostrando un único registro (fila) que contiene toda la información de los productos. Lo que nos interesa es que cada elemento de esta lista se muestre en un registro a parte. Para ello se utiliza la función SQL `explode`, que coge un array de elementos y devuelve un registro por cada uno de esos elementos. Veámoslo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|                                                                                                 col|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|{{none}, 24200, 1728317203080, IVEOPPE teclado portatil samsung galaxy TAB a9 + carcasa\\na estren...|\n",
                        "|{{none}, 24200, 1728316393445, Mcbazel \\nTeclado portatil plegable recargable con dispositivo tac...|\n",
                        "|{{none}, 24200, 1728327614065, Se vende porque se le da uso está en perfectas condiciones poco us...|\n",
                        "|{{none}, 24200, 1728325351863, Se vende porque no se le da uso está en perfectas condiciones poco...|\n",
                        "|{{none}, 24200, 1728304636450, Monitor nuevo. Contiene, pantalla, respaldo de pantalla, cable tip...|\n",
                        "|{{none}, 24200, 1728327810358, Funciona, aunque va muy lento. los botones del tactil van mal. Se ...|\n",
                        "|{{none}, 24200, 1728325826012, Portatil Acer funciona con su cargador original\\nescucho ofertas ,...|\n",
                        "|{{city}, 24200, 1728149565059, Se vende portátil MSI GF75 Thin 10SDR, Intel Core i7, 1TB, NVIDIA ...|\n",
                        "|{{none}, 24200, 1728298268913, precintado\\nsolo envio\\n\\nCUIUIC Monitor portátil de 15,6 Pulgadas...|\n",
                        "|{{none}, 24200, 1728321679391, ORDENADOR PORTÁTIL CHUWI GEMIBOOK XPRO. DESCRIPCIÓN EN FOTOS. NUEV...|\n",
                        "|{{none}, 24200, 1728322196288, Se vende portatil acer antiguo sin cable de corriente, vale para d...|\n",
                        "|{{none}, 24200, 1728322519013, Base para alzar portátil o pantalla. Desmontable., NULL, {false}, ...|\n",
                        "|{{none}, 24200, 1728320872537, ORDENADOR PORTÁTIL BMAX X15 PLUS. DESCRIPCIÓN EN FOTOS. NUEVO. \\nS...|\n",
                        "|{{none}, 24200, 1728318963323, dos cargadores portatiles completamente nuevos con sus respectivos...|\n",
                        "|{{none}, 24200, 1728326775194, Plataforma de refrigeración de tres motores, con USB adicional y c...|\n",
                        "|{{none}, 24200, 1728325281001, Cargador portátil original Sony en perfecto funcionamiento., NULL,...|\n",
                        "|{{none}, 24200, 1728318860092, Ordenador Portatil marca LENOVO, procesador i7, 16 Gb de Ram, 500 ...|\n",
                        "|{{none}, 24200, 1728316560127, portatil para piezas o reparar enciende pero se calienta y se apag...|\n",
                        "|{{country}, 24200, 1706634689502, Vendo portátil Lenovo IdeaPad 3 en muy buen estado. El portátil...|\n",
                        "|{{none}, 24200, 1728312737318, Vendo portatil HP recien formateado y con el windows 10 pro\\nVa un...|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "only showing top 20 rows\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.select(f.explode(\"data.section.payload.items\")).show(truncate=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Bien, ya hemos avanzado, disponemos ahora de un registro por cada producto de la lista `items`, como queríamos. Sin embargo, se sigue mostrando toda la información en una misma columna. Eso lo solucionamos seleccionando los campos anidados deseados. Por ejemplo, supongamos que queremos coger el `id` del producto, el `user_id` del usuario y la fecha de creación del anuncio `created_at`. Una buena manera de operar sería crear una nueva columna llamada, por ejemplo, `\"data\"`, que contenga los registros explotados del campo de `\"items\"`, y luego utilizar este nuevo campo para obtener la info de los otros campos descendientes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>user_id</th><th>created_at</th></tr>\n",
                            "<tr><td>8j34odd1ey69</td><td>kp61on7oqxj5</td><td>1728317203080</td></tr>\n",
                            "<tr><td>e6582kk9ok6o</td><td>kp61on7oqxj5</td><td>1728316393445</td></tr>\n",
                            "<tr><td>3zl8xwq1np6x</td><td>xzo8x8v9gl69</td><td>1728327614065</td></tr>\n",
                            "<tr><td>xzo2omn38w69</td><td>nz0m0n7l93jo</td><td>1728325351863</td></tr>\n",
                            "<tr><td>nzx4vn9247j2</td><td>8z812r1reo63</td><td>1728304636450</td></tr>\n",
                            "<tr><td>8z8k9nm8v1z3</td><td>qzm4m7kvwgzv</td><td>1728327810358</td></tr>\n",
                            "<tr><td>xzo2omnoo469</td><td>3zlgnx7x3njx</td><td>1728325826012</td></tr>\n",
                            "<tr><td>w6749l0nyy6x</td><td>8ejkpqn079zx</td><td>1728149565059</td></tr>\n",
                            "<tr><td>nzx4vnqe55j2</td><td>8z812r2my163</td><td>1728298268913</td></tr>\n",
                            "<tr><td>3zl8xw3y1p6x</td><td>e65y9rpllgjo</td><td>1728321679391</td></tr>\n",
                            "<tr><td>0j24k2v9knzy</td><td>npj9gx531v6e</td><td>1728322196288</td></tr>\n",
                            "<tr><td>e6582kn3106o</td><td>kmzn2g5vgzn3</td><td>1728322519013</td></tr>\n",
                            "<tr><td>x6qm23ennyjy</td><td>e65y9rpllgjo</td><td>1728320872537</td></tr>\n",
                            "<tr><td>wzv4ve7dndzl</td><td>8z815qrvkl63</td><td>1728318963323</td></tr>\n",
                            "<tr><td>vjrqv270k4zk</td><td>wzvr102km16l</td><td>1728326775194</td></tr>\n",
                            "<tr><td>3zl8xwl0dn6x</td><td>7v6g4o07276e</td><td>1728325281001</td></tr>\n",
                            "<tr><td>e6582k12m06o</td><td>kp61pydexx65</td><td>1728318860092</td></tr>\n",
                            "<tr><td>xzo2omm0o469</td><td>ke657840xmjo</td><td>1728316560127</td></tr>\n",
                            "<tr><td>wzy4n2xov5z5</td><td>vjrkk2lv04zk</td><td>1706634689502</td></tr>\n",
                            "<tr><td>v6ggn5ryyl6e</td><td>7v6g4p08r26e</td><td>1728312737318</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+------------+-------------+\n",
                            "|          id|     user_id|   created_at|\n",
                            "+------------+------------+-------------+\n",
                            "|8j34odd1ey69|kp61on7oqxj5|1728317203080|\n",
                            "|e6582kk9ok6o|kp61on7oqxj5|1728316393445|\n",
                            "|3zl8xwq1np6x|xzo8x8v9gl69|1728327614065|\n",
                            "|xzo2omn38w69|nz0m0n7l93jo|1728325351863|\n",
                            "|nzx4vn9247j2|8z812r1reo63|1728304636450|\n",
                            "|8z8k9nm8v1z3|qzm4m7kvwgzv|1728327810358|\n",
                            "|xzo2omnoo469|3zlgnx7x3njx|1728325826012|\n",
                            "|w6749l0nyy6x|8ejkpqn079zx|1728149565059|\n",
                            "|nzx4vnqe55j2|8z812r2my163|1728298268913|\n",
                            "|3zl8xw3y1p6x|e65y9rpllgjo|1728321679391|\n",
                            "|0j24k2v9knzy|npj9gx531v6e|1728322196288|\n",
                            "|e6582kn3106o|kmzn2g5vgzn3|1728322519013|\n",
                            "|x6qm23ennyjy|e65y9rpllgjo|1728320872537|\n",
                            "|wzv4ve7dndzl|8z815qrvkl63|1728318963323|\n",
                            "|vjrqv270k4zk|wzvr102km16l|1728326775194|\n",
                            "|3zl8xwl0dn6x|7v6g4o07276e|1728325281001|\n",
                            "|e6582k12m06o|kp61pydexx65|1728318860092|\n",
                            "|xzo2omm0o469|ke657840xmjo|1728316560127|\n",
                            "|wzy4n2xov5z5|vjrkk2lv04zk|1706634689502|\n",
                            "|v6ggn5ryyl6e|7v6g4p08r26e|1728312737318|\n",
                            "+------------+------------+-------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "wallapop.withColumn(\"data\", f.explode(\"data.section.payload.items\")).select(\n",
                "    \"data.id\", \"data.user_id\", \"data.created_at\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fenomenal. Ahora, siguiendo esta misma operación, obtendremos un dataset completo tabular de los campos del JSON más relevantes. Observemos que para todos los campos seleccionados, se hace una conversión de tipos (método `cast`) y se asigna un alias (método `alias`). Esto es para que la tabla resultante sea consistente, y tenga siempre el mismo esquema de salida.\n",
                "\n",
                "Notemos también que a campos que representan fechas pero se muestran como números enteros (milisegundos desde 1970, esto se conoce como UNIX time), como `created_at` o `modified_at`, les aplicamos una conversión mediante la función `from_unixtime` para representarlos como una fecha legible"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- id: string (nullable = true)\n",
                        " |-- title: string (nullable = true)\n",
                        " |-- user_id: string (nullable = true)\n",
                        " |-- category_id: integer (nullable = true)\n",
                        " |-- created_at: timestamp (nullable = true)\n",
                        " |-- modified_at: timestamp (nullable = true)\n",
                        " |-- description: string (nullable = true)\n",
                        " |-- favorited: boolean (nullable = true)\n",
                        " |-- is_favoriteable: boolean (nullable = true)\n",
                        " |-- is_refurbished: boolean (nullable = true)\n",
                        " |-- latitude: double (nullable = true)\n",
                        " |-- longitude: double (nullable = true)\n",
                        " |-- postal_code: string (nullable = true)\n",
                        " |-- city: string (nullable = true)\n",
                        " |-- region: string (nullable = true)\n",
                        " |-- region2: string (nullable = true)\n",
                        " |-- country_code: string (nullable = true)\n",
                        " |-- amount: double (nullable = true)\n",
                        " |-- currency: string (nullable = true)\n",
                        " |-- reserved: string (nullable = true)\n",
                        " |-- item_is_shippable: boolean (nullable = true)\n",
                        " |-- user_allows_shipping: boolean (nullable = true)\n",
                        " |-- __timestamp: timestamp (nullable = false)\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>title</th><th>user_id</th><th>category_id</th><th>created_at</th><th>modified_at</th><th>description</th><th>favorited</th><th>is_favoriteable</th><th>is_refurbished</th><th>latitude</th><th>longitude</th><th>postal_code</th><th>city</th><th>region</th><th>region2</th><th>country_code</th><th>amount</th><th>currency</th><th>reserved</th><th>item_is_shippable</th><th>user_allows_shipping</th><th>__timestamp</th></tr>\n",
                            "<tr><td>8j34odd1ey69</td><td>IVEOPPE teclado portatil</td><td>kp61on7oqxj5</td><td>24200</td><td>2024-10-07 18:06:43</td><td>2024-10-07 18:06:53</td><td>IVEOPPE teclado portatil samsung galaxy TAB a9 + carcasa\\na estrenar\\nprecio en amazon: 30,99&euro;</td><td>false</td><td>true</td><td>false</td><td>40.41883190365425</td><td>-3.57184367222341</td><td>28821</td><td>Coslada</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>15.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>e6582kk9ok6o</td><td>Teclado portatil plegable recargable</td><td>kp61on7oqxj5</td><td>24200</td><td>2024-10-07 17:53:13</td><td>2024-10-07 17:53:19</td><td>Mcbazel \\nTeclado portatil plegable recargable con dispositivo tactil para dispositivo movil/tabl...</td><td>false</td><td>true</td><td>false</td><td>40.41883190365425</td><td>-3.57184367222341</td><td>28821</td><td>Coslada</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>15.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>3zl8xwq1np6x</td><td>Portatil</td><td>xzo8x8v9gl69</td><td>24200</td><td>2024-10-07 21:00:14</td><td>2024-10-07 21:00:24</td><td>Se vende porque se le da uso est&aacute; en perfectas condiciones poco uso y cualquier cosa por chat pre...</td><td>false</td><td>true</td><td>false</td><td>40.4013020602374</td><td>-3.61266807783252</td><td>28032</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>110.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>xzo2omn38w69</td><td>Port&aacute;til </td><td>nz0m0n7l93jo</td><td>24200</td><td>2024-10-07 20:22:31</td><td>2024-10-07 20:27:58</td><td>Se vende porque no se le da uso est&aacute; en perfectas condiciones poco uso y cualquier cosa por chat ...</td><td>false</td><td>true</td><td>false</td><td>40.40293549760407</td><td>-3.6036383752125976</td><td>28032</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>110.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>nzx4vn9247j2</td><td>Monitor port&aacute;til 11'6 pulgadas</td><td>8z812r1reo63</td><td>24200</td><td>2024-10-07 14:37:16</td><td>2024-10-07 14:39:53</td><td>Monitor nuevo. Contiene, pantalla, respaldo de pantalla, cable tipo c, cable tipo c a usb, cable ...</td><td>false</td><td>true</td><td>false</td><td>40.34549239334717</td><td>-3.8199855046355746</td><td>28922</td><td>Alcorc&oacute;n</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>65.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>8z8k9nm8v1z3</td><td>Ordenador portatil</td><td>qzm4m7kvwgzv</td><td>24200</td><td>2024-10-07 21:03:30</td><td>2024-10-07 21:04:38</td><td>Funciona, aunque va muy lento. los botones del tactil van mal. Se escuchan ofertas. Tengo el carg...</td><td>false</td><td>true</td><td>false</td><td>40.343563207976395</td><td>-3.709246913711613</td><td>28021</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>120.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>xzo2omnoo469</td><td>Portatil Acer</td><td>3zlgnx7x3njx</td><td>24200</td><td>2024-10-07 20:30:26</td><td>2024-10-07 20:55:10</td><td>Portatil Acer funciona con su cargador original\\nescucho ofertas </td><td>false</td><td>true</td><td>false</td><td>40.326254</td><td>-3.768059</td><td>28911</td><td>Legan&eacute;s</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>30.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>w6749l0nyy6x</td><td>Portatil gaming</td><td>8ejkpqn079zx</td><td>24200</td><td>2024-10-05 19:32:45</td><td>2024-10-05 21:37:29</td><td>Se vende port&aacute;til MSI GF75 Thin 10SDR, Intel Core i7, 1TB, NVIDIA GeForce GTX1660Ti/6GB, Windows ...</td><td>false</td><td>true</td><td>false</td><td>40.322746246594974</td><td>-3.854662525858509</td><td>28937</td><td>M&oacute;stoles</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>825.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>nzx4vnqe55j2</td><td>CUIUIC Monitor port&aacute;til de 15,6 Pulgadas</td><td>8z812r2my163</td><td>24200</td><td>2024-10-07 12:51:08</td><td>2024-10-07 12:51:19</td><td>precintado\\nsolo envio\\n\\nCUIUIC Monitor port&aacute;til de 15,6 Pulgadas con Pantalla Full HD USB-C, 19...</td><td>false</td><td>true</td><td>false</td><td>40.416156498413585</td><td>-3.7101967123015727</td><td>28070</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>55.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>3zl8xw3y1p6x</td><td>ORDENADOR PORT&Aacute;TIL </td><td>e65y9rpllgjo</td><td>24200</td><td>2024-10-07 19:21:19</td><td>2024-10-07 19:21:29</td><td>ORDENADOR PORT&Aacute;TIL CHUWI GEMIBOOK XPRO. DESCRIPCI&Oacute;N EN FOTOS. NUEVO.\\nSOLO ENVIO.</td><td>false</td><td>true</td><td>false</td><td>40.457704764564234</td><td>-3.754137266350963</td><td>28040</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>190.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>0j24k2v9knzy</td><td>Portatil acer</td><td>npj9gx531v6e</td><td>24200</td><td>2024-10-07 19:29:56</td><td>2024-10-07 19:30:06</td><td>Se vende portatil acer antiguo sin cable de corriente, vale para despiece tambien</td><td>false</td><td>true</td><td>false</td><td>40.254054239071955</td><td>-3.8166673934653597</td><td>28970</td><td>Humanes de Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>20.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>e6582kn3106o</td><td>Alzador port&aacute;til </td><td>kmzn2g5vgzn3</td><td>24200</td><td>2024-10-07 19:35:19</td><td>2024-10-07 19:35:29</td><td>Base para alzar port&aacute;til o pantalla. Desmontable.</td><td>false</td><td>true</td><td>false</td><td>40.51585470621938</td><td>-3.3609342780673095</td><td>28807</td><td>Alcal&aacute; de Henares</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>5.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>x6qm23ennyjy</td><td>ORDENADOR PORT&Aacute;TIL </td><td>e65y9rpllgjo</td><td>24200</td><td>2024-10-07 19:07:52</td><td>2024-10-07 19:22:12</td><td>ORDENADOR PORT&Aacute;TIL BMAX X15 PLUS. DESCRIPCI&Oacute;N EN FOTOS. NUEVO. \\nSOLO ENVIO.</td><td>false</td><td>true</td><td>false</td><td>40.457704764564234</td><td>-3.754137266350963</td><td>28040</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>220.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>wzv4ve7dndzl</td><td>Cargador portatil </td><td>8z815qrvkl63</td><td>24200</td><td>2024-10-07 18:36:03</td><td>2024-10-07 18:36:13</td><td>dos cargadores portatiles completamente nuevos con sus respectivos cables . uno de color negro y ...</td><td>false</td><td>true</td><td>false</td><td>40.382206491272186</td><td>-3.669754084096236</td><td>28053</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>120.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>vjrqv270k4zk</td><td>Plataforma refrigeraci&oacute;n para port&aacute;til </td><td>wzvr102km16l</td><td>24200</td><td>2024-10-07 20:46:15</td><td>2024-10-07 20:46:25</td><td>Plataforma de refrigeraci&oacute;n de tres motores, con USB adicional y cable incluido.</td><td>false</td><td>true</td><td>false</td><td>40.459700632071076</td><td>-3.7740925124798546</td><td>28023</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>15.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>3zl8xwl0dn6x</td><td>Cargador port&aacute;til Sony </td><td>7v6g4o07276e</td><td>24200</td><td>2024-10-07 20:21:21</td><td>2024-10-07 20:21:33</td><td>Cargador port&aacute;til original Sony en perfecto funcionamiento.</td><td>false</td><td>true</td><td>false</td><td>40.33485650301512</td><td>-3.753512526164084</td><td>28912</td><td>Legan&eacute;s</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>12.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>e6582k12m06o</td><td>Ordenador Portatil</td><td>kp61pydexx65</td><td>24200</td><td>2024-10-07 18:34:20</td><td>2024-10-07 18:34:30</td><td>Ordenador Portatil marca LENOVO, procesador i7, 16 Gb de Ram, 500 Gb de almacenamiento, Windows 1...</td><td>false</td><td>true</td><td>false</td><td>40.64753934259285</td><td>-3.153428038236667</td><td>19005</td><td>Guadalajara</td><td>Castilla-La Mancha</td><td>Guadalajara</td><td>ES</td><td>390.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>xzo2omm0o469</td><td>portatil Samsung</td><td>ke657840xmjo</td><td>24200</td><td>2024-10-07 17:56:00</td><td>2024-10-07 17:56:10</td><td>portatil para piezas o reparar enciende pero se calienta y se apaga descripcion en fotos no se ad...</td><td>false</td><td>true</td><td>false</td><td>40.48059493041799</td><td>-3.3768831193720614</td><td>28801</td><td>Alcal&aacute; de Henares</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>20.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>wzy4n2xov5z5</td><td>Portatil Lenovo </td><td>vjrkk2lv04zk</td><td>24200</td><td>2024-01-30 18:11:29</td><td>2024-10-07 16:19:28</td><td>Vendo port&aacute;til Lenovo IdeaPad 3 en muy buen estado. El port&aacute;til tiene un procesador AMD Ryzen 7, ...</td><td>false</td><td>true</td><td>false</td><td>40.42189783312117</td><td>-3.705112155540614</td><td>28070</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>650.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "<tr><td>v6ggn5ryyl6e</td><td>PORTATIL HP</td><td>7v6g4p08r26e</td><td>24200</td><td>2024-10-07 16:52:17</td><td>2024-10-07 16:52:28</td><td>Vendo portatil HP recien formateado y con el windows 10 pro\\nVa un poquillo lento pero funciona!\\...</td><td>false</td><td>true</td><td>false</td><td>40.238410165127036</td><td>-3.7684811939765335</td><td>28980</td><td>Parla</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>120.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-07 21:07:42.585303</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+----------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------+-------------------+-----------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "|          id|                                   title|     user_id|category_id|         created_at|        modified_at|                                                                                         description|favorited|is_favoriteable|is_refurbished|          latitude|          longitude|postal_code|             city|             region|    region2|country_code|amount|currency|reserved|item_is_shippable|user_allows_shipping|               __timestamp|\n",
                            "+------------+----------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------+-------------------+-----------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "|8j34odd1ey69|                IVEOPPE teclado portatil|kp61on7oqxj5|      24200|2024-10-07 18:06:43|2024-10-07 18:06:53|      IVEOPPE teclado portatil samsung galaxy TAB a9 + carcasa\\na estrenar\\nprecio en amazon: 30,99€|    false|           true|         false| 40.41883190365425|  -3.57184367222341|      28821|          Coslada|Comunidad de Madrid|     Madrid|          ES|  15.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "|e6582kk9ok6o|    Teclado portatil plegable recargable|kp61on7oqxj5|      24200|2024-10-07 17:53:13|2024-10-07 17:53:19|Mcbazel \\nTeclado portatil plegable recargable con dispositivo tactil para dispositivo movil/tabl...|    false|           true|         false| 40.41883190365425|  -3.57184367222341|      28821|          Coslada|Comunidad de Madrid|     Madrid|          ES|  15.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "|3zl8xwq1np6x|                                Portatil|xzo8x8v9gl69|      24200|2024-10-07 21:00:14|2024-10-07 21:00:24|Se vende porque se le da uso está en perfectas condiciones poco uso y cualquier cosa por chat pre...|    false|           true|         false|  40.4013020602374|  -3.61266807783252|      28032|           Madrid|Comunidad de Madrid|     Madrid|          ES| 110.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "|xzo2omn38w69|                               Portátil |nz0m0n7l93jo|      24200|2024-10-07 20:22:31|2024-10-07 20:27:58|Se vende porque no se le da uso está en perfectas condiciones poco uso y cualquier cosa por chat ...|    false|           true|         false| 40.40293549760407|-3.6036383752125976|      28032|           Madrid|Comunidad de Madrid|     Madrid|          ES| 110.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "|nzx4vn9247j2|          Monitor portátil 11'6 pulgadas|8z812r1reo63|      24200|2024-10-07 14:37:16|2024-10-07 14:39:53|Monitor nuevo. Contiene, pantalla, respaldo de pantalla, cable tipo c, cable tipo c a usb, cable ...|    false|           true|         false| 40.34549239334717|-3.8199855046355746|      28922|         Alcorcón|Comunidad de Madrid|     Madrid|          ES|  65.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "|8z8k9nm8v1z3|                      Ordenador portatil|qzm4m7kvwgzv|      24200|2024-10-07 21:03:30|2024-10-07 21:04:38|Funciona, aunque va muy lento. los botones del tactil van mal. Se escuchan ofertas. Tengo el carg...|    false|           true|         false|40.343563207976395| -3.709246913711613|      28021|           Madrid|Comunidad de Madrid|     Madrid|          ES| 120.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|xzo2omnoo469|                           Portatil Acer|3zlgnx7x3njx|      24200|2024-10-07 20:30:26|2024-10-07 20:55:10|                                   Portatil Acer funciona con su cargador original\\nescucho ofertas |    false|           true|         false|         40.326254|          -3.768059|      28911|          Leganés|Comunidad de Madrid|     Madrid|          ES|  30.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "|w6749l0nyy6x|                         Portatil gaming|8ejkpqn079zx|      24200|2024-10-05 19:32:45|2024-10-05 21:37:29|Se vende portátil MSI GF75 Thin 10SDR, Intel Core i7, 1TB, NVIDIA GeForce GTX1660Ti/6GB, Windows ...|    false|           true|         false|40.322746246594974| -3.854662525858509|      28937|         Móstoles|Comunidad de Madrid|     Madrid|          ES| 825.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|nzx4vnqe55j2|CUIUIC Monitor portátil de 15,6 Pulgadas|8z812r2my163|      24200|2024-10-07 12:51:08|2024-10-07 12:51:19|precintado\\nsolo envio\\n\\nCUIUIC Monitor portátil de 15,6 Pulgadas con Pantalla Full HD USB-C, 19...|    false|           true|         false|40.416156498413585|-3.7101967123015727|      28070|           Madrid|Comunidad de Madrid|     Madrid|          ES|  55.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|3zl8xw3y1p6x|                     ORDENADOR PORTÁTIL |e65y9rpllgjo|      24200|2024-10-07 19:21:19|2024-10-07 19:21:29|                   ORDENADOR PORTÁTIL CHUWI GEMIBOOK XPRO. DESCRIPCIÓN EN FOTOS. NUEVO.\\nSOLO ENVIO.|    false|           true|         false|40.457704764564234| -3.754137266350963|      28040|           Madrid|Comunidad de Madrid|     Madrid|          ES| 190.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|0j24k2v9knzy|                           Portatil acer|npj9gx531v6e|      24200|2024-10-07 19:29:56|2024-10-07 19:30:06|                   Se vende portatil acer antiguo sin cable de corriente, vale para despiece tambien|    false|           true|         false|40.254054239071955|-3.8166673934653597|      28970|Humanes de Madrid|Comunidad de Madrid|     Madrid|          ES|  20.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "|e6582kn3106o|                       Alzador portátil |kmzn2g5vgzn3|      24200|2024-10-07 19:35:19|2024-10-07 19:35:29|                                                   Base para alzar portátil o pantalla. Desmontable.|    false|           true|         false| 40.51585470621938|-3.3609342780673095|      28807|Alcalá de Henares|Comunidad de Madrid|     Madrid|          ES|   5.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|x6qm23ennyjy|                     ORDENADOR PORTÁTIL |e65y9rpllgjo|      24200|2024-10-07 19:07:52|2024-10-07 19:22:12|                        ORDENADOR PORTÁTIL BMAX X15 PLUS. DESCRIPCIÓN EN FOTOS. NUEVO. \\nSOLO ENVIO.|    false|           true|         false|40.457704764564234| -3.754137266350963|      28040|           Madrid|Comunidad de Madrid|     Madrid|          ES| 220.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|wzv4ve7dndzl|                      Cargador portatil |8z815qrvkl63|      24200|2024-10-07 18:36:03|2024-10-07 18:36:13|dos cargadores portatiles completamente nuevos con sus respectivos cables . uno de color negro y ...|    false|           true|         false|40.382206491272186| -3.669754084096236|      28053|           Madrid|Comunidad de Madrid|     Madrid|          ES| 120.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|vjrqv270k4zk| Plataforma refrigeración para portátil |wzvr102km16l|      24200|2024-10-07 20:46:15|2024-10-07 20:46:25|                    Plataforma de refrigeración de tres motores, con USB adicional y cable incluido.|    false|           true|         false|40.459700632071076|-3.7740925124798546|      28023|           Madrid|Comunidad de Madrid|     Madrid|          ES|  15.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|3zl8xwl0dn6x|                 Cargador portátil Sony |7v6g4o07276e|      24200|2024-10-07 20:21:21|2024-10-07 20:21:33|                                         Cargador portátil original Sony en perfecto funcionamiento.|    false|           true|         false| 40.33485650301512| -3.753512526164084|      28912|          Leganés|Comunidad de Madrid|     Madrid|          ES|  12.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|e6582k12m06o|                      Ordenador Portatil|kp61pydexx65|      24200|2024-10-07 18:34:20|2024-10-07 18:34:30|Ordenador Portatil marca LENOVO, procesador i7, 16 Gb de Ram, 500 Gb de almacenamiento, Windows 1...|    false|           true|         false| 40.64753934259285| -3.153428038236667|      19005|      Guadalajara| Castilla-La Mancha|Guadalajara|          ES| 390.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|xzo2omm0o469|                        portatil Samsung|ke657840xmjo|      24200|2024-10-07 17:56:00|2024-10-07 17:56:10|portatil para piezas o reparar enciende pero se calienta y se apaga descripcion en fotos no se ad...|    false|           true|         false| 40.48059493041799|-3.3768831193720614|      28801|Alcalá de Henares|Comunidad de Madrid|     Madrid|          ES|  20.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "|wzy4n2xov5z5|                        Portatil Lenovo |vjrkk2lv04zk|      24200|2024-01-30 18:11:29|2024-10-07 16:19:28|Vendo portátil Lenovo IdeaPad 3 en muy buen estado. El portátil tiene un procesador AMD Ryzen 7, ...|    false|           true|         false| 40.42189783312117| -3.705112155540614|      28070|           Madrid|Comunidad de Madrid|     Madrid|          ES| 650.0|     EUR|   false|             true|                true|2024-10-07 21:07:42.284301|\n",
                            "|v6ggn5ryyl6e|                             PORTATIL HP|7v6g4p08r26e|      24200|2024-10-07 16:52:17|2024-10-07 16:52:28|Vendo portatil HP recien formateado y con el windows 10 pro\\nVa un poquillo lento pero funciona!\\...|    false|           true|         false|40.238410165127036|-3.7684811939765335|      28980|            Parla|Comunidad de Madrid|     Madrid|          ES| 120.0|     EUR|   false|             true|               false|2024-10-07 21:07:42.284301|\n",
                            "+------------+----------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------+-------------------+-----------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "wallapop = (\n",
                "    spark.read.json(\"data/wallapop.json\", multiLine=True, primitivesAsString=True)\n",
                "    .withColumn(\"data\", f.explode(\"data.section.payload.items\"))\n",
                "    .select(\n",
                "        f.col(\"data.id\").cast(\"string\").alias(\"id\"),\n",
                "        f.col(\"data.title\").cast(\"string\").alias(\"title\"),\n",
                "        f.col(\"data.user_id\").cast(\"string\").alias(\"user_id\"),\n",
                "        f.col(\"data.category_id\").cast(\"int\").alias(\"category_id\"),\n",
                "        f.from_unixtime((f.col(\"data.created_at\") / 1000))\n",
                "        .cast(\"timestamp\")\n",
                "        .alias(\"created_at\"),\n",
                "        f.from_unixtime(f.col(\"data.modified_at\") / 1000)\n",
                "        .cast(\"timestamp\")\n",
                "        .alias(\"modified_at\"),\n",
                "        f.col(\"data.description\").cast(\"string\").alias(\"description\"),\n",
                "        f.col(\"data.favorited.flag\").cast(\"boolean\").alias(\"favorited\"),\n",
                "        f.col(\"data.is_favoriteable.flag\").cast(\"boolean\").alias(\"is_favoriteable\"),\n",
                "        f.col(\"data.is_refurbished.flag\").cast(\"boolean\").alias(\"is_refurbished\"),\n",
                "        f.col(\"data.location.latitude\").cast(\"double\").alias(\"latitude\"),\n",
                "        f.col(\"data.location.longitude\").cast(\"double\").alias(\"longitude\"),\n",
                "        f.col(\"data.location.postal_code\").cast(\"string\").alias(\"postal_code\"),\n",
                "        f.col(\"data.location.city\").cast(\"string\").alias(\"city\"),\n",
                "        f.col(\"data.location.region\").cast(\"string\").alias(\"region\"),\n",
                "        f.col(\"data.location.region2\").cast(\"string\").alias(\"region2\"),\n",
                "        f.col(\"data.location.country_code\").cast(\"string\").alias(\"country_code\"),\n",
                "        f.col(\"data.price.amount\").cast(\"double\").alias(\"amount\"),\n",
                "        f.col(\"data.price.currency\").cast(\"string\").alias(\"currency\"),\n",
                "        f.col(\"data.reserved.flag\").alias(\"reserved\"),\n",
                "        f.col(\"data.shipping.item_is_shippable\")\n",
                "        .cast(\"boolean\")\n",
                "        .alias(\"item_is_shippable\"),\n",
                "        f.col(\"data.shipping.user_allows_shipping\")\n",
                "        .cast(\"boolean\")\n",
                "        .alias(\"user_allows_shipping\"),\n",
                "        f.current_timestamp().alias(\"__timestamp\"),\n",
                "    )\n",
                ")\n",
                "wallapop.printSchema()\n",
                "display(wallapop)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Genial, ya hemos leído y transformado nuestro set de datos inicialmente desestructurado en una tabla bien estructurada, con unos campos y tipos fijados.\n",
                "\n",
                "Ahora, para completar la ETL, almacenaremos esta tabla en el catálogo de datos de Spark. En este caso, al estar trabajando de manera local, dicho catálogo de datos estará localizado en esta misma ruta (`metastore_db/`, `spark-warehouse/`, `derby.log`), sin embargo, cuando trabajemos en un entorno corporativo, habitualmente el catálogo de datos se alojará en una arquitectura cloud, como AWS, Azure, GCP, Databricks, etc.\n",
                "\n",
                "Aunque no es necesario, es una buena práctica crear en primera instancia la tabla Delta sobre la que escribiremos nuestro dataset, con un schema concreto, metadatos, etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/07 21:07:43 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
                        "24/10/07 21:07:43 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
                        "24/10/07 21:07:44 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
                        "24/10/07 21:07:44 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore dadiego@127.0.1.1\n",
                        "24/10/07 21:07:44 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
                        "24/10/07 21:07:46 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`default`.`wallapop` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
                        "24/10/07 21:07:46 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
                        "24/10/07 21:07:46 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
                        "24/10/07 21:07:46 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
                        "24/10/07 21:07:46 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
                    ]
                }
            ],
            "source": [
                "dt = (\n",
                "    DeltaTable.createIfNotExists(spark)\n",
                "    .addColumns(wallapop.schema)\n",
                "    .tableName(\"wallapop\")\n",
                "    .comment(\"Tabla de productos de Wallapop\")\n",
                "    .execute()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Con el método `createIfNotExists` estamos indicando que cree únicamente la tabla en el catálogo de datos si esta no existía previamente.\n",
                "\n",
                "Una vez creada la tabla, insertaremos los datos de nuestro DataFrame mediante una operación `merge`. Para ello, identificamos en primer lugar cuáles son los campos que consituyen una clave primaria en la tabla, es decir, un identificador único de cada registro. En este caso, podríamos utilizar por ejemplo la combinación `\"id\"`, `\"user_id\"`; cuando estos campos coincidan entre la tabla fuente y la tabla destino, actualizaremos los registros en el destino, y cuando no coincidan, insertaremos los registros de la fuente en el destino. Esto lo podemos hacer utilizando los métodos del objeto `DeltaTable` dentro de la librería externa `delta-spark` que tenemos instalada en nuestro entorno virtual de Python."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/07 21:07:47 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
                        "                                                                                \r"
                    ]
                }
            ],
            "source": [
                "(\n",
                "    dt.alias(\"target\")\n",
                "    .merge(\n",
                "        wallapop.alias(\"source\"),\n",
                "        \"source.id = target.id AND source.user_id = target.user_id\",\n",
                "    )\n",
                "    .whenMatchedUpdateAll()\n",
                "    .whenNotMatchedInsertAll()\n",
                "    .execute()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Cabe mencionar que también podríamos haber creado la tabla directamente a partir del DataFrame de spark, mediante la siguiente instrucción:\n",
                "```\n",
                "wallapop.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"wallapop\")\n",
                "```\n",
                "\n",
                "Ya hemos creado la tabla delta y hemos insertado los registros tabulados de la API de Wallapop en la misma. Ahora podemos consultar el catálogo mediante SQL.\n",
                "\n",
                "Primero, utilizaremos una función auxiliar de nuestro propio paquete de Python creado (`blackops`), llamada `get_detailed_tables_info`, para obtener información detallada de todas las tablas de nuestro catálogo de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/07 21:07:50 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>namespace</th><th>tableName</th><th></th><th>Catalog</th><th>Comment</th><th>Created By</th><th>Created Time</th><th>Database</th><th>InputFormat</th><th>Last Access</th><th>Location</th><th>OutputFormat</th><th>Owner</th><th>Partition Provider</th><th>Provider</th><th>Serde Library</th><th>Table</th><th>Type</th></tr>\n",
                            "<tr><td></td><td>empleados</td><td></td><td>NULL</td><td>NULL</td><td>Spark </td><td>Mon Oct 07 21:07:25 CEST 2024</td><td>NULL</td><td>NULL</td><td>UNKNOWN</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>empleados</td><td>VIEW</td></tr>\n",
                            "<tr><td>default</td><td>wallapop</td><td></td><td>spark_catalog</td><td>Tabla de productos de Wallapop</td><td>Spark 3.5.3</td><td>Mon Oct 07 21:07:46 CEST 2024</td><td>default</td><td>org.apache.hadoop.mapred.SequenceFileInputFormat</td><td>UNKNOWN</td><td>file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...</td><td>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td><td>dadiego</td><td>Catalog</td><td>delta</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td><td>wallapop</td><td>MANAGED</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+\n",
                            "|namespace|tableName|   |      Catalog|                       Comment| Created By|                 Created Time|Database|                                     InputFormat|Last Access|                                                                                            Location|                                             OutputFormat|  Owner|Partition Provider|Provider|                                     Serde Library|    Table|   Type|\n",
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+\n",
                            "|         |empleados|   |         NULL|                          NULL|     Spark |Mon Oct 07 21:07:25 CEST 2024|    NULL|                                            NULL|    UNKNOWN|                                                                                                NULL|                                                     NULL|   NULL|              NULL|    NULL|                                              NULL|empleados|   VIEW|\n",
                            "|  default| wallapop|   |spark_catalog|Tabla de productos de Wallapop|Spark 3.5.3|Mon Oct 07 21:07:46 CEST 2024| default|org.apache.hadoop.mapred.SequenceFileInputFormat|    UNKNOWN|file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...|org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat|dadiego|           Catalog|   delta|org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe| wallapop|MANAGED|\n",
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "get_detailed_tables_info(spark)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos obtener información concreta de nuestra tabla recién creada, `wallapop`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th></tr>\n",
                            "<tr><td>delta</td><td>1abd1a96-ee4d-47ec-8b25-99662ad4c0e8</td><td>spark_catalog.default.wallapop</td><td>Tabla de productos de Wallapop</td><td>file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...</td><td>2024-10-07 21:07:45.344</td><td>2024-10-07 21:07:50.686</td><td>[]</td><td>[]</td><td>1</td><td>16479</td><td>{}</td><td>1</td><td>2</td><td>[appendOnly, invariants]</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
                            "|format|                                  id|                          name|                   description|                                                                                            location|              createdAt|           lastModified|partitionColumns|clusteringColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|           tableFeatures|\n",
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
                            "| delta|1abd1a96-ee4d-47ec-8b25-99662ad4c0e8|spark_catalog.default.wallapop|Tabla de productos de Wallapop|file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...|2024-10-07 21:07:45.344|2024-10-07 21:07:50.686|              []|               []|       1|      16479|        {}|               1|               2|[appendOnly, invariants]|\n",
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+"
                        ]
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dt.detail()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "También podemos obtener una traza histórica de las veces que esta tabla se ha modificado, lo cual es enormemente útil de cara a disponer de un gobierno del dato escalable y robusto"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr>\n",
                            "<tr><td>1</td><td>2024-10-07 21:07:50.686</td><td>NULL</td><td>NULL</td><td>MERGE</td><td>{predicate -&gt; [&quot;((id#1132 = id#1438) AND (user_id#1134 = user_id#1440))&quot;], matchedPredicates -&gt; [...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>0</td><td>Serializable</td><td>false</td><td>{numTargetRowsCopied -&gt; 0, numTargetRowsDeleted -&gt; 0, numTargetFilesAdded -&gt; 1, numTargetBytesAdd...</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.0</td></tr>\n",
                            "<tr><td>0</td><td>2024-10-07 21:07:45.572</td><td>NULL</td><td>NULL</td><td>CREATE TABLE</td><td>{partitionBy -&gt; [], clusterBy -&gt; [], description -&gt; Tabla de productos de Wallapop, isManaged -&gt; ...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>Serializable</td><td>true</td><td>{}</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.0</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
                            "|version|              timestamp|userId|userName|   operation|                                                                                 operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                    operationMetrics|userMetadata|                         engineInfo|\n",
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
                            "|      1|2024-10-07 21:07:50.686|  NULL|    NULL|       MERGE|{predicate -> [\"((id#1132 = id#1438) AND (user_id#1134 = user_id#1440))\"], matchedPredicates -> [...|NULL|    NULL|     NULL|          0|  Serializable|        false|{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdd...|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.0|\n",
                            "|      0|2024-10-07 21:07:45.572|  NULL|    NULL|CREATE TABLE|{partitionBy -> [], clusterBy -> [], description -> Tabla de productos de Wallapop, isManaged -> ...|NULL|    NULL|     NULL|       NULL|  Serializable|         true|                                                                                                  {}|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.0|\n",
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+"
                        ]
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dt.history()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vemos como en el histórico aparecen las dos operaciones que hemos ejecutado sobre esta tabla Delta: la operación de creación de la tabla, y la operación de merge para insertar los nuevos datos.\n",
                "\n",
                "Podemos también ejecutar cualquier operación SQL con esta tabla del catálogo. Por ejemplo, veamos una tabla resumen de cuántos productos existen por comunidad y código postal, ordenada de mayor a menor cantidad de productos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>region</th><th>postal_code</th><th>n_products</th></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28912</td><td>4</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28070</td><td>3</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28911</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28032</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28821</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28040</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28045</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28970</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28921</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28980</td><td>1</td></tr>\n",
                            "<tr><td>Castilla-La Mancha</td><td>45122</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28924</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28230</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28820</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28047</td><td>1</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-------------------+-----------+----------+\n",
                            "|             region|postal_code|n_products|\n",
                            "+-------------------+-----------+----------+\n",
                            "|Comunidad de Madrid|      28912|         4|\n",
                            "|Comunidad de Madrid|      28070|         3|\n",
                            "|Comunidad de Madrid|      28911|         2|\n",
                            "|Comunidad de Madrid|      28032|         2|\n",
                            "|Comunidad de Madrid|      28821|         2|\n",
                            "|Comunidad de Madrid|      28040|         2|\n",
                            "|Comunidad de Madrid|      28045|         2|\n",
                            "|Comunidad de Madrid|      28970|         1|\n",
                            "|Comunidad de Madrid|      28921|         1|\n",
                            "|Comunidad de Madrid|      28980|         1|\n",
                            "| Castilla-La Mancha|      45122|         1|\n",
                            "|Comunidad de Madrid|      28924|         1|\n",
                            "|Comunidad de Madrid|      28230|         1|\n",
                            "|Comunidad de Madrid|      28820|         1|\n",
                            "|Comunidad de Madrid|      28047|         1|\n",
                            "+-------------------+-----------+----------+"
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "spark.sql(\n",
                "    \"select region, postal_code, count(*) as n_products from wallapop group by region, postal_code order by n_products desc limit 15\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
