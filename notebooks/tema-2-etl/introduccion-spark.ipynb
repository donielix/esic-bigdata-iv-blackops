{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introducción\n",
                "En este Notebook aprenderemos las operaciones básicas más utilizadas en PySpark, incluyendo un ejercicio práctico en el que realizaremos una pequeña ETL para extraer unos datos desde una API y los volcaremos en el catálogo de datos de Spark."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Importación de módulos requeridos\n",
                "En primer lugar necesitamos importar las funciones y objetos requeridos para la implementación.\n",
                "\n",
                "- `SparkSession`: objeto necesario para la interacción con la herramienta de Spark a través de Python.\n",
                "- `pyspark.sql.functions`: funciones de SQL que ofrece pyspark, necesarias para las transformaciones de los datos en la ETL.\n",
                "- `fetch_api, save_json`: estas funciones están definidas dentro de nuestra propia librería llamada `blackops`. Contienen el código necesario para extraer y almacenar los datos de la API.\n",
                "- `date, timedelta`: funciones para crear objetos de tipo fecha y timestamp dentro de Python.\n",
                "- `random`: módulo utilizado para la generación de datos aleatorios.\n",
                "- `DeltaTable`: objeto para interaccionar con tablas de tipo Delta. Se trata de un formato ampliamente utilizado en Spark, que ofrece muchas funcionalidades añadidas a nuestro catálogo de datos, como por ejemplo la posibilidad de revertir cambios."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "import pyspark.sql.functions as f\n",
                "from blackops.crawlers.wallapop.functions import fetch_api\n",
                "from blackops.utils.io import save_json\n",
                "from blackops.utils.catalog import get_detailed_tables_info\n",
                "from datetime import date, timedelta\n",
                "import random\n",
                "from delta import DeltaTable"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Establecemos una semilla para la generación de números aleatorios. De esta manera, los resultados serán reproducibles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "random.seed(45)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inicialización de la sesión de Spark\n",
                "\n",
                "Establecemos ahora la comunicación con el motor de Spark desde Python, a través del objeto `SparkSession` de la librería `pyspark`.\n",
                "\n",
                "En este caso de prueba no estamos utilizando un clúster, sino que haremos uso de una arquitectura local. El propio Jupyter Notebook ejercerá como Driver, como Master y como Ejecutor de las tareas.\n",
                "\n",
                "Adicionalmente, estamos instalando dependencias externas como la librería Delta, que incorpora utilidades muy importantes para el manejo de las tablas en nuestro catálogo de datos (histórico de versiones de tablas, omisión de ficheros innecesarios en la lectura, etc.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/02 00:42:50 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.1.40 instead (on interface enp3s0)\n",
                        "24/10/02 00:42:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
                        "Ivy Default Cache set to: /home/dadiego/.ivy2/cache\n",
                        "The jars for the packages stored in: /home/dadiego/.ivy2/jars\n",
                        "io.delta#delta-spark_2.12 added as a dependency\n",
                        ":: resolving dependencies :: org.apache.spark#spark-submit-parent-bb78a1d4-8e28-4265-b7d5-0ed536ecd0c8;1.0\n",
                        "\tconfs: [default]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ":: loading settings :: url = jar:file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/.venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
                        "\tfound io.delta#delta-storage;3.2.0 in central\n",
                        "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
                        ":: resolution report :: resolve 99ms :: artifacts dl 4ms\n",
                        "\t:: modules in use:\n",
                        "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
                        "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
                        "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
                        "\t---------------------------------------------------------------------\n",
                        "\t|                  |            modules            ||   artifacts   |\n",
                        "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
                        "\t---------------------------------------------------------------------\n",
                        "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
                        "\t---------------------------------------------------------------------\n",
                        ":: retrieving :: org.apache.spark#spark-submit-parent-bb78a1d4-8e28-4265-b7d5-0ed536ecd0c8\n",
                        "\tconfs: [default]\n",
                        "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
                        "24/10/02 00:42:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
                    ]
                }
            ],
            "source": [
                "spark = (\n",
                "    SparkSession.Builder()\n",
                "    .master(\"local[*]\")\n",
                "    .config(\n",
                "        map={\n",
                "            \"spark.driver.memory\": \"8g\",\n",
                "            \"spark.jars.packages\": \"io.delta:delta-spark_2.12:3.2.0\",\n",
                "            \"spark.sql.extensions\": \"io.delta.sql.DeltaSparkSessionExtension\",\n",
                "            \"spark.sql.catalog.spark_catalog\": \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
                "            \"spark.databricks.delta.retentionDurationCheck.enabled\": \"false\",\n",
                "            \"spark.sql.catalogImplementation\": \"hive\",\n",
                "            \"spark.sql.repl.eagerEval.enabled\": \"true\",\n",
                "            \"spark.sql.repl.eagerEval.truncate\": \"100\",\n",
                "        }\n",
                "    )\n",
                "    .getOrCreate()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez se ha inicializado la sesión, podemos acceder a la web `localhost:4040` para consultar la interfaz de administración que ofrece Spark. Allí, se podrá monitorizar las tareas que se mandan desde el Driver.\n",
                "\n",
                "**Nota**: Si al inicializar la sesión de Spark obtenemos algún error en el que se nos indica que la variable `JAVA_HOME` no existe, lo más probable es que no tengamos instalado Java en nuestro sistema, y necesitamos instalarlo ya que Spark depende de Java para su funcionamiento. Para ello, en Linux podemos utilizar el gestor de paquetes: `sudo apt update && sudo apt install openjdk-17-jdk -y`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Creación de un DataFrame de Spark\n",
                "\n",
                "En Spark podemos crear directamente un Dataframe a partir de una lista de datos, o bien de un Dataframe de pandas. Para ello se puede utilizar el método `spark.createDataFrame`.\n",
                "Debemos especificar tanto los datos como el esquema que tiene el Dataframe (sus columnas y sus tipos).\n",
                "\n",
                "En este caso hacemos uso del paquete `random` para generar datos aleatorios (pero reproducibles, al haber establecido una semilla)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Podemos especificar el esquema del DataFrame usando una cadena de texto\n",
                "schema = \"id INT, nombre STRING, edad INT, salario FLOAT, es_empleado BOOLEAN, fecha_contratacion DATE, departamento STRING\"\n",
                "\n",
                "# Crear una lista de datos ficticios\n",
                "nombres = [\n",
                "    \"Juan\",\n",
                "    \"María\",\n",
                "    \"Pedro\",\n",
                "    \"Ana\",\n",
                "    \"Luis\",\n",
                "    \"Carla\",\n",
                "    \"Miguel\",\n",
                "    \"Sara\",\n",
                "    \"David\",\n",
                "    \"Laura\",\n",
                "]\n",
                "departamentos = [\"Ventas\", \"Marketing\", \"Finanzas\", \"IT\", \"RRHH\"]\n",
                "\n",
                "data = [\n",
                "    (\n",
                "        i,  # id\n",
                "        random.choice(nombres),  # nombre\n",
                "        random.randint(22, 60),  # edad\n",
                "        round(random.uniform(20000, 80000), 2),  # salario\n",
                "        random.choice([True, False]),  # es_empleado\n",
                "        date(2024, 10, 1)\n",
                "        - timedelta(days=random.randint(0, 3650)),  # fecha_contratacion\n",
                "        random.choice(departamentos),  # departamento\n",
                "    )\n",
                "    for i in range(1, 31)  # Genera 30 registros aleatorios\n",
                "]\n",
                "\n",
                "# Crear el DataFrame usando el esquema en string\n",
                "df = spark.createDataFrame(data, schema)\n",
                "\n",
                "# Creamos una vista temporal del DataFrame en el catálogo, para poder hacer consultas en SQL.\n",
                "df.createOrReplaceTempView(\"empleados\")\n",
                "\n",
                "# Mostramos el DataFrame resultante por pantalla\n",
                "display(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Operaciones de transformación\n",
                "\n",
                "La sintaxis de Spark es muy similar a la del lenguaje SQL, de hecho, admite la introducción de comandos SQL para realizar las transformaciones de los datos. Vamos a ver algunas de las operaciones más habituales.\n",
                "\n",
                "### Select\n",
                "\n",
                "La operación más sencilla consiste en seleccionar simplemente un subconjunto de los datos, sin ninguna otra operación de transformación o filtro añadido. Por ejemplo, seleccionemos únicamente los campos `id` y `nombre`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>8</td><td>David</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td></tr>\n",
                            "<tr><td>12</td><td>David</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+\n",
                            "| id|nombre|\n",
                            "+---+------+\n",
                            "|  1|  Luis|\n",
                            "|  2|  Juan|\n",
                            "|  3|  Luis|\n",
                            "|  4| Pedro|\n",
                            "|  5|Miguel|\n",
                            "|  6|  Luis|\n",
                            "|  7| María|\n",
                            "|  8| David|\n",
                            "|  9|  Sara|\n",
                            "| 10|   Ana|\n",
                            "| 11|Miguel|\n",
                            "| 12| David|\n",
                            "| 13| Laura|\n",
                            "| 14| Pedro|\n",
                            "| 15| María|\n",
                            "| 16|  Sara|\n",
                            "| 17|   Ana|\n",
                            "| 18|  Sara|\n",
                            "| 19| María|\n",
                            "| 20| Pedro|\n",
                            "+---+------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.select(\"id\", \"nombre\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Al igual que en SQL estándar, podemos no solo seleccionar unas columnas sino aplicarles alguna función de transformación dentro del propio comando SELECT, y renombrarlas utilizando un alias.\n",
                "\n",
                "Las funciones SQL en Spark están contenidas en el módulo `pyspark.sql.functions`, que hemos importado al principio y lo hemos almacenado en un objeto con alias `f` (por sencillez de uso).\n",
                "\n",
                "Vamos a seleccionar en este caso los mismos campos que en el ejemplo anterior, sin embargo, al campo `nombre` le vamos a aplicar una transformación para visualizar el nombre en mayúsculas, y al resultado lo renombraremos `nombre_en_mayusculas`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre_en_mayusculas</th></tr>\n",
                            "<tr><td>1</td><td>LUIS</td></tr>\n",
                            "<tr><td>2</td><td>JUAN</td></tr>\n",
                            "<tr><td>3</td><td>LUIS</td></tr>\n",
                            "<tr><td>4</td><td>PEDRO</td></tr>\n",
                            "<tr><td>5</td><td>MIGUEL</td></tr>\n",
                            "<tr><td>6</td><td>LUIS</td></tr>\n",
                            "<tr><td>7</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>8</td><td>DAVID</td></tr>\n",
                            "<tr><td>9</td><td>SARA</td></tr>\n",
                            "<tr><td>10</td><td>ANA</td></tr>\n",
                            "<tr><td>11</td><td>MIGUEL</td></tr>\n",
                            "<tr><td>12</td><td>DAVID</td></tr>\n",
                            "<tr><td>13</td><td>LAURA</td></tr>\n",
                            "<tr><td>14</td><td>PEDRO</td></tr>\n",
                            "<tr><td>15</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>16</td><td>SARA</td></tr>\n",
                            "<tr><td>17</td><td>ANA</td></tr>\n",
                            "<tr><td>18</td><td>SARA</td></tr>\n",
                            "<tr><td>19</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>20</td><td>PEDRO</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+--------------------+\n",
                            "| id|nombre_en_mayusculas|\n",
                            "+---+--------------------+\n",
                            "|  1|                LUIS|\n",
                            "|  2|                JUAN|\n",
                            "|  3|                LUIS|\n",
                            "|  4|               PEDRO|\n",
                            "|  5|              MIGUEL|\n",
                            "|  6|                LUIS|\n",
                            "|  7|               MARÍA|\n",
                            "|  8|               DAVID|\n",
                            "|  9|                SARA|\n",
                            "| 10|                 ANA|\n",
                            "| 11|              MIGUEL|\n",
                            "| 12|               DAVID|\n",
                            "| 13|               LAURA|\n",
                            "| 14|               PEDRO|\n",
                            "| 15|               MARÍA|\n",
                            "| 16|                SARA|\n",
                            "| 17|                 ANA|\n",
                            "| 18|                SARA|\n",
                            "| 19|               MARÍA|\n",
                            "| 20|               PEDRO|\n",
                            "+---+--------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.select(\"id\", f.upper(\"nombre\").alias(\"nombre_en_mayusculas\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### WithColumn\n",
                "\n",
                "Podemos añadir campos nuevos derivados a partir de otros campos utilizando el método `withColumn`. Este comando conservará todas las columnas de la tabla, y añadirá una adicional, con las transformaciones que le indiquemos.\n",
                "\n",
                "Este método opera fila a fila, es decir, aplicará las transformaciones correspondientes registro a registro.\n",
                "\n",
                "Por ejemplo, en nuestra tabla disponemos del campo `edad`, pero supongamos que nos interesa, para nuestra analítica, disponer de un campo con el año de nacimiento. En tal caso, podríamos concatenar dos funciones SQL: con la primera, `current_date`, extraemos la fecha actual, y sobre dicha fecha aplicamos la función `year` para extraer el año. Finalmente, a este año actual le restamos la edad que tiene el usuario para así calcular su año de nacimiento. Cada usuario dispondrá así de un año de nacimiento (transformación fila a fila)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th><th>a&ntilde;o_nacimiento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td><td>1976</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td><td>1998</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td><td>2000</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td><td>1989</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td><td>1993</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td><td>1980</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td><td>2001</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td><td>1968</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td><td>1979</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td><td>1971</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td><td>1978</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td><td>1997</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td><td>2001</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td><td>1991</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td><td>2002</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td><td>1974</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td><td>1971</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td><td>1996</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td><td>1998</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td><td>1997</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|año_nacimiento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|          1976|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|          1998|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|          2000|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|          1989|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|          1993|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|          1980|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|          2001|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|          1968|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|          1979|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|          1971|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|          1978|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|          1997|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|          2001|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|          1991|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|          2002|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|          1974|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|          1971|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|          1996|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|          1998|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|          1997|\n",
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.withColumn(\"año_nacimiento\", f.year(f.current_date()) - f.col(\"edad\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Filter\n",
                "\n",
                "Podemos filtrar los datos de acuerdo a alguna condición especificada. Esta sentencia se corresponde con el comando `WHERE` en SQL. Por ejemplo, queremos obtener únicamente los datos de los empleados. \n",
                "\n",
                "Recordemos que en Python el operador de igualdad es `==`.\n",
                "\n",
                "Para poder realizar operaciones con columnas, necesitamos especificar que se trata de una columna del DataFrame haciendo uso de la función `col`, puesto que si no lo que estaríamos es comparando un string con un booleano (`\"es_empleado\" == True`), que será siempre igual a `False`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td></tr>\n",
                            "<tr><td>23</td><td>Carla</td><td>50</td><td>73172.89</td><td>true</td><td>2015-08-21</td><td>IT</td></tr>\n",
                            "<tr><td>25</td><td>Sara</td><td>59</td><td>59973.55</td><td>true</td><td>2018-04-23</td><td>Marketing</td></tr>\n",
                            "<tr><td>29</td><td>Miguel</td><td>37</td><td>69922.06</td><td>true</td><td>2023-10-26</td><td>Finanzas</td></tr>\n",
                            "<tr><td>30</td><td>Luis</td><td>27</td><td>70247.43</td><td>true</td><td>2020-05-23</td><td>Finanzas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|\n",
                            "| 23| Carla|  50|73172.89|       true|        2015-08-21|          IT|\n",
                            "| 25|  Sara|  59|59973.55|       true|        2018-04-23|   Marketing|\n",
                            "| 29|Miguel|  37|69922.06|       true|        2023-10-26|    Finanzas|\n",
                            "| 30|  Luis|  27|70247.43|       true|        2020-05-23|    Finanzas|\n",
                            "+---+------+----+--------+-----------+------------------+------------+"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(f.col(\"es_empleado\") == True)\n",
                "\n",
                "# Si hacemos df.filter(\"es_empleado\" == True) obtendremos un error porque los tipos no son los esperados."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Agrupaciones\n",
                "\n",
                "Utilizando el comando group by, podemos agrupar nuestro dataset según los valores de una o varias columnas y posteriormente realizar una operación de agregación sobre cada conjunto, para así obtener estadísticas descriptivas de nuestros datos.\n",
                "\n",
                "Por ejemplo, podemos obtener el número de empleados en marketing, con lo cual debemos agrupar por departamento y realizar una operación de agregación de suma. Estas operaciones se denominan \"de agregación\" o \"de reducción\" porque actúan sobre un conjunto de filas (todas aquellas que comparten el mismo valor del grupo) y devuelven un único valor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>salario_total</th></tr>\n",
                            "<tr><td>Finanzas</td><td>524206.53515625</td></tr>\n",
                            "<tr><td>Ventas</td><td>421618.7890625</td></tr>\n",
                            "<tr><td>RRHH</td><td>292734.91015625</td></tr>\n",
                            "<tr><td>IT</td><td>355377.107421875</td></tr>\n",
                            "<tr><td>Marketing</td><td>122665.44140625</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+----------------+\n",
                            "|departamento|   salario_total|\n",
                            "+------------+----------------+\n",
                            "|    Finanzas| 524206.53515625|\n",
                            "|      Ventas|  421618.7890625|\n",
                            "|        RRHH| 292734.91015625|\n",
                            "|          IT|355377.107421875|\n",
                            "|   Marketing| 122665.44140625|\n",
                            "+------------+----------------+"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.groupBy(\"departamento\").agg(f.sum(\"salario\").alias(\"salario_total\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Combinaciones\n",
                "Naturalmente, la riqueza de PySpark es que podemos combinar filtros con agrupaciones, adición de columnas, cambios de tipos, etc para que nuestro dato final quede pulido.\n",
                "\n",
                "Al contrario que en Pandas, todas las operaciones de transformación en Spark son *lazy*, es decir, no se evalúan hasta que se pide una acción (resultado). Esto permite que el catalizador de Spark optimice toda la cadena de consultas de la manera más apropiada antes de ser ejecutadas.\n",
                "\n",
                "Veamos un ejemplo de consulta algo más avanzada: supongamos que queremos conocer cuál es el departamento del que más gente se ha ido a partir de 2017 para unos ciertos intervalos de meses: enero a mayo, junio a septiembre y octubre a diciembre. En este caso podemos comenzar aplicando unos filtros para quedarnos únicamente con registros de los que actualmente ya no son empleados y su fecha de contratación es igual o posterior a 2017. Después de aplicar dicho filtro, podemos añadir dos columnas transitorias para extraer el mes de la fecha de contratación y establecer los intervalos pedidos, utilizando la función `when`, que es esquivalente al `CASE` de SQL. Finalmente, agrupamos por estas categorías de mes y agregamos cogiendo la moda (el valor más repetido de un conjunto de datos)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>categoria_mes</th><th>departamento_mas_repetido</th></tr>\n",
                            "<tr><td>octubre-diciembre</td><td>RRHH</td></tr>\n",
                            "<tr><td>junio-septiembre</td><td>Marketing</td></tr>\n",
                            "<tr><td>enero-mayo</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-----------------+-------------------------+\n",
                            "|    categoria_mes|departamento_mas_repetido|\n",
                            "+-----------------+-------------------------+\n",
                            "|octubre-diciembre|                     RRHH|\n",
                            "| junio-septiembre|                Marketing|\n",
                            "|       enero-mayo|                   Ventas|\n",
                            "+-----------------+-------------------------+"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(\n",
                "    (f.col(\"es_empleado\") == False) & (f.year(\"fecha_contratacion\") >= 2017)\n",
                ").withColumn(\"mes_contratacion\", f.month(\"fecha_contratacion\")).withColumn(\n",
                "    \"categoria_mes\",\n",
                "    f.when(f.col(\"mes_contratacion\").between(1, 5), f.lit(\"enero-mayo\"))\n",
                "    .when(f.col(\"mes_contratacion\").between(6, 9), f.lit(\"junio-septiembre\"))\n",
                "    .otherwise(f.lit(\"octubre-diciembre\")),\n",
                ").groupBy(\n",
                "    \"categoria_mes\"\n",
                ").agg(\n",
                "    f.mode(\"departamento\").alias(\"departamento_mas_repetido\")\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "La consulta equivalente en Spark SQL en este caso sería la siguiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>categoria_mes</th><th>departamento_mas_repetido</th></tr>\n",
                            "<tr><td>octubre-diciembre</td><td>RRHH</td></tr>\n",
                            "<tr><td>junio-septiembre</td><td>Marketing</td></tr>\n",
                            "<tr><td>enero-mayo</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-----------------+-------------------------+\n",
                            "|    categoria_mes|departamento_mas_repetido|\n",
                            "+-----------------+-------------------------+\n",
                            "|octubre-diciembre|                     RRHH|\n",
                            "| junio-septiembre|                Marketing|\n",
                            "|       enero-mayo|                   Ventas|\n",
                            "+-----------------+-------------------------+"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "spark.sql(\n",
                "    \"\"\"\n",
                "    SELECT\n",
                "        CASE\n",
                "            WHEN MONTH(fecha_contratacion) BETWEEN 1 AND 5 THEN 'enero-mayo'\n",
                "            WHEN MONTH(fecha_contratacion) BETWEEN 6 AND 9 THEN 'junio-septiembre'\n",
                "            ELSE 'octubre-diciembre'\n",
                "        END AS categoria_mes,\n",
                "        MODE(departamento) AS departamento_mas_repetido\n",
                "\n",
                "    FROM empleados\n",
                "    WHERE\n",
                "        es_empleado = false AND\n",
                "        YEAR(fecha_contratacion) >= 2017\n",
                "    GROUP BY categoria_mes\n",
                "    \"\"\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como se puede comprobar, se obtienen exactamente los mismos resultados"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Joins\n",
                "Al igual que las operaciones de transformación, otro comando importante es el de JOIN, que nos permite establecer links entre campos de diferentes columnas, lo cual resulta fundamental para el análisis desde diferentes fuentes de datos.\n",
                "\n",
                "Un análisis detallado y extenso de los diferentes tipos de Joins en Pyspark puede verse [aquí](https://sparkbyexamples.com/pyspark/pyspark-join-explained-with-examples/).\n",
                "\n",
                "Esquemáticamente tenemos los siguientes tipos de JOINs:\n",
                "\n",
                "![tipos de joins](joins.png \"Tipos de Joins\")\n",
                "\n",
                "Por poner un ejemplo, creemos un segundo dataframe con información añadida de los departamentos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>departamento</th><th>descripcion</th></tr>\n",
                            "<tr><td>1</td><td>Finanzas</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>2</td><td>Ventas</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------------+------------------------------------------------------------------------+\n",
                            "| id|departamento|                                                             descripcion|\n",
                            "+---+------------+------------------------------------------------------------------------+\n",
                            "|  1|    Finanzas|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|  2|      Ventas|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "+---+------------+------------------------------------------------------------------------+"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "departamentos = spark.createDataFrame(\n",
                "    [\n",
                "        (\n",
                "            1,\n",
                "            \"Finanzas\",\n",
                "            \"Departamento encargado de elaborar informes financieros trimestrales\",\n",
                "        ),\n",
                "        (\n",
                "            2,\n",
                "            \"Ventas\",\n",
                "            \"Departamento encargado de contactar con proveedores y registrar el stock\",\n",
                "        ),\n",
                "    ], schema=\"id int, departamento string, descripcion string\"\n",
                ")\n",
                "display(departamentos)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Y ahora vamos a unir nuestra tabla de origen con esta tabla de información extendida por departamento. El campo de unión lógicamente será la columna `\"departamento\"`.\n",
                "\n",
                "Empecemos con un INNER JOIN. En este caso, únicamente se mostrarán los departamentos de Finanzas y Ventas, ya que son los únicos registros comunes a ambas tablas (el resto de departamentos no está presente en la tabla `departamentos`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>id</th><th>descripcion</th></tr>\n",
                            "<tr><td>Finanzas</td><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>22</td><td>Juan</td><td>26</td><td>39267.68</td><td>false</td><td>2022-02-16</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>26</td><td>Ana</td><td>25</td><td>22953.8</td><td>false</td><td>2018-05-11</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>29</td><td>Miguel</td><td>37</td><td>69922.06</td><td>true</td><td>2023-10-26</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>30</td><td>Luis</td><td>27</td><td>70247.43</td><td>true</td><td>2020-05-23</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>24</td><td>David</td><td>56</td><td>62486.47</td><td>false</td><td>2018-02-17</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>27</td><td>Carla</td><td>50</td><td>68186.09</td><td>false</td><td>2018-02-04</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>28</td><td>Miguel</td><td>51</td><td>64634.71</td><td>false</td><td>2018-05-29</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion| id|                                                             descripcion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+\n",
                            "|    Finanzas|  1|  Luis|  48|49281.69|       true|        2021-05-09|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  3|  Luis|  24|73947.68|       true|        2023-03-28|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  5|Miguel|  31|62027.07|       true|        2022-10-27|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 13| Laura|  23|57455.18|      false|        2021-03-08|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 15| María|  22|57444.64|      false|        2017-10-22|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 17|   Ana|  53| 21659.3|       true|        2018-01-19|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 22|  Juan|  26|39267.68|      false|        2022-02-16|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 26|   Ana|  25| 22953.8|      false|        2018-05-11|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 29|Miguel|  37|69922.06|       true|        2023-10-26|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 30|  Luis|  27|70247.43|       true|        2020-05-23|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas|  2|  Juan|  26|49055.36|       true|        2021-07-27|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  8| David|  56|72059.12|      false|        2018-02-06|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  9|  Sara|  45|74705.86|      false|        2023-01-02|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 18|  Sara|  28|30491.18|       true|        2015-12-13|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 24| David|  56|62486.47|      false|        2018-02-17|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 27| Carla|  50|68186.09|      false|        2018-02-04|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 28|Miguel|  51|64634.71|      false|        2018-05-29|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"inner\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora haremos un LEFT JOIN. En este caso se mostrarán todos los registros de la tabla de origen, con todos los departamentos por tanto. Y si existe un departamento equivalente en la tabla derecha, se mostrará también su información adicional. En caso de no existir un match (cuando el departamento no sea el de ventas o finanzas), dicha información adicional será nula"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>id</th><th>descripcion</th></tr>\n",
                            "<tr><td>Finanzas</td><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Finanzas</td><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>RRHH</td><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Ventas</td><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Marketing</td><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>RRHH</td><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>IT</td><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>RRHH</td><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>IT</td><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>RRHH</td><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>NULL</td><td>NULL</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion|  id|                                                             descripcion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "|    Finanzas|  1|  Luis|  48|49281.69|       true|        2021-05-09|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  3|  Luis|  24|73947.68|       true|        2023-03-28|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas|  2|  Juan|  26|49055.36|       true|        2021-07-27|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|    Finanzas|  5|Miguel|  31|62027.07|       true|        2022-10-27|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|        RRHH|  4| Pedro|  35|79554.92|      false|        2023-11-29|NULL|                                                                    NULL|\n",
                            "|          IT|  6|  Luis|  44|66505.58|      false|        2023-09-13|NULL|                                                                    NULL|\n",
                            "|          IT|  7| María|  23|65070.76|      false|        2015-12-18|NULL|                                                                    NULL|\n",
                            "|      Ventas|  8| David|  56|72059.12|      false|        2018-02-06|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  9|  Sara|  45|74705.86|      false|        2023-01-02|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|   Marketing| 10|   Ana|  53|62691.89|      false|        2021-06-16|NULL|                                                                    NULL|\n",
                            "|          IT| 11|Miguel|  46|70126.54|       true|        2018-03-14|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 13| Laura|  23|57455.18|      false|        2021-03-08|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|        RRHH| 12| David|  27|53608.56|       true|        2014-11-09|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 15| María|  22|57444.64|      false|        2017-10-22|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|          IT| 14| Pedro|  33|20602.28|      false|        2024-03-12|NULL|                                                                    NULL|\n",
                            "|        RRHH| 16|  Sara|  50|32029.18|      false|        2022-01-13|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 17|   Ana|  53| 21659.3|       true|        2018-01-19|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas| 18|  Sara|  28|30491.18|       true|        2015-12-13|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|          IT| 20| Pedro|  27|59899.06|      false|        2015-02-25|NULL|                                                                    NULL|\n",
                            "|        RRHH| 19| María|  26|61548.89|      false|        2015-11-03|NULL|                                                                    NULL|\n",
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"left\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Por último, veamos el caso del LEFT ANTI JOIN. En este caso, se mostrarán únicamente los registros de la tabla origen que no tienen un match con los de la tabla de departamentos; es decir, aquellos registros del dataframe cuyo departamento no es ventas ni finanzas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th></tr>\n",
                            "<tr><td>RRHH</td><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td></tr>\n",
                            "<tr><td>IT</td><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td></tr>\n",
                            "<tr><td>IT</td><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td></tr>\n",
                            "<tr><td>Marketing</td><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td></tr>\n",
                            "<tr><td>IT</td><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td></tr>\n",
                            "<tr><td>RRHH</td><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td></tr>\n",
                            "<tr><td>IT</td><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td></tr>\n",
                            "<tr><td>RRHH</td><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td></tr>\n",
                            "<tr><td>IT</td><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td></tr>\n",
                            "<tr><td>RRHH</td><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td></tr>\n",
                            "<tr><td>RRHH</td><td>21</td><td>Luis</td><td>46</td><td>65993.36</td><td>false</td><td>2022-12-04</td></tr>\n",
                            "<tr><td>IT</td><td>23</td><td>Carla</td><td>50</td><td>73172.89</td><td>true</td><td>2015-08-21</td></tr>\n",
                            "<tr><td>Marketing</td><td>25</td><td>Sara</td><td>59</td><td>59973.55</td><td>true</td><td>2018-04-23</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+\n",
                            "|        RRHH|  4| Pedro|  35|79554.92|      false|        2023-11-29|\n",
                            "|          IT|  6|  Luis|  44|66505.58|      false|        2023-09-13|\n",
                            "|          IT|  7| María|  23|65070.76|      false|        2015-12-18|\n",
                            "|   Marketing| 10|   Ana|  53|62691.89|      false|        2021-06-16|\n",
                            "|          IT| 11|Miguel|  46|70126.54|       true|        2018-03-14|\n",
                            "|        RRHH| 12| David|  27|53608.56|       true|        2014-11-09|\n",
                            "|          IT| 14| Pedro|  33|20602.28|      false|        2024-03-12|\n",
                            "|        RRHH| 16|  Sara|  50|32029.18|      false|        2022-01-13|\n",
                            "|          IT| 20| Pedro|  27|59899.06|      false|        2015-02-25|\n",
                            "|        RRHH| 19| María|  26|61548.89|      false|        2015-11-03|\n",
                            "|        RRHH| 21|  Luis|  46|65993.36|      false|        2022-12-04|\n",
                            "|          IT| 23| Carla|  50|73172.89|       true|        2015-08-21|\n",
                            "|   Marketing| 25|  Sara|  59|59973.55|       true|        2018-04-23|\n",
                            "+------------+---+------+----+--------+-----------+------------------+"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"leftanti\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Caso práctico: Extracción de datos de Wallapop\n",
                "Vamos a construir un pequeño ejemplo de una ETL (Extraction Transform Load). Extraeremos datos en crudo desde la API REST de Wallapop, los guardamos en una carpeta de almacenamiento, los leemos con spark, realizamos algunas transformaciones y almacenamos la tabla resultante en nuestro catálogo de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    json_data = fetch_api(product=\"portátil\")\n",
                "    save_json(obj=json_data, path=\"data/wallapop.json\", indent=4)\n",
                "except Exception as e:\n",
                "    print(f\"Warning: No ha sido posible descargar los datos de la API: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos previsualizar cuál es la estructura de nuestro fichero JSON utilizando el comando externo `cat` de nuestra terminal (válido únicamente en sistemas Unix, con `jq` instalado).\n",
                "\n",
                "Si no está instalado `jq`, puede instalarse mediante `sudo apt update && sudo apt install jq -y`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1;39m{\n",
                        "  \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "    \u001b[0m\u001b[34;1m\"section\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "      \u001b[0m\u001b[34;1m\"payload\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "        \u001b[0m\u001b[34;1m\"order\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"most_relevance\"\u001b[0m\u001b[1;39m,\n",
                        "        \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Find what you want\"\u001b[0m\u001b[1;39m,\n",
                        "        \u001b[0m\u001b[34;1m\"items\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
                        "          \u001b[1;39m{\n",
                        "            \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"9jdk4mmm7n6k\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"user_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pj9ydq0n026e\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Monitor LG de 19\\\" para Portatil/Pc\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"FLATRON L-194LW-SF. Como nuevo. Funcionando  perfectamente. Prueba real a doble pantalla en portatil HP usando el cable DVI-D a HDMI incluido (ver foto), lo que permite disponer de un monitor con conexión a cualquier dispositivo actual con entrada HDMI. Se incluye cable de corriente, 1  cable totalmente nuevo DVI-D a HDMI y los 2 cables originales DVI-D a DVI-D y D-Sub 15 pin a D-Sub 15 pin (valorados los 3 cables en 15 euros aprox.), permitiendo variedad de conexiones. Se incluye también instrucciones en ingles y CD de instalación con drivers y guia de uso.\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"category_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m24200\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"price\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "              \u001b[0m\u001b[34;1m\"amount\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m55\u001b[0m\u001b[1;39m,\n",
                        "              \u001b[0m\u001b[34;1m\"currency\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"EUR\"\u001b[0m\u001b[1;39m\n",
                        "            \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"images\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
                        "              \u001b[1;39m{\n",
                        "                \u001b[0m\u001b[34;1m\"average_color\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"13C1AC\"\u001b[0m\u001b[1;39m,\n"
                    ]
                }
            ],
            "source": [
                "%%sh\n",
                "cat data/wallapop.json | jq -C | head -20"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez determinada la estructura que tiene nuestro fichero JSON de información, notamos que los datos que queremos obtener se encuentran dentro de la ruta `data -> section -> payload -> items`. Dicha ruta se corresponde con un array (lista) de items, que son los productos de Wallapop; cada uno de ellos tiene unos campos, algunos simples como `id`, `user_id`, y otros compuestos como `price -> amount` o `price -> currency`.\n",
                "\n",
                "En primer lugar, observemos que si leemos el fichero JSON directamente no obtenemos una estructura muy amigable\n",
                "\n",
                "*Nota*: el argumento `multiLine=True` se introduce para especificar que el fichero JSON de entrada que estamos tratando de leer abarca múltiples líneas, y no una sola. De esta manera nos evitaremos errores de lectura."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "|                                              data|                                              meta|\n",
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "|{{{[{{none}, 24200, 1727815730476, FLATRON L-19...|{eyJhbGciOiJIUzI1NiJ9.eyJwYXJhbXMiOnsic2VhcmNoU...|\n",
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop = spark.read.json(\"data/wallapop.json\", multiLine=True)\n",
                "wallapop.show(truncate=50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esto es porque nos ha cogido las dos primeras claves más externas de nuestro fichero JSON, que son los campos `\"data\"` y `\"meta\"`.\n",
                "\n",
                "Observemos qué estructura hemos cargado haciendo un `printSchema` de nuestro DataFrame. De esta manera obtendremos información de los campos y sus tipos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- data: struct (nullable = true)\n",
                        " |    |-- section: struct (nullable = true)\n",
                        " |    |    |-- payload: struct (nullable = true)\n",
                        " |    |    |    |-- items: array (nullable = true)\n",
                        " |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |-- bump: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- type: string (nullable = true)\n",
                        " |    |    |    |    |    |-- category_id: long (nullable = true)\n",
                        " |    |    |    |    |    |-- created_at: long (nullable = true)\n",
                        " |    |    |    |    |    |-- description: string (nullable = true)\n",
                        " |    |    |    |    |    |-- discount: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- percentage: long (nullable = true)\n",
                        " |    |    |    |    |    |    |-- previous_price: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- amount: double (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- currency: string (nullable = true)\n",
                        " |    |    |    |    |    |-- favorited: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- id: string (nullable = true)\n",
                        " |    |    |    |    |    |-- images: array (nullable = true)\n",
                        " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |    |    |-- average_color: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- urls: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- big: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- medium: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- small: string (nullable = true)\n",
                        " |    |    |    |    |    |-- is_favoriteable: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- is_refurbished: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- location: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- city: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- country_code: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- latitude: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- longitude: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- postal_code: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- region: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- region2: string (nullable = true)\n",
                        " |    |    |    |    |    |-- modified_at: long (nullable = true)\n",
                        " |    |    |    |    |    |-- price: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- amount: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- currency: string (nullable = true)\n",
                        " |    |    |    |    |    |-- reserved: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- shipping: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- cost_configuration_id: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- item_is_shippable: boolean (nullable = true)\n",
                        " |    |    |    |    |    |    |-- user_allows_shipping: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- taxonomy: array (nullable = true)\n",
                        " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |    |    |-- icon: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- id: long (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- name: string (nullable = true)\n",
                        " |    |    |    |    |    |-- title: string (nullable = true)\n",
                        " |    |    |    |    |    |-- user_id: string (nullable = true)\n",
                        " |    |    |    |    |    |-- web_slug: string (nullable = true)\n",
                        " |    |    |    |-- order: string (nullable = true)\n",
                        " |    |    |    |-- title: string (nullable = true)\n",
                        " |    |    |-- type: string (nullable = true)\n",
                        " |    |-- tracking: struct (nullable = true)\n",
                        " |    |    |-- location: struct (nullable = true)\n",
                        " |    |    |    |-- country_code: string (nullable = true)\n",
                        " |    |    |    |-- latitude: double (nullable = true)\n",
                        " |    |    |    |-- longitude: double (nullable = true)\n",
                        " |    |    |-- variant: string (nullable = true)\n",
                        " |-- meta: struct (nullable = true)\n",
                        " |    |-- next_page: string (nullable = true)\n",
                        " |    |-- next_section_type: string (nullable = true)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.printSchema()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora, para navegar a través de nuestro fichero JSON, podemos utilizar la sintáxis por puntos; es decir, para obtener el campo deseado `\"items\"`, que contiene la información de todos los productos, debemos acceder mediante `data.section.payload.items`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|                                                                                               items|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|[{{none}, 24200, 1727815730476, FLATRON L-194LW-SF. Como nuevo. Funcionando  perfectamente. Prueb...|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.select(\"data.section.payload.items\").show(truncate=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sin embargo, seguimos sin apreciar una estructura legible. Esto es porque se nos está mostrando un único registro (fila) que contiene toda la información de los productos. Lo que nos interesa es que cada elemento de esta lista se muestre en un registro a parte. Para ello se utiliza la función SQL `explode`, que coge un array de elementos y devuelve un registro por cada uno de esos elementos. Veámoslo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|                                                                                                 col|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|{{none}, 24200, 1727815730476, FLATRON L-194LW-SF. Como nuevo. Funcionando  perfectamente. Prueba...|\n",
                        "|{{none}, 24200, 1727776756838, 13 pulgadas usado muy poco. incluye cable mini hdmi. Funciona perf...|\n",
                        "|{{none}, 24200, 1727808065598, Hola vendo portátil con cargador la batería no dura mucho mejor ve...|\n",
                        "|{{none}, 24200, 1727795035144, Impresora instantánea portátil. No necesita tinta, es térmica. Se ...|\n",
                        "|{{none}, 24200, 1727817565933, Portátil Asus X555Q, procesador AMD A12 9700 (4x2.5ghz), tarjeta g...|\n",
                        "|{{none}, 24200, 1727817173345, Nuevo sin uso apenas unas horas,regalo para niño sin usar.Ordenado...|\n",
                        "|{{none}, 24200, 1727816433783, Ordenador portatil morado marca hp con su cargador , NULL, {false}...|\n",
                        "|{{none}, 24200, 1727818970579, Completamente nuevos a estrenar. Disponibles en color plata y gris...|\n",
                        "|{{none}, 24200, 1727803255106, Cargador original de Portátil Acer Extense.\\nCompatible con otros ...|\n",
                        "|{{none}, 24200, 1727805066181, Batería para portátil , NULL, {false}, e6582rqkmp6o, [{13C1AC, {ht...|\n",
                        "|{{none}, 24200, 1727804328171, ordenador en miy buen estado, practicamente sin usar, NULL, {false...|\n",
                        "|{{none}, 24200, 1727773791138, Pantalla para portátil sin anclajes de 15,6 HD nueva, NULL, {false...|\n",
                        "|{{none}, 24200, 1727802803659, No se si funciona, no viene con cargador, no va con el disco que s...|\n",
                        "|{{none}, 24200, 1727820410371, Portátil LENOVO 81WQ Intel Celeron N4020, 1.10 GHZ Ram 8GB Windows...|\n",
                        "|{{none}, 24200, 1727800915406, Bateria portatil con USB tipo C. Esta nueva, la compre pero no me ...|\n",
                        "|{{none}, 24200, 1727800578367, Especificaciones HP ProBook 450 G8\\n\\nProcesador Intel® Core™ i5-1...|\n",
                        "|{{none}, 24200, 1727800795669, en muy buen estado y con cargador, NULL, {false}, mzn2me81pyzn, [{...|\n",
                        "|{{none}, 24200, 1727795708150, Ordenador portátil ASUS con cargador con las siguientes caracterís...|\n",
                        "|{{none}, 24200, 1727717063941, La calidad de impresión es decente con un texto claro oscuro e imp...|\n",
                        "|{{none}, 24200, 1727797940836, Original funda para portátil. \\nMedidas: 29x39 cm, NULL, {false}, ...|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "only showing top 20 rows\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.select(f.explode(\"data.section.payload.items\")).show(truncate=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Bien, ya hemos avanzado, disponemos ahora de un registro por cada producto de la lista `items`, como queríamos. Sin embargo, se sigue mostrando toda la información en una misma columna. Eso lo solucionamos seleccionando los campos anidados deseados. Por ejemplo, supongamos que queremos coger el `id` del producto, el `user_id` del usuario y la fecha de creación del anuncio `created_at`. Una buena manera de operar sería crear una nueva columna llamada, por ejemplo, `\"data\"`, que contenga los registros explotados del campo de `\"items\"`, y luego utilizar este nuevo campo para obtener la info de los otros campos descendientes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>user_id</th><th>created_at</th></tr>\n",
                            "<tr><td>9jdk4mmm7n6k</td><td>pj9ydq0n026e</td><td>1727815730476</td></tr>\n",
                            "<tr><td>pzp23woo99j3</td><td>k3zlkgn2o26x</td><td>1727776756838</td></tr>\n",
                            "<tr><td>p6141e5nkx65</td><td>3zlgmk2ggnjx</td><td>1727808065598</td></tr>\n",
                            "<tr><td>36e1gowdeyjd</td><td>8ejke1oymrjx</td><td>1727795035144</td></tr>\n",
                            "<tr><td>8z8k9revldz3</td><td>pzpy3k9em9z3</td><td>1727817565933</td></tr>\n",
                            "<tr><td>8z8k9rrmo1z3</td><td>9nz0mvneq7jo</td><td>1727817173345</td></tr>\n",
                            "<tr><td>nz04x22l73jo</td><td>e65yy53okpjo</td><td>1727816433783</td></tr>\n",
                            "<tr><td>x6qm2nw42yjy</td><td>4w6744pq156x</td><td>1727818970579</td></tr>\n",
                            "<tr><td>qzme1ve5lojv</td><td>436epk2ek8jd</td><td>1727803255106</td></tr>\n",
                            "<tr><td>e6582rqkmp6o</td><td>mxzor1kq15z9</td><td>1727805066181</td></tr>\n",
                            "<tr><td>xzo2odg37w69</td><td>wzvyyp7m17zl</td><td>1727804328171</td></tr>\n",
                            "<tr><td>qzme1pwrpojv</td><td>36ewe8xp0n6d</td><td>1727773791138</td></tr>\n",
                            "<tr><td>e6582r8llm6o</td><td>36ewne5w0n6d</td><td>1727802803659</td></tr>\n",
                            "<tr><td>vjrqvpx304zk</td><td>pj9yn8g3oo6e</td><td>1727820410371</td></tr>\n",
                            "<tr><td>8j34o2ew1269</td><td>ejk44lry0pzx</td><td>1727800915406</td></tr>\n",
                            "<tr><td>e6582rgdxp6o</td><td>mxzo8dldr569</td><td>1727800578367</td></tr>\n",
                            "<tr><td>mzn2me81pyzn</td><td>qnzx0l7d9mz2</td><td>1727800795669</td></tr>\n",
                            "<tr><td>wzv4vky037zl</td><td>9jd7nygoenjk</td><td>1727795708150</td></tr>\n",
                            "<tr><td>wzv4vqy7nrzl</td><td>dqjwyqre1gzo</td><td>1727717063941</td></tr>\n",
                            "<tr><td>ejk8wd9egrjx</td><td>g0j2ev557vjy</td><td>1727797940836</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+------------+-------------+\n",
                            "|          id|     user_id|   created_at|\n",
                            "+------------+------------+-------------+\n",
                            "|9jdk4mmm7n6k|pj9ydq0n026e|1727815730476|\n",
                            "|pzp23woo99j3|k3zlkgn2o26x|1727776756838|\n",
                            "|p6141e5nkx65|3zlgmk2ggnjx|1727808065598|\n",
                            "|36e1gowdeyjd|8ejke1oymrjx|1727795035144|\n",
                            "|8z8k9revldz3|pzpy3k9em9z3|1727817565933|\n",
                            "|8z8k9rrmo1z3|9nz0mvneq7jo|1727817173345|\n",
                            "|nz04x22l73jo|e65yy53okpjo|1727816433783|\n",
                            "|x6qm2nw42yjy|4w6744pq156x|1727818970579|\n",
                            "|qzme1ve5lojv|436epk2ek8jd|1727803255106|\n",
                            "|e6582rqkmp6o|mxzor1kq15z9|1727805066181|\n",
                            "|xzo2odg37w69|wzvyyp7m17zl|1727804328171|\n",
                            "|qzme1pwrpojv|36ewe8xp0n6d|1727773791138|\n",
                            "|e6582r8llm6o|36ewne5w0n6d|1727802803659|\n",
                            "|vjrqvpx304zk|pj9yn8g3oo6e|1727820410371|\n",
                            "|8j34o2ew1269|ejk44lry0pzx|1727800915406|\n",
                            "|e6582rgdxp6o|mxzo8dldr569|1727800578367|\n",
                            "|mzn2me81pyzn|qnzx0l7d9mz2|1727800795669|\n",
                            "|wzv4vky037zl|9jd7nygoenjk|1727795708150|\n",
                            "|wzv4vqy7nrzl|dqjwyqre1gzo|1727717063941|\n",
                            "|ejk8wd9egrjx|g0j2ev557vjy|1727797940836|\n",
                            "+------------+------------+-------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "wallapop.withColumn(\"data\", f.explode(\"data.section.payload.items\")).select(\n",
                "    \"data.id\", \"data.user_id\", \"data.created_at\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fenomenal. Ahora, siguiendo esta misma operación, obtendremos un dataset completo tabular de los campos del JSON más relevantes. Observemos que para todos los campos seleccionados, se hace una conversión de tipos (método `cast`) y se asigna un alias (método `alias`). Esto es para que la tabla resultante sea consistente, y tenga siempre el mismo esquema de salida.\n",
                "\n",
                "Notemos también que a campos que representan fechas pero se muestran como números enteros (milisegundos desde 1970, esto se conoce como UNIX time), como `created_at` o `modified_at`, les aplicamos una conversión mediante la función `from_unixtime` para representarlos como una fecha legible"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- id: string (nullable = true)\n",
                        " |-- title: string (nullable = true)\n",
                        " |-- user_id: string (nullable = true)\n",
                        " |-- category_id: integer (nullable = true)\n",
                        " |-- created_at: timestamp (nullable = true)\n",
                        " |-- modified_at: timestamp (nullable = true)\n",
                        " |-- description: string (nullable = true)\n",
                        " |-- favorited: boolean (nullable = true)\n",
                        " |-- is_favoriteable: boolean (nullable = true)\n",
                        " |-- is_refurbished: boolean (nullable = true)\n",
                        " |-- latitude: double (nullable = true)\n",
                        " |-- longitude: double (nullable = true)\n",
                        " |-- postal_code: string (nullable = true)\n",
                        " |-- city: string (nullable = true)\n",
                        " |-- region: string (nullable = true)\n",
                        " |-- region2: string (nullable = true)\n",
                        " |-- country_code: string (nullable = true)\n",
                        " |-- amount: double (nullable = true)\n",
                        " |-- currency: string (nullable = true)\n",
                        " |-- reserved: string (nullable = true)\n",
                        " |-- item_is_shippable: boolean (nullable = true)\n",
                        " |-- user_allows_shipping: boolean (nullable = true)\n",
                        " |-- __timestamp: timestamp (nullable = false)\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>title</th><th>user_id</th><th>category_id</th><th>created_at</th><th>modified_at</th><th>description</th><th>favorited</th><th>is_favoriteable</th><th>is_refurbished</th><th>latitude</th><th>longitude</th><th>postal_code</th><th>city</th><th>region</th><th>region2</th><th>country_code</th><th>amount</th><th>currency</th><th>reserved</th><th>item_is_shippable</th><th>user_allows_shipping</th><th>__timestamp</th></tr>\n",
                            "<tr><td>9jdk4mmm7n6k</td><td>Monitor LG de 19&quot; para Portatil/Pc</td><td>pj9ydq0n026e</td><td>24200</td><td>2024-10-01 22:48:50</td><td>2024-10-01 23:02:05</td><td>FLATRON L-194LW-SF. Como nuevo. Funcionando  perfectamente. Prueba real a doble pantalla en porta...</td><td>false</td><td>true</td><td>false</td><td>40.42311172329895</td><td>-3.65551552224851</td><td>28028</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>55.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>pzp23woo99j3</td><td>Monitor portatil</td><td>k3zlkgn2o26x</td><td>24200</td><td>2024-10-01 11:59:16</td><td>2024-10-01 11:59:26</td><td>13 pulgadas usado muy poco. incluye cable mini hdmi. Funciona perfectamente. Hago envios wallapop. </td><td>false</td><td>true</td><td>false</td><td>40.59448299258544</td><td>-3.4906866475115046</td><td>28110</td><td>Algete</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>65.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>p6141e5nkx65</td><td>Port&aacute;til</td><td>3zlgmk2ggnjx</td><td>24200</td><td>2024-10-01 20:41:05</td><td>2024-10-01 20:41:15</td><td>Hola vendo port&aacute;til con cargador la bater&iacute;a no dura mucho mejor ver un saludo</td><td>false</td><td>true</td><td>false</td><td>40.3636519022605</td><td>-3.723264264097807</td><td>28041</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>40.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>36e1gowdeyjd</td><td>Impresora instant&aacute;nea port&aacute;til fotos y etiquetas</td><td>8ejke1oymrjx</td><td>24200</td><td>2024-10-01 17:03:55</td><td>2024-10-01 17:04:05</td><td>Impresora instant&aacute;nea port&aacute;til. No necesita tinta, es t&eacute;rmica. Se pueden imprimir fotos y etiquet...</td><td>false</td><td>true</td><td>false</td><td>40.398622719522706</td><td>-3.7328175811627995</td><td>28019</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>13.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>8z8k9revldz3</td><td>Port&aacute;til Asus</td><td>pzpy3k9em9z3</td><td>24200</td><td>2024-10-01 23:19:25</td><td>2024-10-01 23:19:36</td><td>Port&aacute;til Asus X555Q, procesador AMD A12 9700 (4x2.5ghz), tarjeta gr&aacute;fica Radeon R7 1gb dedicado, ...</td><td>false</td><td>true</td><td>false</td><td>40.39559819840811</td><td>-3.607382424871634</td><td>28032</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>170.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>8z8k9rrmo1z3</td><td>Ordenador port&aacute;til </td><td>9nz0mvneq7jo</td><td>24200</td><td>2024-10-01 23:12:53</td><td>2024-10-01 23:13:03</td><td>Nuevo sin uso apenas unas horas,regalo para ni&ntilde;o sin usar.Ordenador Chuwi potente y r&aacute;pido Almace...</td><td>false</td><td>true</td><td>false</td><td>40.33770830097314</td><td>-3.7815546218248604</td><td>28918</td><td>Legan&eacute;s</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>225.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>nz04x22l73jo</td><td>ORDENADOR PORTATIL </td><td>e65yy53okpjo</td><td>24200</td><td>2024-10-01 23:00:33</td><td>2024-10-01 23:01:15</td><td>Ordenador portatil morado marca hp con su cargador </td><td>false</td><td>true</td><td>false</td><td>40.58392659912069</td><td>-3.9984050529940465</td><td>28260</td><td>Galapagar</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>200.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>x6qm2nw42yjy</td><td>Base Plegable para port&aacute;til</td><td>4w6744pq156x</td><td>24200</td><td>2024-10-01 23:42:50</td><td>2024-10-01 23:43:00</td><td>Completamente nuevos a estrenar. Disponibles en color plata y gris espacial.\\n\\nIdeal para mejora...</td><td>false</td><td>true</td><td>false</td><td>40.289204</td><td>-3.819584</td><td>28943</td><td>Fuenlabrada</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>12.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>qzme1ve5lojv</td><td>Cargador port&aacute;til </td><td>436epk2ek8jd</td><td>24200</td><td>2024-10-01 19:20:55</td><td>2024-10-01 19:21:05</td><td>Cargador original de Port&aacute;til Acer Extense.\\nCompatible con otros modelos </td><td>false</td><td>true</td><td>false</td><td>40.389077633884696</td><td>-3.7438077768118725</td><td>28047</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>10.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>e6582rqkmp6o</td><td>Bater&iacute;a para port&aacute;til </td><td>mxzor1kq15z9</td><td>24200</td><td>2024-10-01 19:51:06</td><td>2024-10-01 19:53:39</td><td>Bater&iacute;a para port&aacute;til </td><td>false</td><td>true</td><td>false</td><td>40.64775661487887</td><td>-3.7868335211563586</td><td>28770</td><td>Colmenar Viejo</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>20.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>xzo2odg37w69</td><td>Ordenador portatil</td><td>wzvyyp7m17zl</td><td>24200</td><td>2024-10-01 19:38:48</td><td>2024-10-01 19:38:58</td><td>ordenador en miy buen estado, practicamente sin usar</td><td>false</td><td>true</td><td>false</td><td>40.50977987302981</td><td>-3.890518419009281</td><td>28230</td><td>Las Rozas de Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>150.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>qzme1pwrpojv</td><td>Pantalla para port&aacute;til sin anclajes de 15,6 HD</td><td>36ewe8xp0n6d</td><td>24200</td><td>2024-10-01 11:09:51</td><td>2024-10-01 11:12:13</td><td>Pantalla para port&aacute;til sin anclajes de 15,6 HD nueva</td><td>false</td><td>true</td><td>false</td><td>40.45644037219361</td><td>-3.703880905073141</td><td>28020</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>20.0</td><td>EUR</td><td>true</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>e6582r8llm6o</td><td>DAD portatil</td><td>36ewne5w0n6d</td><td>24200</td><td>2024-10-01 19:13:23</td><td>2024-10-01 19:13:38</td><td>No se si funciona, no viene con cargador, no va con el disco que se ve en las fotos.</td><td>false</td><td>true</td><td>false</td><td>40.37293760915915</td><td>-3.5927043753672905</td><td>28031</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>20.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>vjrqvpx304zk</td><td>Port&aacute;til LENOVO 81WQ</td><td>pj9yn8g3oo6e</td><td>24200</td><td>2024-10-02 00:06:50</td><td>2024-10-02 00:07:00</td><td>Port&aacute;til LENOVO 81WQ Intel Celeron N4020, 1.10 GHZ Ram 8GB Windows 11 home. Con apertura de panta...</td><td>false</td><td>true</td><td>false</td><td>40.13497708386232</td><td>-3.8453300549424254</td><td>45200</td><td>Illescas</td><td>Castilla-La Mancha</td><td>Toledo</td><td>ES</td><td>205.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>8j34o2ew1269</td><td>Bateria portatil </td><td>ejk44lry0pzx</td><td>24200</td><td>2024-10-01 18:41:55</td><td>2024-10-01 18:42:05</td><td>Bateria portatil con USB tipo C. Esta nueva, la compre pero no me vale puesto que mi iPhone no ti...</td><td>false</td><td>true</td><td>false</td><td>40.35015184751012</td><td>-3.8190701588517504</td><td>28924</td><td>Alcorc&oacute;n</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>23.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>e6582rgdxp6o</td><td>Portatil HP</td><td>mxzo8dldr569</td><td>24200</td><td>2024-10-01 18:36:18</td><td>2024-10-01 18:36:28</td><td>Especificaciones HP ProBook 450 G8\\n\\nProcesador Intel&reg; Core&trade; i5-1135G7 (4 n&uacute;cleos, hasta 4.2 GHz...</td><td>false</td><td>true</td><td>false</td><td>40.548974218889356</td><td>-3.6485371906748405</td><td>28100</td><td>Alcobendas</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>500.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>mzn2me81pyzn</td><td>portatil hp</td><td>qnzx0l7d9mz2</td><td>24200</td><td>2024-10-01 18:39:55</td><td>2024-10-01 18:40:05</td><td>en muy buen estado y con cargador</td><td>false</td><td>true</td><td>false</td><td>40.455373578732555</td><td>-3.4607000547694713</td><td>28851</td><td>Mercado Parque Corredor del Henares</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>50.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>wzv4vky037zl</td><td>Portatil</td><td>9jd7nygoenjk</td><td>24200</td><td>2024-10-01 17:15:08</td><td>2024-10-01 17:15:18</td><td>Ordenador port&aacute;til ASUS con cargador con las siguientes caracter&iacute;sticas:4GB Ram DDR3,AMD E1-7010 ...</td><td>false</td><td>true</td><td>false</td><td>39.96758716719902</td><td>-4.83254988037358</td><td>45600</td><td>Talavera de la Reina</td><td>Castilla-La Mancha</td><td>Toledo</td><td>ES</td><td>250.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>wzv4vqy7nrzl</td><td>Impresora port&aacute;til</td><td>dqjwyqre1gzo</td><td>24200</td><td>2024-09-30 19:24:23</td><td>2024-10-01 18:26:14</td><td>La calidad de impresi&oacute;n es decente con un texto claro oscuro e impermeable legiblemente en archiv...</td><td>false</td><td>true</td><td>false</td><td>40.0866331</td><td>-3.8630442</td><td>45210</td><td>Yuncos</td><td>Castilla-La Mancha</td><td>Toledo</td><td>ES</td><td>119.99</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "<tr><td>ejk8wd9egrjx</td><td>Funda para port&aacute;til</td><td>g0j2ev557vjy</td><td>24200</td><td>2024-10-01 17:52:20</td><td>2024-10-01 17:52:31</td><td>Original funda para port&aacute;til. \\nMedidas: 29x39 cm</td><td>false</td><td>true</td><td>false</td><td>40.3196648025162</td><td>-3.7302172522495054</td><td>28907</td><td>Getafe</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>5.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-10-02 00:43:09.094205</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+------------------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------------------------+-------------------+-------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "|          id|                                           title|     user_id|category_id|         created_at|        modified_at|                                                                                         description|favorited|is_favoriteable|is_refurbished|          latitude|          longitude|postal_code|                               city|             region|region2|country_code|amount|currency|reserved|item_is_shippable|user_allows_shipping|               __timestamp|\n",
                            "+------------+------------------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------------------------+-------------------+-------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "|9jdk4mmm7n6k|              Monitor LG de 19\" para Portatil/Pc|pj9ydq0n026e|      24200|2024-10-01 22:48:50|2024-10-01 23:02:05|FLATRON L-194LW-SF. Como nuevo. Funcionando  perfectamente. Prueba real a doble pantalla en porta...|    false|           true|         false| 40.42311172329895|  -3.65551552224851|      28028|                             Madrid|Comunidad de Madrid| Madrid|          ES|  55.0|     EUR|   false|             true|               false|2024-10-02 00:43:08.767394|\n",
                            "|pzp23woo99j3|                                Monitor portatil|k3zlkgn2o26x|      24200|2024-10-01 11:59:16|2024-10-01 11:59:26| 13 pulgadas usado muy poco. incluye cable mini hdmi. Funciona perfectamente. Hago envios wallapop. |    false|           true|         false| 40.59448299258544|-3.4906866475115046|      28110|                             Algete|Comunidad de Madrid| Madrid|          ES|  65.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|p6141e5nkx65|                                        Portátil|3zlgmk2ggnjx|      24200|2024-10-01 20:41:05|2024-10-01 20:41:15|                       Hola vendo portátil con cargador la batería no dura mucho mejor ver un saludo|    false|           true|         false|  40.3636519022605| -3.723264264097807|      28041|                             Madrid|Comunidad de Madrid| Madrid|          ES|  40.0|     EUR|   false|             true|               false|2024-10-02 00:43:08.767394|\n",
                            "|36e1gowdeyjd|Impresora instantánea portátil fotos y etiquetas|8ejke1oymrjx|      24200|2024-10-01 17:03:55|2024-10-01 17:04:05|Impresora instantánea portátil. No necesita tinta, es térmica. Se pueden imprimir fotos y etiquet...|    false|           true|         false|40.398622719522706|-3.7328175811627995|      28019|                             Madrid|Comunidad de Madrid| Madrid|          ES|  13.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|8z8k9revldz3|                                   Portátil Asus|pzpy3k9em9z3|      24200|2024-10-01 23:19:25|2024-10-01 23:19:36|Portátil Asus X555Q, procesador AMD A12 9700 (4x2.5ghz), tarjeta gráfica Radeon R7 1gb dedicado, ...|    false|           true|         false| 40.39559819840811| -3.607382424871634|      28032|                             Madrid|Comunidad de Madrid| Madrid|          ES| 170.0|     EUR|   false|             true|               false|2024-10-02 00:43:08.767394|\n",
                            "|8z8k9rrmo1z3|                             Ordenador portátil |9nz0mvneq7jo|      24200|2024-10-01 23:12:53|2024-10-01 23:13:03|Nuevo sin uso apenas unas horas,regalo para niño sin usar.Ordenador Chuwi potente y rápido Almace...|    false|           true|         false| 40.33770830097314|-3.7815546218248604|      28918|                            Leganés|Comunidad de Madrid| Madrid|          ES| 225.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|nz04x22l73jo|                             ORDENADOR PORTATIL |e65yy53okpjo|      24200|2024-10-01 23:00:33|2024-10-01 23:01:15|                                                 Ordenador portatil morado marca hp con su cargador |    false|           true|         false| 40.58392659912069|-3.9984050529940465|      28260|                          Galapagar|Comunidad de Madrid| Madrid|          ES| 200.0|     EUR|   false|             true|               false|2024-10-02 00:43:08.767394|\n",
                            "|x6qm2nw42yjy|                     Base Plegable para portátil|4w6744pq156x|      24200|2024-10-01 23:42:50|2024-10-01 23:43:00|Completamente nuevos a estrenar. Disponibles en color plata y gris espacial.\\n\\nIdeal para mejora...|    false|           true|         false|         40.289204|          -3.819584|      28943|                        Fuenlabrada|Comunidad de Madrid| Madrid|          ES|  12.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|qzme1ve5lojv|                              Cargador portátil |436epk2ek8jd|      24200|2024-10-01 19:20:55|2024-10-01 19:21:05|                          Cargador original de Portátil Acer Extense.\\nCompatible con otros modelos |    false|           true|         false|40.389077633884696|-3.7438077768118725|      28047|                             Madrid|Comunidad de Madrid| Madrid|          ES|  10.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|e6582rqkmp6o|                          Batería para portátil |mxzor1kq15z9|      24200|2024-10-01 19:51:06|2024-10-01 19:53:39|                                                                              Batería para portátil |    false|           true|         false| 40.64775661487887|-3.7868335211563586|      28770|                     Colmenar Viejo|Comunidad de Madrid| Madrid|          ES|  20.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|xzo2odg37w69|                              Ordenador portatil|wzvyyp7m17zl|      24200|2024-10-01 19:38:48|2024-10-01 19:38:58|                                                ordenador en miy buen estado, practicamente sin usar|    false|           true|         false| 40.50977987302981| -3.890518419009281|      28230|                Las Rozas de Madrid|Comunidad de Madrid| Madrid|          ES| 150.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|qzme1pwrpojv|  Pantalla para portátil sin anclajes de 15,6 HD|36ewe8xp0n6d|      24200|2024-10-01 11:09:51|2024-10-01 11:12:13|                                                Pantalla para portátil sin anclajes de 15,6 HD nueva|    false|           true|         false| 40.45644037219361| -3.703880905073141|      28020|                             Madrid|Comunidad de Madrid| Madrid|          ES|  20.0|     EUR|    true|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|e6582r8llm6o|                                    DAD portatil|36ewne5w0n6d|      24200|2024-10-01 19:13:23|2024-10-01 19:13:38|                No se si funciona, no viene con cargador, no va con el disco que se ve en las fotos.|    false|           true|         false| 40.37293760915915|-3.5927043753672905|      28031|                             Madrid|Comunidad de Madrid| Madrid|          ES|  20.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|vjrqvpx304zk|                            Portátil LENOVO 81WQ|pj9yn8g3oo6e|      24200|2024-10-02 00:06:50|2024-10-02 00:07:00|Portátil LENOVO 81WQ Intel Celeron N4020, 1.10 GHZ Ram 8GB Windows 11 home. Con apertura de panta...|    false|           true|         false| 40.13497708386232|-3.8453300549424254|      45200|                           Illescas| Castilla-La Mancha| Toledo|          ES| 205.0|     EUR|   false|             true|               false|2024-10-02 00:43:08.767394|\n",
                            "|8j34o2ew1269|                               Bateria portatil |ejk44lry0pzx|      24200|2024-10-01 18:41:55|2024-10-01 18:42:05|Bateria portatil con USB tipo C. Esta nueva, la compre pero no me vale puesto que mi iPhone no ti...|    false|           true|         false| 40.35015184751012|-3.8190701588517504|      28924|                           Alcorcón|Comunidad de Madrid| Madrid|          ES|  23.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|e6582rgdxp6o|                                     Portatil HP|mxzo8dldr569|      24200|2024-10-01 18:36:18|2024-10-01 18:36:28|Especificaciones HP ProBook 450 G8\\n\\nProcesador Intel® Core™ i5-1135G7 (4 núcleos, hasta 4.2 GHz...|    false|           true|         false|40.548974218889356|-3.6485371906748405|      28100|                         Alcobendas|Comunidad de Madrid| Madrid|          ES| 500.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|mzn2me81pyzn|                                     portatil hp|qnzx0l7d9mz2|      24200|2024-10-01 18:39:55|2024-10-01 18:40:05|                                                                   en muy buen estado y con cargador|    false|           true|         false|40.455373578732555|-3.4607000547694713|      28851|Mercado Parque Corredor del Henares|Comunidad de Madrid| Madrid|          ES|  50.0|     EUR|   false|             true|               false|2024-10-02 00:43:08.767394|\n",
                            "|wzv4vky037zl|                                        Portatil|9jd7nygoenjk|      24200|2024-10-01 17:15:08|2024-10-01 17:15:18|Ordenador portátil ASUS con cargador con las siguientes características:4GB Ram DDR3,AMD E1-7010 ...|    false|           true|         false| 39.96758716719902|  -4.83254988037358|      45600|               Talavera de la Reina| Castilla-La Mancha| Toledo|          ES| 250.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|wzv4vqy7nrzl|                              Impresora portátil|dqjwyqre1gzo|      24200|2024-09-30 19:24:23|2024-10-01 18:26:14|La calidad de impresión es decente con un texto claro oscuro e impermeable legiblemente en archiv...|    false|           true|         false|        40.0866331|         -3.8630442|      45210|                             Yuncos| Castilla-La Mancha| Toledo|          ES|119.99|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "|ejk8wd9egrjx|                             Funda para portátil|g0j2ev557vjy|      24200|2024-10-01 17:52:20|2024-10-01 17:52:31|                                                   Original funda para portátil. \\nMedidas: 29x39 cm|    false|           true|         false|  40.3196648025162|-3.7302172522495054|      28907|                             Getafe|Comunidad de Madrid| Madrid|          ES|   5.0|     EUR|   false|             true|                true|2024-10-02 00:43:08.767394|\n",
                            "+------------+------------------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------------------------+-------------------+-------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "wallapop = (\n",
                "    spark.read.json(\"data/wallapop.json\", multiLine=True, primitivesAsString=True)\n",
                "    .withColumn(\"data\", f.explode(\"data.section.payload.items\"))\n",
                "    .select(\n",
                "        f.col(\"data.id\").cast(\"string\").alias(\"id\"),\n",
                "        f.col(\"data.title\").cast(\"string\").alias(\"title\"),\n",
                "        f.col(\"data.user_id\").cast(\"string\").alias(\"user_id\"),\n",
                "        f.col(\"data.category_id\").cast(\"int\").alias(\"category_id\"),\n",
                "        f.from_unixtime((f.col(\"data.created_at\") / 1000))\n",
                "        .cast(\"timestamp\")\n",
                "        .alias(\"created_at\"),\n",
                "        f.from_unixtime(f.col(\"data.modified_at\") / 1000)\n",
                "        .cast(\"timestamp\")\n",
                "        .alias(\"modified_at\"),\n",
                "        f.col(\"data.description\").cast(\"string\").alias(\"description\"),\n",
                "        f.col(\"data.favorited.flag\").cast(\"boolean\").alias(\"favorited\"),\n",
                "        f.col(\"data.is_favoriteable.flag\").cast(\"boolean\").alias(\"is_favoriteable\"),\n",
                "        f.col(\"data.is_refurbished.flag\").cast(\"boolean\").alias(\"is_refurbished\"),\n",
                "        f.col(\"data.location.latitude\").cast(\"double\").alias(\"latitude\"),\n",
                "        f.col(\"data.location.longitude\").cast(\"double\").alias(\"longitude\"),\n",
                "        f.col(\"data.location.postal_code\").cast(\"string\").alias(\"postal_code\"),\n",
                "        f.col(\"data.location.city\").cast(\"string\").alias(\"city\"),\n",
                "        f.col(\"data.location.region\").cast(\"string\").alias(\"region\"),\n",
                "        f.col(\"data.location.region2\").cast(\"string\").alias(\"region2\"),\n",
                "        f.col(\"data.location.country_code\").cast(\"string\").alias(\"country_code\"),\n",
                "        f.col(\"data.price.amount\").cast(\"double\").alias(\"amount\"),\n",
                "        f.col(\"data.price.currency\").cast(\"string\").alias(\"currency\"),\n",
                "        f.col(\"data.reserved.flag\").alias(\"reserved\"),\n",
                "        f.col(\"data.shipping.item_is_shippable\")\n",
                "        .cast(\"boolean\")\n",
                "        .alias(\"item_is_shippable\"),\n",
                "        f.col(\"data.shipping.user_allows_shipping\")\n",
                "        .cast(\"boolean\")\n",
                "        .alias(\"user_allows_shipping\"),\n",
                "        f.current_timestamp().alias(\"__timestamp\"),\n",
                "    )\n",
                ")\n",
                "wallapop.printSchema()\n",
                "display(wallapop)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Genial, ya hemos leído y transformado nuestro set de datos inicialmente desestructurado en una tabla bien estructurada, con unos campos y tipos fijados.\n",
                "\n",
                "Ahora, para completar la ETL, almacenaremos esta tabla en el catálogo de datos de Spark. En este caso, al estar trabajando de manera local, dicho catálogo de datos estará localizado en esta misma ruta (`metastore_db/`, `spark-warehouse/`, `derby.log`), sin embargo, cuando trabajemos en un entorno corporativo, habitualmente el catálogo de datos se alojará en una arquitectura cloud, como AWS, Azure, GCP, Databricks, etc.\n",
                "\n",
                "Aunque no es necesario, es una buena práctica crear en primera instancia la tabla Delta sobre la que escribiremos nuestro dataset, con un schema concreto, metadatos, etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/02 00:43:09 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
                        "24/10/02 00:43:09 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
                        "24/10/02 00:43:11 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
                        "24/10/02 00:43:11 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore dadiego@127.0.1.1\n",
                        "24/10/02 00:43:11 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
                        "24/10/02 00:43:12 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`default`.`wallapop` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
                        "24/10/02 00:43:12 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
                        "24/10/02 00:43:12 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
                        "24/10/02 00:43:12 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
                        "24/10/02 00:43:12 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
                    ]
                }
            ],
            "source": [
                "dt = (\n",
                "    DeltaTable.createIfNotExists(spark)\n",
                "    .addColumns(wallapop.schema)\n",
                "    .tableName(\"wallapop\")\n",
                "    .comment(\"Tabla de productos de Wallapop\")\n",
                "    .execute()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Con el método `createIfNotExists` estamos indicando que cree únicamente la tabla en el catálogo de datos si esta no existía previamente.\n",
                "\n",
                "Una vez creada la tabla, insertaremos los datos de nuestro DataFrame mediante una operación `merge`. Para ello, identificamos en primer lugar cuáles son los campos que consituyen una clave primaria en la tabla, es decir, un identificador único de cada registro. En este caso, podríamos utilizar por ejemplo la combinación `\"id\"`, `\"user_id\"`; cuando estos campos coincidan entre la tabla fuente y la tabla destino, actualizaremos los registros en el destino, y cuando no coincidan, insertaremos los registros de la fuente en el destino. Esto lo podemos hacer utilizando los métodos del objeto `DeltaTable` dentro de la librería externa `delta-spark` que tenemos instalada en nuestro entorno virtual de Python."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/02 00:43:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
                        "                                                                                \r"
                    ]
                }
            ],
            "source": [
                "(\n",
                "    dt.alias(\"target\")\n",
                "    .merge(\n",
                "        wallapop.alias(\"source\"),\n",
                "        \"source.id = target.id AND source.user_id = target.user_id\",\n",
                "    )\n",
                "    .whenMatchedUpdateAll()\n",
                "    .whenNotMatchedInsertAll()\n",
                "    .execute()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Cabe mencionar que también podríamos haber creado la tabla directamente a partir del DataFrame de spark, mediante la siguiente instrucción:\n",
                "```\n",
                "wallapop.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"wallapop\")\n",
                "```\n",
                "\n",
                "Ya hemos creado la tabla delta y hemos insertado los registros tabulados de la API de Wallapop en la misma. Ahora podemos consultar el catálogo mediante SQL.\n",
                "\n",
                "Primero, utilizaremos una función auxiliar de nuestro propio paquete de Python creado (`blackops`), llamada `get_detailed_tables_info`, para obtener información detallada de todas las tablas de nuestro catálogo de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/02 00:43:17 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>namespace</th><th>tableName</th><th></th><th>Catalog</th><th>Comment</th><th>Created By</th><th>Created Time</th><th>Database</th><th>InputFormat</th><th>Last Access</th><th>Location</th><th>OutputFormat</th><th>Owner</th><th>Partition Provider</th><th>Provider</th><th>Serde Library</th><th>Table</th><th>Type</th></tr>\n",
                            "<tr><td></td><td>empleados</td><td></td><td>NULL</td><td>NULL</td><td>Spark </td><td>Wed Oct 02 00:42:53 CEST 2024</td><td>NULL</td><td>NULL</td><td>UNKNOWN</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>empleados</td><td>VIEW</td></tr>\n",
                            "<tr><td>default</td><td>wallapop</td><td></td><td>spark_catalog</td><td>Tabla de productos de Wallapop</td><td>Spark 3.5.3</td><td>Wed Oct 02 00:43:12 CEST 2024</td><td>default</td><td>org.apache.hadoop.mapred.SequenceFileInputFormat</td><td>UNKNOWN</td><td>file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...</td><td>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td><td>dadiego</td><td>Catalog</td><td>delta</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td><td>wallapop</td><td>MANAGED</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+\n",
                            "|namespace|tableName|   |      Catalog|                       Comment| Created By|                 Created Time|Database|                                     InputFormat|Last Access|                                                                                            Location|                                             OutputFormat|  Owner|Partition Provider|Provider|                                     Serde Library|    Table|   Type|\n",
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+\n",
                            "|         |empleados|   |         NULL|                          NULL|     Spark |Wed Oct 02 00:42:53 CEST 2024|    NULL|                                            NULL|    UNKNOWN|                                                                                                NULL|                                                     NULL|   NULL|              NULL|    NULL|                                              NULL|empleados|   VIEW|\n",
                            "|  default| wallapop|   |spark_catalog|Tabla de productos de Wallapop|Spark 3.5.3|Wed Oct 02 00:43:12 CEST 2024| default|org.apache.hadoop.mapred.SequenceFileInputFormat|    UNKNOWN|file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...|org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat|dadiego|           Catalog|   delta|org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe| wallapop|MANAGED|\n",
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "get_detailed_tables_info(spark)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos obtener información concreta de nuestra tabla recién creada, `wallapop`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th></tr>\n",
                            "<tr><td>delta</td><td>ac6db2b1-45db-49ab-bb67-587b339f4f62</td><td>spark_catalog.default.wallapop</td><td>Tabla de productos de Wallapop</td><td>file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...</td><td>2024-10-02 00:43:11.7</td><td>2024-10-02 00:43:16.873</td><td>[]</td><td>[]</td><td>1</td><td>15573</td><td>{}</td><td>1</td><td>2</td><td>[appendOnly, invariants]</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+---------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
                            "|format|                                  id|                          name|                   description|                                                                                            location|            createdAt|           lastModified|partitionColumns|clusteringColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|           tableFeatures|\n",
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+---------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
                            "| delta|ac6db2b1-45db-49ab-bb67-587b339f4f62|spark_catalog.default.wallapop|Tabla de productos de Wallapop|file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...|2024-10-02 00:43:11.7|2024-10-02 00:43:16.873|              []|               []|       1|      15573|        {}|               1|               2|[appendOnly, invariants]|\n",
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+---------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dt.detail()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "También podemos obtener una traza histórica de las veces que esta tabla se ha modificado, lo cual es enormemente útil de cara a disponer de un gobierno del dato escalable y robusto"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr>\n",
                            "<tr><td>1</td><td>2024-10-02 00:43:16.873</td><td>NULL</td><td>NULL</td><td>MERGE</td><td>{predicate -&gt; [&quot;((id#906 = id#1212) AND (user_id#908 = user_id#1214))&quot;], matchedPredicates -&gt; [{&quot;...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>0</td><td>Serializable</td><td>false</td><td>{numTargetRowsCopied -&gt; 0, numTargetRowsDeleted -&gt; 0, numTargetFilesAdded -&gt; 1, numTargetBytesAdd...</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.0</td></tr>\n",
                            "<tr><td>0</td><td>2024-10-02 00:43:11.88</td><td>NULL</td><td>NULL</td><td>CREATE TABLE</td><td>{partitionBy -&gt; [], clusterBy -&gt; [], description -&gt; Tabla de productos de Wallapop, isManaged -&gt; ...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>Serializable</td><td>true</td><td>{}</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.0</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
                            "|version|              timestamp|userId|userName|   operation|                                                                                 operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                    operationMetrics|userMetadata|                         engineInfo|\n",
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
                            "|      1|2024-10-02 00:43:16.873|  NULL|    NULL|       MERGE|{predicate -> [\"((id#906 = id#1212) AND (user_id#908 = user_id#1214))\"], matchedPredicates -> [{\"...|NULL|    NULL|     NULL|          0|  Serializable|        false|{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdd...|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.0|\n",
                            "|      0| 2024-10-02 00:43:11.88|  NULL|    NULL|CREATE TABLE|{partitionBy -> [], clusterBy -> [], description -> Tabla de productos de Wallapop, isManaged -> ...|NULL|    NULL|     NULL|       NULL|  Serializable|         true|                                                                                                  {}|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.0|\n",
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dt.history()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vemos como en el histórico aparecen las dos operaciones que hemos ejecutado sobre esta tabla Delta: la operación de creación de la tabla, y la operación de merge para insertar los nuevos datos.\n",
                "\n",
                "Podemos también ejecutar cualquier operación SQL con esta tabla del catálogo. Por ejemplo, veamos una tabla resumen de cuántos productos existen por comunidad y código postal, ordenada de mayor a menor cantidad de productos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>region</th><th>postal_code</th><th>n_products</th></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28047</td><td>3</td></tr>\n",
                            "<tr><td>Castilla-La Mancha</td><td>45200</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28020</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28523</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28770</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28018</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28260</td><td>2</td></tr>\n",
                            "<tr><td>Castilla-La Mancha</td><td>45210</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28921</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28014</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28041</td><td>1</td></tr>\n",
                            "<tr><td>Castilla-La Mancha</td><td>45600</td><td>1</td></tr>\n",
                            "<tr><td>Castilla-La Mancha</td><td>45003</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28110</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28924</td><td>1</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-------------------+-----------+----------+\n",
                            "|             region|postal_code|n_products|\n",
                            "+-------------------+-----------+----------+\n",
                            "|Comunidad de Madrid|      28047|         3|\n",
                            "| Castilla-La Mancha|      45200|         2|\n",
                            "|Comunidad de Madrid|      28020|         2|\n",
                            "|Comunidad de Madrid|      28523|         2|\n",
                            "|Comunidad de Madrid|      28770|         2|\n",
                            "|Comunidad de Madrid|      28018|         2|\n",
                            "|Comunidad de Madrid|      28260|         2|\n",
                            "| Castilla-La Mancha|      45210|         1|\n",
                            "|Comunidad de Madrid|      28921|         1|\n",
                            "|Comunidad de Madrid|      28014|         1|\n",
                            "|Comunidad de Madrid|      28041|         1|\n",
                            "| Castilla-La Mancha|      45600|         1|\n",
                            "| Castilla-La Mancha|      45003|         1|\n",
                            "|Comunidad de Madrid|      28110|         1|\n",
                            "|Comunidad de Madrid|      28924|         1|\n",
                            "+-------------------+-----------+----------+"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "spark.sql(\n",
                "    \"select region, postal_code, count(*) as n_products from wallapop group by region, postal_code order by n_products desc limit 15\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
