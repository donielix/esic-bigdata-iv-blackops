{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introducción\n",
                "En este Notebook aprenderemos las operaciones básicas más utilizadas en PySpark, incluyendo un ejercicio práctico en el que realizaremos una pequeña ETL para extraer unos datos desde una API y los volcaremos en el catálogo de datos de Spark."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Importación de módulos requeridos\n",
                "En primer lugar necesitamos importar las funciones y objetos requeridos para la implementación.\n",
                "\n",
                "- `SparkSession`: objeto necesario para la interacción con la herramienta de Spark a través de Python.\n",
                "- `pyspark.sql.functions`: funciones de SQL que ofrece pyspark, necesarias para las transformaciones de los datos en la ETL.\n",
                "- `fetch_api, save_json`: estas funciones están definidas dentro de nuestra propia librería llamada `blackops`. Contienen el código necesario para extraer y almacenar los datos de la API.\n",
                "- `date, timedelta`: funciones para crear objetos de tipo fecha y timestamp dentro de Python.\n",
                "- `random`: módulo utilizado para la generación de datos aleatorios.\n",
                "- `DeltaTable`: objeto para interaccionar con tablas de tipo Delta. Se trata de un formato ampliamente utilizado en Spark, que ofrece muchas funcionalidades añadidas a nuestro catálogo de datos, como por ejemplo la posibilidad de revertir cambios."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "import pyspark.sql.functions as f\n",
                "from blackops.crawlers.wallapop.functions import fetch_api, save_json\n",
                "from blackops.utils.catalog import get_detailed_tables_info\n",
                "from datetime import date, timedelta\n",
                "import random\n",
                "from delta import DeltaTable"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Establecemos una semilla para la generación de números aleatorios. De esta manera, los resultados serán reproducibles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "random.seed(45)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inicialización de la sesión de Spark\n",
                "\n",
                "Establecemos ahora la comunicación con el motor de Spark desde Python, a través del objeto `SparkSession` de la librería `pyspark`.\n",
                "\n",
                "En este caso de prueba no estamos utilizando un clúster, sino que haremos uso de una arquitectura local. El propio Jupyter Notebook ejercerá como Driver, como Master y como Ejecutor de las tareas.\n",
                "\n",
                "Adicionalmente, estamos instalando dependencias externas como la librería Delta, que incorpora utilidades muy importantes para el manejo de las tablas en nuestro catálogo de datos (histórico de versiones de tablas, omisión de ficheros innecesarios en la lectura, etc.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/09/28 12:32:29 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.1.40 instead (on interface enp3s0)\n",
                        "24/09/28 12:32:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
                        "Ivy Default Cache set to: /home/dadiego/.ivy2/cache\n",
                        "The jars for the packages stored in: /home/dadiego/.ivy2/jars\n",
                        "io.delta#delta-spark_2.12 added as a dependency\n",
                        ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d838f30e-1916-4405-9584-1a550198d467;1.0\n",
                        "\tconfs: [default]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ":: loading settings :: url = jar:file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/.venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
                        "\tfound io.delta#delta-storage;3.2.0 in central\n",
                        "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
                        ":: resolution report :: resolve 108ms :: artifacts dl 3ms\n",
                        "\t:: modules in use:\n",
                        "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
                        "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
                        "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
                        "\t---------------------------------------------------------------------\n",
                        "\t|                  |            modules            ||   artifacts   |\n",
                        "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
                        "\t---------------------------------------------------------------------\n",
                        "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
                        "\t---------------------------------------------------------------------\n",
                        ":: retrieving :: org.apache.spark#spark-submit-parent-d838f30e-1916-4405-9584-1a550198d467\n",
                        "\tconfs: [default]\n",
                        "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
                        "24/09/28 12:32:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
                    ]
                }
            ],
            "source": [
                "spark = (\n",
                "    SparkSession.Builder()\n",
                "    .master(\"local[*]\")\n",
                "    .config(\n",
                "        map={\n",
                "            \"spark.driver.memory\": \"8g\",\n",
                "            \"spark.jars.packages\": \"io.delta:delta-spark_2.12:3.2.0\",\n",
                "            \"spark.sql.extensions\": \"io.delta.sql.DeltaSparkSessionExtension\",\n",
                "            \"spark.sql.catalog.spark_catalog\": \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
                "            \"spark.databricks.delta.retentionDurationCheck.enabled\": \"false\",\n",
                "            \"spark.sql.catalogImplementation\": \"hive\",\n",
                "            \"spark.sql.repl.eagerEval.enabled\": \"true\",\n",
                "            \"spark.sql.repl.eagerEval.truncate\": \"100\",\n",
                "        }\n",
                "    )\n",
                "    .getOrCreate()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez se ha inicializado la sesión, podemos acceder a la web `localhost:4040` para consultar la interfaz de administración que ofrece Spark. Allí, se podrá monitorizar las tareas que se mandan desde el Driver.\n",
                "\n",
                "**Nota**: Si al inicializar la sesión de Spark obtenemos algún error en el que se nos indica que la variable `JAVA_HOME` no existe, lo más probable es que no tengamos instalado Java en nuestro sistema, y necesitamos instalarlo ya que Spark depende de Java para su funcionamiento. Para ello, en Linux podemos utilizar el gestor de paquetes: `sudo apt update && sudo apt install openjdk-17-jdk -y`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Creación de un DataFrame de Spark\n",
                "\n",
                "En Spark podemos crear directamente un Dataframe a partir de una lista de datos, o bien de un Dataframe de pandas. Para ello se puede utilizar el método `spark.createDataFrame`.\n",
                "Debemos especificar tanto los datos como el esquema que tiene el Dataframe (sus columnas y sus tipos).\n",
                "\n",
                "En este caso hacemos uso del paquete `random` para generar datos aleatorios (pero reproducibles, al haber establecido una semilla)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Podemos especificar el esquema del DataFrame usando una cadena de texto\n",
                "schema = \"id INT, nombre STRING, edad INT, salario FLOAT, es_empleado BOOLEAN, fecha_contratacion DATE, departamento STRING\"\n",
                "\n",
                "# Crear una lista de datos ficticios\n",
                "nombres = [\n",
                "    \"Juan\",\n",
                "    \"María\",\n",
                "    \"Pedro\",\n",
                "    \"Ana\",\n",
                "    \"Luis\",\n",
                "    \"Carla\",\n",
                "    \"Miguel\",\n",
                "    \"Sara\",\n",
                "    \"David\",\n",
                "    \"Laura\",\n",
                "]\n",
                "departamentos = [\"Ventas\", \"Marketing\", \"Finanzas\", \"IT\", \"RRHH\"]\n",
                "\n",
                "data = [\n",
                "    (\n",
                "        i,  # id\n",
                "        random.choice(nombres),  # nombre\n",
                "        random.randint(22, 60),  # edad\n",
                "        round(random.uniform(20000, 80000), 2),  # salario\n",
                "        random.choice([True, False]),  # es_empleado\n",
                "        date(2024, 10, 1)\n",
                "        - timedelta(days=random.randint(0, 3650)),  # fecha_contratacion\n",
                "        random.choice(departamentos),  # departamento\n",
                "    )\n",
                "    for i in range(1, 31)  # Genera 30 registros aleatorios\n",
                "]\n",
                "\n",
                "# Crear el DataFrame usando el esquema en string\n",
                "df = spark.createDataFrame(data, schema)\n",
                "\n",
                "# Creamos una vista temporal del DataFrame en el catálogo, para poder hacer consultas en SQL.\n",
                "df.createOrReplaceTempView(\"empleados\")\n",
                "\n",
                "# Mostramos el DataFrame resultante por pantalla\n",
                "display(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Operaciones de transformación\n",
                "\n",
                "La sintaxis de Spark es muy similar a la del lenguaje SQL, de hecho, admite la introducción de comandos SQL para realizar las transformaciones de los datos. Vamos a ver algunas de las operaciones más habituales.\n",
                "\n",
                "### Select\n",
                "\n",
                "La operación más sencilla consiste en seleccionar simplemente un subconjunto de los datos, sin ninguna otra operación de transformación o filtro añadido. Por ejemplo, seleccionemos únicamente los campos `id` y `nombre`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>8</td><td>David</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td></tr>\n",
                            "<tr><td>12</td><td>David</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+\n",
                            "| id|nombre|\n",
                            "+---+------+\n",
                            "|  1|  Luis|\n",
                            "|  2|  Juan|\n",
                            "|  3|  Luis|\n",
                            "|  4| Pedro|\n",
                            "|  5|Miguel|\n",
                            "|  6|  Luis|\n",
                            "|  7| María|\n",
                            "|  8| David|\n",
                            "|  9|  Sara|\n",
                            "| 10|   Ana|\n",
                            "| 11|Miguel|\n",
                            "| 12| David|\n",
                            "| 13| Laura|\n",
                            "| 14| Pedro|\n",
                            "| 15| María|\n",
                            "| 16|  Sara|\n",
                            "| 17|   Ana|\n",
                            "| 18|  Sara|\n",
                            "| 19| María|\n",
                            "| 20| Pedro|\n",
                            "+---+------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.select(\"id\", \"nombre\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Al igual que en SQL estándar, podemos no solo seleccionar unas columnas sino aplicarles alguna función de transformación dentro del propio comando SELECT, y renombrarlas utilizando un alias.\n",
                "\n",
                "Las funciones SQL en Spark están contenidas en el módulo `pyspark.sql.functions`, que hemos importado al principio y lo hemos almacenado en un objeto con alias `f` (por sencillez de uso).\n",
                "\n",
                "Vamos a seleccionar en este caso los mismos campos que en el ejemplo anterior, sin embargo, al campo `nombre` le vamos a aplicar una transformación para visualizar el nombre en mayúsculas, y al resultado lo renombraremos `nombre_en_mayusculas`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre_en_mayusculas</th></tr>\n",
                            "<tr><td>1</td><td>LUIS</td></tr>\n",
                            "<tr><td>2</td><td>JUAN</td></tr>\n",
                            "<tr><td>3</td><td>LUIS</td></tr>\n",
                            "<tr><td>4</td><td>PEDRO</td></tr>\n",
                            "<tr><td>5</td><td>MIGUEL</td></tr>\n",
                            "<tr><td>6</td><td>LUIS</td></tr>\n",
                            "<tr><td>7</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>8</td><td>DAVID</td></tr>\n",
                            "<tr><td>9</td><td>SARA</td></tr>\n",
                            "<tr><td>10</td><td>ANA</td></tr>\n",
                            "<tr><td>11</td><td>MIGUEL</td></tr>\n",
                            "<tr><td>12</td><td>DAVID</td></tr>\n",
                            "<tr><td>13</td><td>LAURA</td></tr>\n",
                            "<tr><td>14</td><td>PEDRO</td></tr>\n",
                            "<tr><td>15</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>16</td><td>SARA</td></tr>\n",
                            "<tr><td>17</td><td>ANA</td></tr>\n",
                            "<tr><td>18</td><td>SARA</td></tr>\n",
                            "<tr><td>19</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>20</td><td>PEDRO</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+--------------------+\n",
                            "| id|nombre_en_mayusculas|\n",
                            "+---+--------------------+\n",
                            "|  1|                LUIS|\n",
                            "|  2|                JUAN|\n",
                            "|  3|                LUIS|\n",
                            "|  4|               PEDRO|\n",
                            "|  5|              MIGUEL|\n",
                            "|  6|                LUIS|\n",
                            "|  7|               MARÍA|\n",
                            "|  8|               DAVID|\n",
                            "|  9|                SARA|\n",
                            "| 10|                 ANA|\n",
                            "| 11|              MIGUEL|\n",
                            "| 12|               DAVID|\n",
                            "| 13|               LAURA|\n",
                            "| 14|               PEDRO|\n",
                            "| 15|               MARÍA|\n",
                            "| 16|                SARA|\n",
                            "| 17|                 ANA|\n",
                            "| 18|                SARA|\n",
                            "| 19|               MARÍA|\n",
                            "| 20|               PEDRO|\n",
                            "+---+--------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.select(\"id\", f.upper(\"nombre\").alias(\"nombre_en_mayusculas\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### WithColumn\n",
                "\n",
                "Podemos añadir campos nuevos derivados a partir de otros campos utilizando el método `withColumn`. Este comando conservará todas las columnas de la tabla, y añadirá una adicional, con las transformaciones que le indiquemos.\n",
                "\n",
                "Este método opera fila a fila, es decir, aplicará las transformaciones correspondientes registro a registro.\n",
                "\n",
                "Por ejemplo, en nuestra tabla disponemos del campo `edad`, pero supongamos que nos interesa, para nuestra analítica, disponer de un campo con el año de nacimiento. En tal caso, podríamos concatenar dos funciones SQL: con la primera, `current_date`, extraemos la fecha actual, y sobre dicha fecha aplicamos la función `year` para extraer el año. Finalmente, a este año actual le restamos la edad que tiene el usuario para así calcular su año de nacimiento. Cada usuario dispondrá así de un año de nacimiento (transformación fila a fila)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th><th>a&ntilde;o_nacimiento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td><td>1976</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td><td>1998</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td><td>2000</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td><td>1989</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td><td>1993</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td><td>1980</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td><td>2001</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td><td>1968</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td><td>1979</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td><td>1971</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td><td>1978</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td><td>1997</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td><td>2001</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td><td>1991</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td><td>2002</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td><td>1974</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td><td>1971</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td><td>1996</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td><td>1998</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td><td>1997</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|año_nacimiento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|          1976|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|          1998|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|          2000|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|          1989|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|          1993|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|          1980|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|          2001|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|          1968|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|          1979|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|          1971|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|          1978|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|          1997|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|          2001|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|          1991|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|          2002|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|          1974|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|          1971|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|          1996|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|          1998|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|          1997|\n",
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.withColumn(\"año_nacimiento\", f.year(f.current_date()) - f.col(\"edad\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Filter\n",
                "\n",
                "Podemos filtrar los datos de acuerdo a alguna condición especificada. Esta sentencia se corresponde con el comando `WHERE` en SQL. Por ejemplo, queremos obtener únicamente los datos de los empleados. \n",
                "\n",
                "Recordemos que en Python el operador de igualdad es `==`.\n",
                "\n",
                "Para poder realizar operaciones con columnas, necesitamos especificar que se trata de una columna del DataFrame haciendo uso de la función `col`, puesto que si no lo que estaríamos es comparando un string con un booleano (`\"es_empleado\" == True`), que será siempre igual a `False`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td></tr>\n",
                            "<tr><td>23</td><td>Carla</td><td>50</td><td>73172.89</td><td>true</td><td>2015-08-21</td><td>IT</td></tr>\n",
                            "<tr><td>25</td><td>Sara</td><td>59</td><td>59973.55</td><td>true</td><td>2018-04-23</td><td>Marketing</td></tr>\n",
                            "<tr><td>29</td><td>Miguel</td><td>37</td><td>69922.06</td><td>true</td><td>2023-10-26</td><td>Finanzas</td></tr>\n",
                            "<tr><td>30</td><td>Luis</td><td>27</td><td>70247.43</td><td>true</td><td>2020-05-23</td><td>Finanzas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|\n",
                            "| 23| Carla|  50|73172.89|       true|        2015-08-21|          IT|\n",
                            "| 25|  Sara|  59|59973.55|       true|        2018-04-23|   Marketing|\n",
                            "| 29|Miguel|  37|69922.06|       true|        2023-10-26|    Finanzas|\n",
                            "| 30|  Luis|  27|70247.43|       true|        2020-05-23|    Finanzas|\n",
                            "+---+------+----+--------+-----------+------------------+------------+"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(f.col(\"es_empleado\") == True)\n",
                "\n",
                "# Si hacemos df.filter(\"es_empleado\" == True) obtendremos un error porque los tipos no son los esperados."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Agrupaciones\n",
                "\n",
                "Utilizando el comando group by, podemos agrupar nuestro dataset según los valores de una o varias columnas y posteriormente realizar una operación de agregación sobre cada conjunto, para así obtener estadísticas descriptivas de nuestros datos.\n",
                "\n",
                "Por ejemplo, podemos obtener el número de empleados en marketing, con lo cual debemos agrupar por departamento y realizar una operación de agregación de suma. Estas operaciones se denominan \"de agregación\" o \"de reducción\" porque actúan sobre un conjunto de filas (todas aquellas que comparten el mismo valor del grupo) y devuelven un único valor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>salario_total</th></tr>\n",
                            "<tr><td>Finanzas</td><td>524206.53515625</td></tr>\n",
                            "<tr><td>Ventas</td><td>421618.7890625</td></tr>\n",
                            "<tr><td>RRHH</td><td>292734.91015625</td></tr>\n",
                            "<tr><td>IT</td><td>355377.107421875</td></tr>\n",
                            "<tr><td>Marketing</td><td>122665.44140625</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+----------------+\n",
                            "|departamento|   salario_total|\n",
                            "+------------+----------------+\n",
                            "|    Finanzas| 524206.53515625|\n",
                            "|      Ventas|  421618.7890625|\n",
                            "|        RRHH| 292734.91015625|\n",
                            "|          IT|355377.107421875|\n",
                            "|   Marketing| 122665.44140625|\n",
                            "+------------+----------------+"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.groupBy(\"departamento\").agg(f.sum(\"salario\").alias(\"salario_total\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Combinaciones\n",
                "Naturalmente, la riqueza de PySpark es que podemos combinar filtros con agrupaciones, adición de columnas, cambios de tipos, etc para que nuestro dato final quede pulido.\n",
                "\n",
                "Al contrario que en Pandas, todas las operaciones de transformación en Spark son *lazy*, es decir, no se evalúan hasta que se pide una acción (resultado). Esto permite que el catalizador de Spark optimice toda la cadena de consultas de la manera más apropiada antes de ser ejecutadas.\n",
                "\n",
                "Veamos un ejemplo de consulta algo más avanzada: supongamos que queremos conocer cuál es el departamento del que más gente se ha ido a partir de 2017 para unos ciertos intervalos de meses: enero a mayo, junio a septiembre y octubre a diciembre. En este caso podemos comenzar aplicando unos filtros para quedarnos únicamente con registros de los que actualmente ya no son empleados y su fecha de contratación es igual o posterior a 2017. Después de aplicar dicho filtro, podemos añadir dos columnas transitorias para extraer el mes de la fecha de contratación y establecer los intervalos pedidos, utilizando la función `when`, que es esquivalente al `CASE` de SQL. Finalmente, agrupamos por estas categorías de mes y agregamos cogiendo la moda (el valor más repetido de un conjunto de datos)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>categoria_mes</th><th>departamento_mas_repetido</th></tr>\n",
                            "<tr><td>octubre-diciembre</td><td>RRHH</td></tr>\n",
                            "<tr><td>junio-septiembre</td><td>Marketing</td></tr>\n",
                            "<tr><td>enero-mayo</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-----------------+-------------------------+\n",
                            "|    categoria_mes|departamento_mas_repetido|\n",
                            "+-----------------+-------------------------+\n",
                            "|octubre-diciembre|                     RRHH|\n",
                            "| junio-septiembre|                Marketing|\n",
                            "|       enero-mayo|                   Ventas|\n",
                            "+-----------------+-------------------------+"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(\n",
                "    (f.col(\"es_empleado\") == False) & (f.year(\"fecha_contratacion\") >= 2017)\n",
                ").withColumn(\"mes_contratacion\", f.month(\"fecha_contratacion\")).withColumn(\n",
                "    \"categoria_mes\",\n",
                "    f.when(f.col(\"mes_contratacion\").between(1, 5), f.lit(\"enero-mayo\"))\n",
                "    .when(f.col(\"mes_contratacion\").between(6, 9), f.lit(\"junio-septiembre\"))\n",
                "    .otherwise(f.lit(\"octubre-diciembre\")),\n",
                ").groupBy(\n",
                "    \"categoria_mes\"\n",
                ").agg(\n",
                "    f.mode(\"departamento\").alias(\"departamento_mas_repetido\")\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "La consulta equivalente en Spark SQL en este caso sería la siguiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>categoria_mes</th><th>departamento_mas_repetido</th></tr>\n",
                            "<tr><td>octubre-diciembre</td><td>RRHH</td></tr>\n",
                            "<tr><td>junio-septiembre</td><td>Marketing</td></tr>\n",
                            "<tr><td>enero-mayo</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-----------------+-------------------------+\n",
                            "|    categoria_mes|departamento_mas_repetido|\n",
                            "+-----------------+-------------------------+\n",
                            "|octubre-diciembre|                     RRHH|\n",
                            "| junio-septiembre|                Marketing|\n",
                            "|       enero-mayo|                   Ventas|\n",
                            "+-----------------+-------------------------+"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "spark.sql(\n",
                "    \"\"\"\n",
                "    SELECT\n",
                "        CASE\n",
                "            WHEN MONTH(fecha_contratacion) BETWEEN 1 AND 5 THEN 'enero-mayo'\n",
                "            WHEN MONTH(fecha_contratacion) BETWEEN 6 AND 9 THEN 'junio-septiembre'\n",
                "            ELSE 'octubre-diciembre'\n",
                "        END AS categoria_mes,\n",
                "        MODE(departamento) AS departamento_mas_repetido\n",
                "\n",
                "    FROM empleados\n",
                "    WHERE\n",
                "        es_empleado = false AND\n",
                "        YEAR(fecha_contratacion) >= 2017\n",
                "    GROUP BY categoria_mes\n",
                "    \"\"\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como se puede comprobar, se obtienen exactamente los mismos resultados"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Caso práctico: Extracción de datos de Wallapop\n",
                "Vamos a construir un pequeño ejemplo de una ETL (Extraction Transform Load). Extraeremos datos en crudo desde la API REST de Wallapop, los guardamos en una carpeta de almacenamiento, los leemos con spark, realizamos algunas transformaciones y almacenamos la tabla resultante en nuestro catálogo de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    json_data = fetch_api(product=\"portátil\")\n",
                "    save_json(obj=json_data, path=\"data/wallapop.json\", indent=4)\n",
                "except Exception as e:\n",
                "    print(f\"Warning: No ha sido posible descargar los datos de la API: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos previsualizar cuál es la estructura de nuestro fichero JSON utilizando el comando externo `cat` de nuestra terminal (válido únicamente en sistemas Unix, con `jq` instalado).\n",
                "\n",
                "Si no está instalado `jq`, puede instalarse mediante `sudo apt update && sudo apt install jq -y`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1;39m{\n",
                        "  \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "    \u001b[0m\u001b[34;1m\"section\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "      \u001b[0m\u001b[34;1m\"payload\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "        \u001b[0m\u001b[34;1m\"order\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"most_relevance\"\u001b[0m\u001b[1;39m,\n",
                        "        \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Find what you want\"\u001b[0m\u001b[1;39m,\n",
                        "        \u001b[0m\u001b[34;1m\"items\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
                        "          \u001b[1;39m{\n",
                        "            \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pj9mq457kk6e\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"user_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"vjrd1q4rx46k\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Soporte para Portatil / Mesa de Mezclas\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Vendo soporte para Portatil pero tambien vale si tienes una mesa de mezclas pequeña de dj\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"category_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m24200\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"price\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "              \u001b[0m\u001b[34;1m\"amount\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m10\u001b[0m\u001b[1;39m,\n",
                        "              \u001b[0m\u001b[34;1m\"currency\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"EUR\"\u001b[0m\u001b[1;39m\n",
                        "            \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"images\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
                        "              \u001b[1;39m{\n",
                        "                \u001b[0m\u001b[34;1m\"average_color\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"13C1AC\"\u001b[0m\u001b[1;39m,\n"
                    ]
                }
            ],
            "source": [
                "%%sh\n",
                "cat data/wallapop.json | jq -C | head -20"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez determinada la estructura que tiene nuestro fichero JSON de información, notamos que los datos que queremos obtener se encuentran dentro de la ruta `data -> section -> payload -> items`. Dicha ruta se corresponde con un array (lista) de items, que son los productos de Wallapop; cada uno de ellos tiene unos campos, algunos simples como `id`, `user_id`, y otros compuestos como `price -> amount` o `price -> currency`.\n",
                "\n",
                "En primer lugar, observemos que si leemos el fichero JSON directamente no obtenemos una estructura muy amigable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "|                                              data|                                              meta|\n",
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "|{{{[{{none}, 24200, 1727516670420, Vendo soport...|{eyJhbGciOiJIUzI1NiJ9.eyJwYXJhbXMiOnsic2VhcmNoU...|\n",
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop = spark.read.json(\"data/wallapop.json\", multiLine=True)\n",
                "wallapop.show(truncate=50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esto es porque nos ha cogido las dos primeras claves más externas de nuestro fichero JSON, que son los campos `\"data\"` y `\"meta\"`.\n",
                "\n",
                "Observemos qué estructura hemos cargado haciendo un `printSchema` de nuestro DataFrame. De esta manera obtendremos información de los campos y sus tipos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- data: struct (nullable = true)\n",
                        " |    |-- section: struct (nullable = true)\n",
                        " |    |    |-- payload: struct (nullable = true)\n",
                        " |    |    |    |-- items: array (nullable = true)\n",
                        " |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |-- bump: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- type: string (nullable = true)\n",
                        " |    |    |    |    |    |-- category_id: long (nullable = true)\n",
                        " |    |    |    |    |    |-- created_at: long (nullable = true)\n",
                        " |    |    |    |    |    |-- description: string (nullable = true)\n",
                        " |    |    |    |    |    |-- discount: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- percentage: long (nullable = true)\n",
                        " |    |    |    |    |    |    |-- previous_price: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- amount: double (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- currency: string (nullable = true)\n",
                        " |    |    |    |    |    |-- favorited: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- id: string (nullable = true)\n",
                        " |    |    |    |    |    |-- images: array (nullable = true)\n",
                        " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |    |    |-- average_color: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- urls: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- big: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- medium: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- small: string (nullable = true)\n",
                        " |    |    |    |    |    |-- is_favoriteable: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- is_refurbished: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- location: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- city: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- country_code: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- latitude: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- longitude: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- postal_code: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- region: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- region2: string (nullable = true)\n",
                        " |    |    |    |    |    |-- modified_at: long (nullable = true)\n",
                        " |    |    |    |    |    |-- price: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- amount: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- currency: string (nullable = true)\n",
                        " |    |    |    |    |    |-- reserved: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- shipping: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- cost_configuration_id: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- item_is_shippable: boolean (nullable = true)\n",
                        " |    |    |    |    |    |    |-- user_allows_shipping: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- taxonomy: array (nullable = true)\n",
                        " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |    |    |-- icon: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- id: long (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- name: string (nullable = true)\n",
                        " |    |    |    |    |    |-- title: string (nullable = true)\n",
                        " |    |    |    |    |    |-- user_id: string (nullable = true)\n",
                        " |    |    |    |    |    |-- web_slug: string (nullable = true)\n",
                        " |    |    |    |-- order: string (nullable = true)\n",
                        " |    |    |    |-- title: string (nullable = true)\n",
                        " |    |    |-- type: string (nullable = true)\n",
                        " |    |-- tracking: struct (nullable = true)\n",
                        " |    |    |-- location: struct (nullable = true)\n",
                        " |    |    |    |-- country_code: string (nullable = true)\n",
                        " |    |    |    |-- latitude: double (nullable = true)\n",
                        " |    |    |    |-- longitude: double (nullable = true)\n",
                        " |    |    |-- variant: string (nullable = true)\n",
                        " |-- meta: struct (nullable = true)\n",
                        " |    |-- next_page: string (nullable = true)\n",
                        " |    |-- next_section_type: string (nullable = true)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.printSchema()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora, para navegar a través de nuestro fichero JSON, podemos utilizar la sintáxis por puntos; es decir, para obtener el campo deseado `\"items\"`, que contiene la información de todos los productos, debemos acceder mediante `data.section.payload.items`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|                                                                                               items|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|[{{none}, 24200, 1727516670420, Vendo soporte para Portatil pero tambien vale si tienes una mesa ...|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.select(\"data.section.payload.items\").show(truncate=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sin embargo, seguimos sin apreciar una estructura legible. Esto es porque se nos está mostrando un único registro (fila) que contiene toda la información de los productos. Lo que nos interesa es que cada elemento de esta lista se muestre en un registro a parte. Para ello se utiliza la función SQL `explode`, que coge un array de elementos y devuelve un registro por cada uno de esos elementos. Veámoslo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|                                                                                                 col|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|{{none}, 24200, 1727516670420, Vendo soporte para Portatil pero tambien vale si tienes una mesa d...|\n",
                        "|{{none}, 24200, 1727514300255, Teclado Bluetooth portátil plegable muy práctico y con muy poco us...|\n",
                        "|{{none}, 24200, 1727518263833, Portatil HP 250 G8\\nOrdenador de 15,6” FullHD\\nIntel Core I5-1135G...|\n",
                        "|{{none}, 24200, 1727516192754, Se vende todo por 20 euros, son piezas de portátil diferente marcá...|\n",
                        "|{{none}, 24200, 1727444183886, Ventilador portable para portátiles para la refrigeración de estos...|\n",
                        "|{{none}, 24200, 1727519183576, DVD portatil - BELSON - BS-130806\\n\\nReproductor Dvd Portatil con ...|\n",
                        "|{{none}, 24200, 1727515228880, Puerto de carga o conector del cargador para ACER SWIFT SF315-41 R...|\n",
                        "|{{none}, 24200, 1727515227519, Disipador de cobre para ACER SWIFT SF315-41 R69U. Hago envíos y ac...|\n",
                        "|{{none}, 24200, 1727515226265, Placa con puertos USB 2.0, tarjetas SD y LED's de encendido y carg...|\n",
                        "|{{none}, 24200, 1727515224639, Set de altavoces para ACER SWIFT SF315-41 R69U. Hago envíos y acep...|\n",
                        "|{{none}, 24200, 1727515225435, Ventilador para ACER SWIFT SF315-41 R69U. Hago envíos y acepto biz...|\n",
                        "|{{none}, 24200, 1727509580150, OFERTON \\nKARAOKE PORTATIL Colorfull\\nK12 sistema portátil de soni...|\n",
                        "|{{none}, 24200, 1727517559662, Reproductor de dvd portátil marca Airis, con funda, cargador eléct...|\n",
                        "|{{none}, 24200, 1727516867735, Portatil hp model 15s eq008ns\\nPantalla FullHD 1080 15,6”\\nProcesa...|\n",
                        "|{{none}, 24200, 1727515589555, Altavoz para PC o Portátil, con salida analógica. Ha estado guarda...|\n",
                        "|{{none}, 24200, 1727515825183, Sistema operativo Windows 11 pro \\nDisco SSD m.2 de 256 GB\\nMemori...|\n",
                        "|{{none}, 24200, 1727506608475, Maletin o funda de ordenador portatil con cremallera y 7 compartim...|\n",
                        "|{{none}, 24200, 1727515418313, Sistema operativo windows 11 pro\\nDisco ssd m.2 de 256 GB\\nMemoria...|\n",
                        "|{{none}, 24200, 1727514214339, 🚨👀 ¡Oferta! Soporte de ordenador portátil para 11,6-17 pulgadas,...|\n",
                        "|{{none}, 24200, 1727514851688, Portatil Lenovo Ideapad 530S de 14”.\\nMuy ligero y extraplano.\\nTe...|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "only showing top 20 rows\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.select(f.explode(\"data.section.payload.items\")).show(truncate=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Bien, ya hemos avanzado, disponemos ahora de un registro por cada producto de la lista `items`, como queríamos. Sin embargo, se sigue mostrando toda la información en una misma columna. Eso lo solucionamos seleccionando los campos anidados deseados. Por ejemplo, supongamos que queremos coger el `id` del producto, el `user_id` del usuario y la fecha de creación del anuncio `created_at`. Una buena manera de operar sería crear una nueva columna llamada, por ejemplo, `\"data\"`, que contenga los registros explotados del campo de `\"items\"`, y luego utilizar este nuevo campo para obtener la info de los otros campos descendientes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>user_id</th><th>created_at</th></tr>\n",
                            "<tr><td>pj9mq457kk6e</td><td>vjrd1q4rx46k</td><td>1727516670420</td></tr>\n",
                            "<tr><td>vjrqve93pwzk</td><td>p61o88mkx5j5</td><td>1727514300255</td></tr>\n",
                            "<tr><td>p614184klg65</td><td>g0j2gq3y7rzy</td><td>1727518263833</td></tr>\n",
                            "<tr><td>0j24k83g4ezy</td><td>8x6qd1k8kejy</td><td>1727516192754</td></tr>\n",
                            "<tr><td>e658282neg6o</td><td>ejkx1revk16x</td><td>1727444183886</td></tr>\n",
                            "<tr><td>8j34o8411l69</td><td>mxzo770ed2j9</td><td>1727519183576</td></tr>\n",
                            "<tr><td>qjw4vrpedqzo</td><td>g0j21e1xpvzy</td><td>1727515228880</td></tr>\n",
                            "<tr><td>wzv4vgnry1zl</td><td>g0j21e1xpvzy</td><td>1727515227519</td></tr>\n",
                            "<tr><td>xzo2ogrl8w69</td><td>g0j21e1xpvzy</td><td>1727515226265</td></tr>\n",
                            "<tr><td>e6582qgvyg6o</td><td>g0j21e1xpvzy</td><td>1727515224639</td></tr>\n",
                            "<tr><td>nz04x80gmrjo</td><td>g0j21e1xpvzy</td><td>1727515225435</td></tr>\n",
                            "<tr><td>wzv4vgr2o4zl</td><td>4z4v072okwzy</td><td>1727509580150</td></tr>\n",
                            "<tr><td>8z8k98kvwrz3</td><td>7v6go2957jeo</td><td>1727517559662</td></tr>\n",
                            "<tr><td>qzme1myd9ljv</td><td>p8j35r8312z9</td><td>1727516867735</td></tr>\n",
                            "<tr><td>nzx4ve0097j2</td><td>dqjw1py0rezo</td><td>1727515589555</td></tr>\n",
                            "<tr><td>wzy4vr5rwvz5</td><td>0j2wg8ko7rjy</td><td>1727515825183</td></tr>\n",
                            "<tr><td>p614189mq765</td><td>8ejkmog4rqzx</td><td>1727506608475</td></tr>\n",
                            "<tr><td>8j34o8ey7269</td><td>vjrde18pdw6k</td><td>1727515418313</td></tr>\n",
                            "<tr><td>8j34o8xkey69</td><td>36ewevgwdy6d</td><td>1727514214339</td></tr>\n",
                            "<tr><td>mzn2m3vymkzn</td><td>8j3yrgq91y69</td><td>1727514851688</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+------------+-------------+\n",
                            "|          id|     user_id|   created_at|\n",
                            "+------------+------------+-------------+\n",
                            "|pj9mq457kk6e|vjrd1q4rx46k|1727516670420|\n",
                            "|vjrqve93pwzk|p61o88mkx5j5|1727514300255|\n",
                            "|p614184klg65|g0j2gq3y7rzy|1727518263833|\n",
                            "|0j24k83g4ezy|8x6qd1k8kejy|1727516192754|\n",
                            "|e658282neg6o|ejkx1revk16x|1727444183886|\n",
                            "|8j34o8411l69|mxzo770ed2j9|1727519183576|\n",
                            "|qjw4vrpedqzo|g0j21e1xpvzy|1727515228880|\n",
                            "|wzv4vgnry1zl|g0j21e1xpvzy|1727515227519|\n",
                            "|xzo2ogrl8w69|g0j21e1xpvzy|1727515226265|\n",
                            "|e6582qgvyg6o|g0j21e1xpvzy|1727515224639|\n",
                            "|nz04x80gmrjo|g0j21e1xpvzy|1727515225435|\n",
                            "|wzv4vgr2o4zl|4z4v072okwzy|1727509580150|\n",
                            "|8z8k98kvwrz3|7v6go2957jeo|1727517559662|\n",
                            "|qzme1myd9ljv|p8j35r8312z9|1727516867735|\n",
                            "|nzx4ve0097j2|dqjw1py0rezo|1727515589555|\n",
                            "|wzy4vr5rwvz5|0j2wg8ko7rjy|1727515825183|\n",
                            "|p614189mq765|8ejkmog4rqzx|1727506608475|\n",
                            "|8j34o8ey7269|vjrde18pdw6k|1727515418313|\n",
                            "|8j34o8xkey69|36ewevgwdy6d|1727514214339|\n",
                            "|mzn2m3vymkzn|8j3yrgq91y69|1727514851688|\n",
                            "+------------+------------+-------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "wallapop.withColumn(\"data\", f.explode(\"data.section.payload.items\")).select(\n",
                "    \"data.id\", \"data.user_id\", \"data.created_at\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fenomenal. Ahora, siguiendo esta misma operación, obtendremos un dataset completo tabular de los campos del JSON más relevantes. Observemos que para todos los campos seleccionados, se hace una conversión de tipos (método `cast`) y se asigna un alias (método `alias`). Esto es para que la tabla resultante sea consistente, y tenga siempre el mismo esquema de salida.\n",
                "\n",
                "Notemos también que a campos que representan fechas pero se muestran como números enteros (milisegundos desde 1970, esto se conoce como UNIX time), como `created_at` o `modified_at`, les aplicamos una conversión mediante la función `from_unixtime` para representarlos como una fecha legible"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- id: string (nullable = true)\n",
                        " |-- title: string (nullable = true)\n",
                        " |-- user_id: string (nullable = true)\n",
                        " |-- category_id: integer (nullable = true)\n",
                        " |-- created_at: timestamp (nullable = true)\n",
                        " |-- modified_at: timestamp (nullable = true)\n",
                        " |-- description: string (nullable = true)\n",
                        " |-- percentage: integer (nullable = true)\n",
                        " |-- previous_price_amount: double (nullable = true)\n",
                        " |-- previous_price_currency: string (nullable = true)\n",
                        " |-- favorited: boolean (nullable = true)\n",
                        " |-- is_favoriteable: boolean (nullable = true)\n",
                        " |-- is_refurbished: boolean (nullable = true)\n",
                        " |-- latitude: double (nullable = true)\n",
                        " |-- longitude: double (nullable = true)\n",
                        " |-- postal_code: string (nullable = true)\n",
                        " |-- city: string (nullable = true)\n",
                        " |-- region: string (nullable = true)\n",
                        " |-- region2: string (nullable = true)\n",
                        " |-- country_code: string (nullable = true)\n",
                        " |-- amount: double (nullable = true)\n",
                        " |-- currency: string (nullable = true)\n",
                        " |-- reserved: string (nullable = true)\n",
                        " |-- item_is_shippable: boolean (nullable = true)\n",
                        " |-- user_allows_shipping: boolean (nullable = true)\n",
                        " |-- __timestamp: timestamp (nullable = false)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/09/28 12:32:43 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>title</th><th>user_id</th><th>category_id</th><th>created_at</th><th>modified_at</th><th>description</th><th>percentage</th><th>previous_price_amount</th><th>previous_price_currency</th><th>favorited</th><th>is_favoriteable</th><th>is_refurbished</th><th>latitude</th><th>longitude</th><th>postal_code</th><th>city</th><th>region</th><th>region2</th><th>country_code</th><th>amount</th><th>currency</th><th>reserved</th><th>item_is_shippable</th><th>user_allows_shipping</th><th>__timestamp</th></tr>\n",
                            "<tr><td>pj9mq457kk6e</td><td>Soporte para Portatil / Mesa de Mezclas</td><td>vjrd1q4rx46k</td><td>24200</td><td>2024-09-28 11:44:30</td><td>2024-09-28 11:44:41</td><td>Vendo soporte para Portatil pero tambien vale si tienes una mesa de mezclas peque&ntilde;a de dj</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.3007871</td><td>-3.4378134</td><td>28500</td><td>Arganda del Rey</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>10.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>vjrqve93pwzk</td><td>Teclado Bluetooth port&aacute;til plegable</td><td>p61o88mkx5j5</td><td>24200</td><td>2024-09-28 11:05:00</td><td>2024-09-28 11:05:10</td><td>Teclado Bluetooth port&aacute;til plegable muy pr&aacute;ctico y con muy poco uso.</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.388187529781774</td><td>-3.713019692257435</td><td>28026</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>9.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>p614184klg65</td><td>Portatil HP</td><td>g0j2gq3y7rzy</td><td>24200</td><td>2024-09-28 12:11:03</td><td>2024-09-28 12:11:14</td><td>Portatil HP 250 G8\\nOrdenador de 15,6&rdquo; FullHD\\nIntel Core I5-1135G7\\nDisco duro SSD NVME 256 gb\\n...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.483780140950714</td><td>-3.86560871014634</td><td>28230</td><td>Las Rozas de Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>250.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>0j24k83g4ezy</td><td>Piezas de port&aacute;til </td><td>8x6qd1k8kejy</td><td>24200</td><td>2024-09-28 11:36:32</td><td>2024-09-28 11:36:48</td><td>Se vende todo por 20 euros, son piezas de port&aacute;til diferente marc&aacute;s </td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.4315752</td><td>-3.6276283</td><td>28037</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>20.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>e658282neg6o</td><td>ventilador port&aacute;til </td><td>ejkx1revk16x</td><td>24200</td><td>2024-09-27 15:36:23</td><td>2024-09-27 15:36:34</td><td>Ventilador portable para port&aacute;tiles para la refrigeraci&oacute;n de estos mismos. tiene unos a&ntilde;os pero v...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.23246875179884</td><td>-3.979483127852885</td><td>28607</td><td>El &Aacute;lamo</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>5.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>8j34o8411l69</td><td>Dvd Portatil - Belson</td><td>mxzo770ed2j9</td><td>24200</td><td>2024-09-28 12:26:23</td><td>2024-09-28 12:32:15</td><td>DVD portatil - BELSON - BS-130806\\n\\nReproductor Dvd Portatil con pantalla TFT 7&rdquo;\\n\\nFormatos DVD...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.34486734204959</td><td>-3.7380263560548213</td><td>28916</td><td>Legan&eacute;s</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>35.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>qjw4vrpedqzo</td><td>Recambio Ordenador Port&aacute;til</td><td>g0j21e1xpvzy</td><td>24200</td><td>2024-09-28 11:20:28</td><td>2024-09-28 11:20:39</td><td>Puerto de carga o conector del cargador para ACER SWIFT SF315-41 R69U. Hago env&iacute;os y acepto bizum.\\n</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.4269821</td><td>-3.6963103</td><td>28010</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>4.99</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>wzv4vgnry1zl</td><td>Recambio Ordenador Port&aacute;til</td><td>g0j21e1xpvzy</td><td>24200</td><td>2024-09-28 11:20:27</td><td>2024-09-28 11:20:37</td><td>Disipador de cobre para ACER SWIFT SF315-41 R69U. Hago env&iacute;os y acepto bizum.\\n</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.4269821</td><td>-3.6963103</td><td>28010</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>3.99</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>xzo2ogrl8w69</td><td>Recambio Ordenador Port&aacute;til</td><td>g0j21e1xpvzy</td><td>24200</td><td>2024-09-28 11:20:26</td><td>2024-09-28 11:20:36</td><td>Placa con puertos USB 2.0, tarjetas SD y LED's de encendido y carga para ACER SWIFT SF315-41 R69U...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.4269821</td><td>-3.6963103</td><td>28010</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>4.99</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>e6582qgvyg6o</td><td>Recambio Ordenador Port&aacute;til</td><td>g0j21e1xpvzy</td><td>24200</td><td>2024-09-28 11:20:24</td><td>2024-09-28 11:20:34</td><td>Set de altavoces para ACER SWIFT SF315-41 R69U. Hago env&iacute;os y acepto bizum.\\n</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.4269821</td><td>-3.6963103</td><td>28010</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>7.99</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>nz04x80gmrjo</td><td>Recambio Ordenador Port&aacute;til</td><td>g0j21e1xpvzy</td><td>24200</td><td>2024-09-28 11:20:25</td><td>2024-09-28 11:20:35</td><td>Ventilador para ACER SWIFT SF315-41 R69U. Hago env&iacute;os y acepto bizum. Con tornillos incluidos.\\n</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.4269821</td><td>-3.6963103</td><td>28010</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>4.99</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>wzv4vgr2o4zl</td><td>Karaoke port&aacute;til Colorfull</td><td>4z4v072okwzy</td><td>24200</td><td>2024-09-28 09:46:20</td><td>2024-09-28 09:46:30</td><td>OFERTON \\nKARAOKE PORTATIL Colorfull\\nK12 sistema port&aacute;til de sonido\\nCon karaoke y luz rgb</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.4175915401244</td><td>-3.691384529401185</td><td>28009</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>12.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>8z8k98kvwrz3</td><td>Reproductor DVD port&aacute;til Airis</td><td>7v6go2957jeo</td><td>24200</td><td>2024-09-28 11:59:19</td><td>2024-09-28 11:59:29</td><td>Reproductor de dvd port&aacute;til marca Airis, con funda, cargador el&eacute;ctrico y cargador para &eacute;l coche. ...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.374868576955876</td><td>-3.6654142575659967</td><td>28018</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>10.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>qzme1myd9ljv</td><td>Portatil hp RYZEN 7 </td><td>p8j35r8312z9</td><td>24200</td><td>2024-09-28 11:47:47</td><td>2024-09-28 11:47:58</td><td>Portatil hp model 15s eq008ns\\nPantalla FullHD 1080 15,6&rdquo;\\nProcesador RYZEN 7 3700 \\nGrafica Rade...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.47909286756544</td><td>-3.3599827970820915</td><td>28807</td><td>Alcal&aacute; de Henares</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>200.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>nzx4ve0097j2</td><td>Altavoz para PC o Port&aacute;til </td><td>dqjw1py0rezo</td><td>24200</td><td>2024-09-28 11:26:29</td><td>2024-09-28 11:26:39</td><td>Altavoz para PC o Port&aacute;til, con salida anal&oacute;gica. Ha estado guardado varios a&ntilde;os en un trastero. ...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.38228672188106</td><td>-3.6900643016927757</td><td>28045</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>5.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>wzy4vr5rwvz5</td><td>Portatil HP i5 </td><td>0j2wg8ko7rjy</td><td>24200</td><td>2024-09-28 11:30:25</td><td>2024-09-28 11:30:35</td><td>Sistema operativo Windows 11 pro \\nDisco SSD m.2 de 256 GB\\nMemoria ram de 16 GB \\nMicrosoft Offi...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.468777530515105</td><td>-3.6428086745985553</td><td>28033</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>250.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>p614189mq765</td><td>Funda ordenador portatil</td><td>8ejkmog4rqzx</td><td>24200</td><td>2024-09-28 08:56:48</td><td>2024-09-28 08:56:58</td><td>Maletin o funda de ordenador portatil con cremallera y 7 compartimentos</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.545001562312954</td><td>-3.641195819553692</td><td>28100</td><td>Alcobendas</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>6.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>8j34o8ey7269</td><td>Port&aacute;til hp i5 </td><td>vjrde18pdw6k</td><td>24200</td><td>2024-09-28 11:23:38</td><td>2024-09-28 11:23:48</td><td>Sistema operativo windows 11 pro\\nDisco ssd m.2 de 256 GB\\nMemoria ram de 16 GB\\nMicrosoft office...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.475079539201225</td><td>-3.650639460036658</td><td>28033</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>250.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>8j34o8xkey69</td><td>🚨👀 &iexcl;Oferta! Soporte de ordenador port&aacute;til</td><td>36ewevgwdy6d</td><td>24200</td><td>2024-09-28 11:03:34</td><td>2024-09-28 11:03:44</td><td>🚨👀 &iexcl;Oferta! Soporte de ordenador port&aacute;til para 11,6-17 pulgadas, soporte de escritorio, ayuda a...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.54630090696002</td><td>-3.6393026328942715</td><td>28100</td><td>Alcobendas</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>20.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "<tr><td>mzn2m3vymkzn</td><td>Portatil Lenovo Ideapad 530S</td><td>8j3yrgq91y69</td><td>24200</td><td>2024-09-28 11:14:11</td><td>2024-09-28 11:14:22</td><td>Portatil Lenovo Ideapad 530S de 14&rdquo;.\\nMuy ligero y extraplano.\\nTeclado retroiluminado.\\nPotente ...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>false</td><td>true</td><td>false</td><td>40.45371924976639</td><td>-3.6327397219040813</td><td>28043</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>320.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-28 12:32:43.642223</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+-------------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+----------+---------------------+-----------------------+---------+---------------+--------------+------------------+-------------------+-----------+-------------------+-------------------+-------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "|          id|                                      title|     user_id|category_id|         created_at|        modified_at|                                                                                         description|percentage|previous_price_amount|previous_price_currency|favorited|is_favoriteable|is_refurbished|          latitude|          longitude|postal_code|               city|             region|region2|country_code|amount|currency|reserved|item_is_shippable|user_allows_shipping|               __timestamp|\n",
                            "+------------+-------------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+----------+---------------------+-----------------------+---------+---------------+--------------+------------------+-------------------+-----------+-------------------+-------------------+-------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "|pj9mq457kk6e|    Soporte para Portatil / Mesa de Mezclas|vjrd1q4rx46k|      24200|2024-09-28 11:44:30|2024-09-28 11:44:41|           Vendo soporte para Portatil pero tambien vale si tienes una mesa de mezclas pequeña de dj|      NULL|                 NULL|                   NULL|    false|           true|         false|        40.3007871|         -3.4378134|      28500|    Arganda del Rey|Comunidad de Madrid| Madrid|          ES|  10.0|     EUR|   false|             true|               false|2024-09-28 12:32:43.256542|\n",
                            "|vjrqve93pwzk|        Teclado Bluetooth portátil plegable|p61o88mkx5j5|      24200|2024-09-28 11:05:00|2024-09-28 11:05:10|                                Teclado Bluetooth portátil plegable muy práctico y con muy poco uso.|      NULL|                 NULL|                   NULL|    false|           true|         false|40.388187529781774| -3.713019692257435|      28026|             Madrid|Comunidad de Madrid| Madrid|          ES|   9.0|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|p614184klg65|                                Portatil HP|g0j2gq3y7rzy|      24200|2024-09-28 12:11:03|2024-09-28 12:11:14|Portatil HP 250 G8\\nOrdenador de 15,6” FullHD\\nIntel Core I5-1135G7\\nDisco duro SSD NVME 256 gb\\n...|      NULL|                 NULL|                   NULL|    false|           true|         false|40.483780140950714|  -3.86560871014634|      28230|Las Rozas de Madrid|Comunidad de Madrid| Madrid|          ES| 250.0|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|0j24k83g4ezy|                        Piezas de portátil |8x6qd1k8kejy|      24200|2024-09-28 11:36:32|2024-09-28 11:36:48|                                Se vende todo por 20 euros, son piezas de portátil diferente marcás |      NULL|                 NULL|                   NULL|    false|           true|         false|        40.4315752|         -3.6276283|      28037|             Madrid|Comunidad de Madrid| Madrid|          ES|  20.0|     EUR|   false|             true|               false|2024-09-28 12:32:43.256542|\n",
                            "|e658282neg6o|                       ventilador portátil |ejkx1revk16x|      24200|2024-09-27 15:36:23|2024-09-27 15:36:34|Ventilador portable para portátiles para la refrigeración de estos mismos. tiene unos años pero v...|      NULL|                 NULL|                   NULL|    false|           true|         false| 40.23246875179884| -3.979483127852885|      28607|           El Álamo|Comunidad de Madrid| Madrid|          ES|   5.0|     EUR|   false|             true|               false|2024-09-28 12:32:43.256542|\n",
                            "|8j34o8411l69|                      Dvd Portatil - Belson|mxzo770ed2j9|      24200|2024-09-28 12:26:23|2024-09-28 12:32:15|DVD portatil - BELSON - BS-130806\\n\\nReproductor Dvd Portatil con pantalla TFT 7”\\n\\nFormatos DVD...|      NULL|                 NULL|                   NULL|    false|           true|         false| 40.34486734204959|-3.7380263560548213|      28916|            Leganés|Comunidad de Madrid| Madrid|          ES|  35.0|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|qjw4vrpedqzo|                Recambio Ordenador Portátil|g0j21e1xpvzy|      24200|2024-09-28 11:20:28|2024-09-28 11:20:39|Puerto de carga o conector del cargador para ACER SWIFT SF315-41 R69U. Hago envíos y acepto bizum.\\n|      NULL|                 NULL|                   NULL|    false|           true|         false|        40.4269821|         -3.6963103|      28010|             Madrid|Comunidad de Madrid| Madrid|          ES|  4.99|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|wzv4vgnry1zl|                Recambio Ordenador Portátil|g0j21e1xpvzy|      24200|2024-09-28 11:20:27|2024-09-28 11:20:37|                     Disipador de cobre para ACER SWIFT SF315-41 R69U. Hago envíos y acepto bizum.\\n|      NULL|                 NULL|                   NULL|    false|           true|         false|        40.4269821|         -3.6963103|      28010|             Madrid|Comunidad de Madrid| Madrid|          ES|  3.99|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|xzo2ogrl8w69|                Recambio Ordenador Portátil|g0j21e1xpvzy|      24200|2024-09-28 11:20:26|2024-09-28 11:20:36|Placa con puertos USB 2.0, tarjetas SD y LED's de encendido y carga para ACER SWIFT SF315-41 R69U...|      NULL|                 NULL|                   NULL|    false|           true|         false|        40.4269821|         -3.6963103|      28010|             Madrid|Comunidad de Madrid| Madrid|          ES|  4.99|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|e6582qgvyg6o|                Recambio Ordenador Portátil|g0j21e1xpvzy|      24200|2024-09-28 11:20:24|2024-09-28 11:20:34|                       Set de altavoces para ACER SWIFT SF315-41 R69U. Hago envíos y acepto bizum.\\n|      NULL|                 NULL|                   NULL|    false|           true|         false|        40.4269821|         -3.6963103|      28010|             Madrid|Comunidad de Madrid| Madrid|          ES|  7.99|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|nz04x80gmrjo|                Recambio Ordenador Portátil|g0j21e1xpvzy|      24200|2024-09-28 11:20:25|2024-09-28 11:20:35|    Ventilador para ACER SWIFT SF315-41 R69U. Hago envíos y acepto bizum. Con tornillos incluidos.\\n|      NULL|                 NULL|                   NULL|    false|           true|         false|        40.4269821|         -3.6963103|      28010|             Madrid|Comunidad de Madrid| Madrid|          ES|  4.99|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|wzv4vgr2o4zl|                 Karaoke portátil Colorfull|4z4v072okwzy|      24200|2024-09-28 09:46:20|2024-09-28 09:46:30|         OFERTON \\nKARAOKE PORTATIL Colorfull\\nK12 sistema portátil de sonido\\nCon karaoke y luz rgb|      NULL|                 NULL|                   NULL|    false|           true|         false|  40.4175915401244| -3.691384529401185|      28009|             Madrid|Comunidad de Madrid| Madrid|          ES|  12.0|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|8z8k98kvwrz3|             Reproductor DVD portátil Airis|7v6go2957jeo|      24200|2024-09-28 11:59:19|2024-09-28 11:59:29|Reproductor de dvd portátil marca Airis, con funda, cargador eléctrico y cargador para él coche. ...|      NULL|                 NULL|                   NULL|    false|           true|         false|40.374868576955876|-3.6654142575659967|      28018|             Madrid|Comunidad de Madrid| Madrid|          ES|  10.0|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|qzme1myd9ljv|                       Portatil hp RYZEN 7 |p8j35r8312z9|      24200|2024-09-28 11:47:47|2024-09-28 11:47:58|Portatil hp model 15s eq008ns\\nPantalla FullHD 1080 15,6”\\nProcesador RYZEN 7 3700 \\nGrafica Rade...|      NULL|                 NULL|                   NULL|    false|           true|         false| 40.47909286756544|-3.3599827970820915|      28807|  Alcalá de Henares|Comunidad de Madrid| Madrid|          ES| 200.0|     EUR|   false|             true|               false|2024-09-28 12:32:43.256542|\n",
                            "|nzx4ve0097j2|                Altavoz para PC o Portátil |dqjw1py0rezo|      24200|2024-09-28 11:26:29|2024-09-28 11:26:39|Altavoz para PC o Portátil, con salida analógica. Ha estado guardado varios años en un trastero. ...|      NULL|                 NULL|                   NULL|    false|           true|         false| 40.38228672188106|-3.6900643016927757|      28045|             Madrid|Comunidad de Madrid| Madrid|          ES|   5.0|     EUR|   false|             true|               false|2024-09-28 12:32:43.256542|\n",
                            "|wzy4vr5rwvz5|                            Portatil HP i5 |0j2wg8ko7rjy|      24200|2024-09-28 11:30:25|2024-09-28 11:30:35|Sistema operativo Windows 11 pro \\nDisco SSD m.2 de 256 GB\\nMemoria ram de 16 GB \\nMicrosoft Offi...|      NULL|                 NULL|                   NULL|    false|           true|         false|40.468777530515105|-3.6428086745985553|      28033|             Madrid|Comunidad de Madrid| Madrid|          ES| 250.0|     EUR|   false|             true|               false|2024-09-28 12:32:43.256542|\n",
                            "|p614189mq765|                   Funda ordenador portatil|8ejkmog4rqzx|      24200|2024-09-28 08:56:48|2024-09-28 08:56:58|                             Maletin o funda de ordenador portatil con cremallera y 7 compartimentos|      NULL|                 NULL|                   NULL|    false|           true|         false|40.545001562312954| -3.641195819553692|      28100|         Alcobendas|Comunidad de Madrid| Madrid|          ES|   6.0|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|8j34o8ey7269|                            Portátil hp i5 |vjrde18pdw6k|      24200|2024-09-28 11:23:38|2024-09-28 11:23:48|Sistema operativo windows 11 pro\\nDisco ssd m.2 de 256 GB\\nMemoria ram de 16 GB\\nMicrosoft office...|      NULL|                 NULL|                   NULL|    false|           true|         false|40.475079539201225| -3.650639460036658|      28033|             Madrid|Comunidad de Madrid| Madrid|          ES| 250.0|     EUR|   false|             true|               false|2024-09-28 12:32:43.256542|\n",
                            "|8j34o8xkey69|🚨👀 ¡Oferta! Soporte de ordenador portátil|36ewevgwdy6d|      24200|2024-09-28 11:03:34|2024-09-28 11:03:44|🚨👀 ¡Oferta! Soporte de ordenador portátil para 11,6-17 pulgadas, soporte de escritorio, ayuda a...|      NULL|                 NULL|                   NULL|    false|           true|         false| 40.54630090696002|-3.6393026328942715|      28100|         Alcobendas|Comunidad de Madrid| Madrid|          ES|  20.0|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "|mzn2m3vymkzn|               Portatil Lenovo Ideapad 530S|8j3yrgq91y69|      24200|2024-09-28 11:14:11|2024-09-28 11:14:22|Portatil Lenovo Ideapad 530S de 14”.\\nMuy ligero y extraplano.\\nTeclado retroiluminado.\\nPotente ...|      NULL|                 NULL|                   NULL|    false|           true|         false| 40.45371924976639|-3.6327397219040813|      28043|             Madrid|Comunidad de Madrid| Madrid|          ES| 320.0|     EUR|   false|             true|                true|2024-09-28 12:32:43.256542|\n",
                            "+------------+-------------------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+----------+---------------------+-----------------------+---------+---------------+--------------+------------------+-------------------+-----------+-------------------+-------------------+-------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "wallapop = (\n",
                "    spark.read.json(\"data/wallapop.json\", multiLine=True, primitivesAsString=True)\n",
                "    .withColumn(\"data\", f.explode(\"data.section.payload.items\"))\n",
                "    .select(\n",
                "        f.col(\"data.id\").cast(\"string\").alias(\"id\"),\n",
                "        f.col(\"data.title\").cast(\"string\").alias(\"title\"),\n",
                "        f.col(\"data.user_id\").cast(\"string\").alias(\"user_id\"),\n",
                "        f.col(\"data.category_id\").cast(\"int\").alias(\"category_id\"),\n",
                "        f.from_unixtime((f.col(\"data.created_at\") / 1000))\n",
                "        .cast(\"timestamp\")\n",
                "        .alias(\"created_at\"),\n",
                "        f.from_unixtime(f.col(\"data.modified_at\") / 1000)\n",
                "        .cast(\"timestamp\")\n",
                "        .alias(\"modified_at\"),\n",
                "        f.col(\"data.description\").cast(\"string\").alias(\"description\"),\n",
                "        f.col(\"data.discount.percentage\").cast(\"int\").alias(\"percentage\"),\n",
                "        f.col(\"data.discount.previous_price.amount\")\n",
                "        .cast(\"double\")\n",
                "        .alias(\"previous_price_amount\"),\n",
                "        f.col(\"data.discount.previous_price.currency\")\n",
                "        .cast(\"string\")\n",
                "        .alias(\"previous_price_currency\"),\n",
                "        f.col(\"data.favorited.flag\").cast(\"boolean\").alias(\"favorited\"),\n",
                "        f.col(\"data.is_favoriteable.flag\").cast(\"boolean\").alias(\"is_favoriteable\"),\n",
                "        f.col(\"data.is_refurbished.flag\").cast(\"boolean\").alias(\"is_refurbished\"),\n",
                "        f.col(\"data.location.latitude\").cast(\"double\").alias(\"latitude\"),\n",
                "        f.col(\"data.location.longitude\").cast(\"double\").alias(\"longitude\"),\n",
                "        f.col(\"data.location.postal_code\").cast(\"string\").alias(\"postal_code\"),\n",
                "        f.col(\"data.location.city\").cast(\"string\").alias(\"city\"),\n",
                "        f.col(\"data.location.region\").cast(\"string\").alias(\"region\"),\n",
                "        f.col(\"data.location.region2\").cast(\"string\").alias(\"region2\"),\n",
                "        f.col(\"data.location.country_code\").cast(\"string\").alias(\"country_code\"),\n",
                "        f.col(\"data.price.amount\").cast(\"double\").alias(\"amount\"),\n",
                "        f.col(\"data.price.currency\").cast(\"string\").alias(\"currency\"),\n",
                "        f.col(\"data.reserved.flag\").alias(\"reserved\"),\n",
                "        f.col(\"data.shipping.item_is_shippable\")\n",
                "        .cast(\"boolean\")\n",
                "        .alias(\"item_is_shippable\"),\n",
                "        f.col(\"data.shipping.user_allows_shipping\")\n",
                "        .cast(\"boolean\")\n",
                "        .alias(\"user_allows_shipping\"),\n",
                "        f.current_timestamp().alias(\"__timestamp\"),\n",
                "    )\n",
                ")\n",
                "wallapop.printSchema()\n",
                "display(wallapop)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Genial, ya hemos leído y transformado nuestro set de datos inicialmente desestructurado en una tabla bien estructurada, con unos campos y tipos fijados.\n",
                "\n",
                "Ahora, para completar la ETL, almacenaremos esta tabla en el catálogo de datos de Spark. En este caso, al estar trabajando de manera local, dicho catálogo de datos estará localizado en esta misma ruta (`metastore_db/`, `spark-warehouse/`, `derby.log`), sin embargo, cuando trabajemos en un entorno corporativo, habitualmente el catálogo de datos se alojará en una arquitectura cloud, como AWS, Azure, GCP, Databricks, etc.\n",
                "\n",
                "Aunque no es necesario, es una buena práctica crear en primera instancia la tabla Delta sobre la que escribiremos nuestro dataset, con un schema concreto, metadatos, etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/09/28 12:32:44 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
                        "24/09/28 12:32:44 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
                        "24/09/28 12:32:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
                        "24/09/28 12:32:45 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore dadiego@127.0.1.1\n",
                        "24/09/28 12:32:45 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
                        "24/09/28 12:32:47 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`default`.`wallapop` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
                        "24/09/28 12:32:47 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
                        "24/09/28 12:32:47 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
                        "24/09/28 12:32:47 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
                        "24/09/28 12:32:47 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
                    ]
                }
            ],
            "source": [
                "dt = (\n",
                "    DeltaTable.createIfNotExists(spark)\n",
                "    .addColumns(wallapop.schema)\n",
                "    .tableName(\"wallapop\")\n",
                "    .comment(\"Tabla de productos de Wallapop\")\n",
                "    .execute()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Con el método `createIfNotExists` estamos indicando que cree únicamente la tabla en el catálogo de datos si esta no existía previamente.\n",
                "\n",
                "Una vez creada la tabla, insertaremos los datos de nuestro DataFrame mediante una operación `merge`. Para ello, identificamos en primer lugar cuáles son los campos que consituyen una clave primaria en la tabla, es decir, un identificador único de cada registro. En este caso, podríamos utilizar por ejemplo la combinación `\"id\"`, `\"user_id\"`; cuando estos campos coincidan entre la tabla fuente y la tabla destino, actualizaremos los registros en el destino, y cuando no coincidan, insertaremos los registros de la fuente en el destino. Esto lo podemos hacer utilizando los métodos del objeto `DeltaTable` dentro de la librería externa `delta-spark` que tenemos instalada en nuestro entorno virtual de Python."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                }
            ],
            "source": [
                "(\n",
                "    dt.alias(\"target\")\n",
                "    .merge(\n",
                "        wallapop.alias(\"source\"),\n",
                "        \"source.id = target.id AND source.user_id = target.user_id\",\n",
                "    )\n",
                "    .whenMatchedUpdateAll()\n",
                "    .whenNotMatchedInsertAll()\n",
                "    .execute()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ya hemos creado la tabla delta y hemos insertado los registros tabulados de la API de Wallapop en la misma. Ahora podemos consultar el catálogo mediante SQL.\n",
                "\n",
                "Primero, utilizaremos una función auxiliar de nuestro propio paquete de Python creado (`blackops`), llamada `get_detailed_tables_info`, para obtener información detallada de todas las tablas de nuestro catálogo de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/09/28 12:32:51 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>namespace</th><th>tableName</th><th></th><th>Catalog</th><th>Comment</th><th>Created By</th><th>Created Time</th><th>Database</th><th>InputFormat</th><th>Last Access</th><th>Location</th><th>OutputFormat</th><th>Owner</th><th>Partition Provider</th><th>Provider</th><th>Serde Library</th><th>Table</th><th>Type</th></tr>\n",
                            "<tr><td></td><td>empleados</td><td></td><td>NULL</td><td>NULL</td><td>Spark </td><td>Sat Sep 28 12:32:32 CEST 2024</td><td>NULL</td><td>NULL</td><td>UNKNOWN</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>empleados</td><td>VIEW</td></tr>\n",
                            "<tr><td>default</td><td>wallapop</td><td></td><td>spark_catalog</td><td>Tabla de productos de Wallapop</td><td>Spark 3.5.3</td><td>Sat Sep 28 12:32:47 CEST 2024</td><td>default</td><td>org.apache.hadoop.mapred.SequenceFileInputFormat</td><td>UNKNOWN</td><td>file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...</td><td>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td><td>dadiego</td><td>Catalog</td><td>delta</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td><td>wallapop</td><td>MANAGED</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+\n",
                            "|namespace|tableName|   |      Catalog|                       Comment| Created By|                 Created Time|Database|                                     InputFormat|Last Access|                                                                                            Location|                                             OutputFormat|  Owner|Partition Provider|Provider|                                     Serde Library|    Table|   Type|\n",
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+\n",
                            "|         |empleados|   |         NULL|                          NULL|     Spark |Sat Sep 28 12:32:32 CEST 2024|    NULL|                                            NULL|    UNKNOWN|                                                                                                NULL|                                                     NULL|   NULL|              NULL|    NULL|                                              NULL|empleados|   VIEW|\n",
                            "|  default| wallapop|   |spark_catalog|Tabla de productos de Wallapop|Spark 3.5.3|Sat Sep 28 12:32:47 CEST 2024| default|org.apache.hadoop.mapred.SequenceFileInputFormat|    UNKNOWN|file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...|org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat|dadiego|           Catalog|   delta|org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe| wallapop|MANAGED|\n",
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "get_detailed_tables_info(spark)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos obtener información concreta de nuestra tabla recién creada, `wallapop`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th></tr>\n",
                            "<tr><td>delta</td><td>7c5731bc-40d6-43a1-be7c-c2f9a2d42497</td><td>spark_catalog.default.wallapop</td><td>Tabla de productos de Wallapop</td><td>file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...</td><td>2024-09-28 12:32:46.382</td><td>2024-09-28 12:32:51.663</td><td>[]</td><td>[]</td><td>1</td><td>17943</td><td>{}</td><td>1</td><td>2</td><td>[appendOnly, invariants]</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
                            "|format|                                  id|                          name|                   description|                                                                                            location|              createdAt|           lastModified|partitionColumns|clusteringColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|           tableFeatures|\n",
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
                            "| delta|7c5731bc-40d6-43a1-be7c-c2f9a2d42497|spark_catalog.default.wallapop|Tabla de productos de Wallapop|file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...|2024-09-28 12:32:46.382|2024-09-28 12:32:51.663|              []|               []|       1|      17943|        {}|               1|               2|[appendOnly, invariants]|\n",
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dt.detail()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "También podemos obtener una traza histórica de las veces que esta tabla se ha modificado, lo cual es enormemente útil de cara a disponer de un gobierno del dato escalable y robusto"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr>\n",
                            "<tr><td>1</td><td>2024-09-28 12:32:51.663</td><td>NULL</td><td>NULL</td><td>MERGE</td><td>{predicate -&gt; [&quot;((id#643 = id#982) AND (user_id#645 = user_id#984))&quot;], matchedPredicates -&gt; [{&quot;ac...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>0</td><td>Serializable</td><td>false</td><td>{numTargetRowsCopied -&gt; 0, numTargetRowsDeleted -&gt; 0, numTargetFilesAdded -&gt; 1, numTargetBytesAdd...</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.0</td></tr>\n",
                            "<tr><td>0</td><td>2024-09-28 12:32:46.548</td><td>NULL</td><td>NULL</td><td>CREATE TABLE</td><td>{partitionBy -&gt; [], clusterBy -&gt; [], description -&gt; Tabla de productos de Wallapop, isManaged -&gt; ...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>Serializable</td><td>true</td><td>{}</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.0</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
                            "|version|              timestamp|userId|userName|   operation|                                                                                 operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                    operationMetrics|userMetadata|                         engineInfo|\n",
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
                            "|      1|2024-09-28 12:32:51.663|  NULL|    NULL|       MERGE|{predicate -> [\"((id#643 = id#982) AND (user_id#645 = user_id#984))\"], matchedPredicates -> [{\"ac...|NULL|    NULL|     NULL|          0|  Serializable|        false|{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdd...|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.0|\n",
                            "|      0|2024-09-28 12:32:46.548|  NULL|    NULL|CREATE TABLE|{partitionBy -> [], clusterBy -> [], description -> Tabla de productos de Wallapop, isManaged -> ...|NULL|    NULL|     NULL|       NULL|  Serializable|         true|                                                                                                  {}|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.0|\n",
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dt.history()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vemos como en el histórico aparecen las dos operaciones que hemos ejecutado sobre esta tabla Delta: la operación de creación de la tabla, y la operación de merge para insertar los nuevos datos.\n",
                "\n",
                "Podemos también ejecutar cualquier operación SQL con esta tabla del catálogo. Por ejemplo, veamos una tabla resumen de cuántos productos existen por comunidad y código postal, ordenada de mayor a menor cantidad de productos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>region</th><th>postal_code</th><th>n_products</th></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28010</td><td>5</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28033</td><td>3</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28100</td><td>3</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28043</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28037</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28801</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28035</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28607</td><td>1</td></tr>\n",
                            "<tr><td>Castilla-La Mancha</td><td>19002</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28916</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28700</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28030</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28230</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28047</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28911</td><td>1</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-------------------+-----------+----------+\n",
                            "|             region|postal_code|n_products|\n",
                            "+-------------------+-----------+----------+\n",
                            "|Comunidad de Madrid|      28010|         5|\n",
                            "|Comunidad de Madrid|      28033|         3|\n",
                            "|Comunidad de Madrid|      28100|         3|\n",
                            "|Comunidad de Madrid|      28043|         2|\n",
                            "|Comunidad de Madrid|      28037|         2|\n",
                            "|Comunidad de Madrid|      28801|         2|\n",
                            "|Comunidad de Madrid|      28035|         2|\n",
                            "|Comunidad de Madrid|      28607|         1|\n",
                            "| Castilla-La Mancha|      19002|         1|\n",
                            "|Comunidad de Madrid|      28916|         1|\n",
                            "|Comunidad de Madrid|      28700|         1|\n",
                            "|Comunidad de Madrid|      28030|         1|\n",
                            "|Comunidad de Madrid|      28230|         1|\n",
                            "|Comunidad de Madrid|      28047|         1|\n",
                            "|Comunidad de Madrid|      28911|         1|\n",
                            "+-------------------+-----------+----------+"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "spark.sql(\n",
                "    \"select region, postal_code, count(*) as n_products from wallapop group by region, postal_code order by n_products desc limit 15\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
