{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introducción\n",
                "En este Notebook aprenderemos las operaciones básicas más utilizadas en PySpark, incluyendo un ejercicio práctico en el que realizaremos una pequeña ETL para extraer unos datos desde una API y los volcaremos en el catálogo de datos de Spark."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Importación de módulos requeridos\n",
                "En primer lugar necesitamos importar las funciones y objetos requeridos para la implementación.\n",
                "\n",
                "- `SparkSession`: objeto necesario para la interacción con la herramienta de Spark a través de Python.\n",
                "- `pyspark.sql.functions`: funciones de SQL que ofrece pyspark, necesarias para las transformaciones de los datos en la ETL.\n",
                "- `fetch_api, save_json`: estas funciones están definidas dentro de nuestra propia librería llamada `blackops`. Contienen el código necesario para extraer y almacenar los datos de la API.\n",
                "- `date, timedelta`: funciones para crear objetos de tipo fecha y timestamp dentro de Python.\n",
                "- `random`: módulo utilizado para la generación de datos aleatorios.\n",
                "- `DeltaTable`: objeto para interaccionar con tablas de tipo Delta. Se trata de un formato ampliamente utilizado en Spark, que ofrece muchas funcionalidades añadidas a nuestro catálogo de datos, como por ejemplo la posibilidad de revertir cambios."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "import pyspark.sql.functions as f\n",
                "from blackops.crawlers.wallapop.functions import fetch_api\n",
                "from blackops.utils.io import save_json\n",
                "from blackops.utils.catalog import get_detailed_tables_info\n",
                "from datetime import date, timedelta\n",
                "import random\n",
                "from delta import DeltaTable"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Establecemos una semilla para la generación de números aleatorios. De esta manera, los resultados serán reproducibles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "random.seed(45)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inicialización de la sesión de Spark\n",
                "\n",
                "Establecemos ahora la comunicación con el motor de Spark desde Python, a través del objeto `SparkSession` de la librería `pyspark`.\n",
                "\n",
                "En este caso de prueba no estamos utilizando un clúster, sino que haremos uso de una arquitectura local. El propio Jupyter Notebook ejercerá como Driver, como Master y como Ejecutor de las tareas.\n",
                "\n",
                "Adicionalmente, estamos instalando dependencias externas como la librería Delta, que incorpora utilidades muy importantes para el manejo de las tablas en nuestro catálogo de datos (histórico de versiones de tablas, omisión de ficheros innecesarios en la lectura, etc.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/09/29 17:59:22 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.1.40 instead (on interface enp3s0)\n",
                        "24/09/29 17:59:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
                        "Ivy Default Cache set to: /home/dadiego/.ivy2/cache\n",
                        "The jars for the packages stored in: /home/dadiego/.ivy2/jars\n",
                        "io.delta#delta-spark_2.12 added as a dependency\n",
                        ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d3d3f7a1-71b1-4842-be34-4d9fe2d3c810;1.0\n",
                        "\tconfs: [default]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ":: loading settings :: url = jar:file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/.venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
                        "\tfound io.delta#delta-storage;3.2.0 in central\n",
                        "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
                        ":: resolution report :: resolve 101ms :: artifacts dl 4ms\n",
                        "\t:: modules in use:\n",
                        "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
                        "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
                        "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
                        "\t---------------------------------------------------------------------\n",
                        "\t|                  |            modules            ||   artifacts   |\n",
                        "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
                        "\t---------------------------------------------------------------------\n",
                        "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
                        "\t---------------------------------------------------------------------\n",
                        ":: retrieving :: org.apache.spark#spark-submit-parent-d3d3f7a1-71b1-4842-be34-4d9fe2d3c810\n",
                        "\tconfs: [default]\n",
                        "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
                        "24/09/29 17:59:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
                    ]
                }
            ],
            "source": [
                "spark = (\n",
                "    SparkSession.Builder()\n",
                "    .master(\"local[*]\")\n",
                "    .config(\n",
                "        map={\n",
                "            \"spark.driver.memory\": \"8g\",\n",
                "            \"spark.jars.packages\": \"io.delta:delta-spark_2.12:3.2.0\",\n",
                "            \"spark.sql.extensions\": \"io.delta.sql.DeltaSparkSessionExtension\",\n",
                "            \"spark.sql.catalog.spark_catalog\": \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
                "            \"spark.databricks.delta.retentionDurationCheck.enabled\": \"false\",\n",
                "            \"spark.sql.catalogImplementation\": \"hive\",\n",
                "            \"spark.sql.repl.eagerEval.enabled\": \"true\",\n",
                "            \"spark.sql.repl.eagerEval.truncate\": \"100\",\n",
                "        }\n",
                "    )\n",
                "    .getOrCreate()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez se ha inicializado la sesión, podemos acceder a la web `localhost:4040` para consultar la interfaz de administración que ofrece Spark. Allí, se podrá monitorizar las tareas que se mandan desde el Driver.\n",
                "\n",
                "**Nota**: Si al inicializar la sesión de Spark obtenemos algún error en el que se nos indica que la variable `JAVA_HOME` no existe, lo más probable es que no tengamos instalado Java en nuestro sistema, y necesitamos instalarlo ya que Spark depende de Java para su funcionamiento. Para ello, en Linux podemos utilizar el gestor de paquetes: `sudo apt update && sudo apt install openjdk-17-jdk -y`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Creación de un DataFrame de Spark\n",
                "\n",
                "En Spark podemos crear directamente un Dataframe a partir de una lista de datos, o bien de un Dataframe de pandas. Para ello se puede utilizar el método `spark.createDataFrame`.\n",
                "Debemos especificar tanto los datos como el esquema que tiene el Dataframe (sus columnas y sus tipos).\n",
                "\n",
                "En este caso hacemos uso del paquete `random` para generar datos aleatorios (pero reproducibles, al haber establecido una semilla)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Podemos especificar el esquema del DataFrame usando una cadena de texto\n",
                "schema = \"id INT, nombre STRING, edad INT, salario FLOAT, es_empleado BOOLEAN, fecha_contratacion DATE, departamento STRING\"\n",
                "\n",
                "# Crear una lista de datos ficticios\n",
                "nombres = [\n",
                "    \"Juan\",\n",
                "    \"María\",\n",
                "    \"Pedro\",\n",
                "    \"Ana\",\n",
                "    \"Luis\",\n",
                "    \"Carla\",\n",
                "    \"Miguel\",\n",
                "    \"Sara\",\n",
                "    \"David\",\n",
                "    \"Laura\",\n",
                "]\n",
                "departamentos = [\"Ventas\", \"Marketing\", \"Finanzas\", \"IT\", \"RRHH\"]\n",
                "\n",
                "data = [\n",
                "    (\n",
                "        i,  # id\n",
                "        random.choice(nombres),  # nombre\n",
                "        random.randint(22, 60),  # edad\n",
                "        round(random.uniform(20000, 80000), 2),  # salario\n",
                "        random.choice([True, False]),  # es_empleado\n",
                "        date(2024, 10, 1)\n",
                "        - timedelta(days=random.randint(0, 3650)),  # fecha_contratacion\n",
                "        random.choice(departamentos),  # departamento\n",
                "    )\n",
                "    for i in range(1, 31)  # Genera 30 registros aleatorios\n",
                "]\n",
                "\n",
                "# Crear el DataFrame usando el esquema en string\n",
                "df = spark.createDataFrame(data, schema)\n",
                "\n",
                "# Creamos una vista temporal del DataFrame en el catálogo, para poder hacer consultas en SQL.\n",
                "df.createOrReplaceTempView(\"empleados\")\n",
                "\n",
                "# Mostramos el DataFrame resultante por pantalla\n",
                "display(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Operaciones de transformación\n",
                "\n",
                "La sintaxis de Spark es muy similar a la del lenguaje SQL, de hecho, admite la introducción de comandos SQL para realizar las transformaciones de los datos. Vamos a ver algunas de las operaciones más habituales.\n",
                "\n",
                "### Select\n",
                "\n",
                "La operación más sencilla consiste en seleccionar simplemente un subconjunto de los datos, sin ninguna otra operación de transformación o filtro añadido. Por ejemplo, seleccionemos únicamente los campos `id` y `nombre`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>8</td><td>David</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td></tr>\n",
                            "<tr><td>12</td><td>David</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+\n",
                            "| id|nombre|\n",
                            "+---+------+\n",
                            "|  1|  Luis|\n",
                            "|  2|  Juan|\n",
                            "|  3|  Luis|\n",
                            "|  4| Pedro|\n",
                            "|  5|Miguel|\n",
                            "|  6|  Luis|\n",
                            "|  7| María|\n",
                            "|  8| David|\n",
                            "|  9|  Sara|\n",
                            "| 10|   Ana|\n",
                            "| 11|Miguel|\n",
                            "| 12| David|\n",
                            "| 13| Laura|\n",
                            "| 14| Pedro|\n",
                            "| 15| María|\n",
                            "| 16|  Sara|\n",
                            "| 17|   Ana|\n",
                            "| 18|  Sara|\n",
                            "| 19| María|\n",
                            "| 20| Pedro|\n",
                            "+---+------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.select(\"id\", \"nombre\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Al igual que en SQL estándar, podemos no solo seleccionar unas columnas sino aplicarles alguna función de transformación dentro del propio comando SELECT, y renombrarlas utilizando un alias.\n",
                "\n",
                "Las funciones SQL en Spark están contenidas en el módulo `pyspark.sql.functions`, que hemos importado al principio y lo hemos almacenado en un objeto con alias `f` (por sencillez de uso).\n",
                "\n",
                "Vamos a seleccionar en este caso los mismos campos que en el ejemplo anterior, sin embargo, al campo `nombre` le vamos a aplicar una transformación para visualizar el nombre en mayúsculas, y al resultado lo renombraremos `nombre_en_mayusculas`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre_en_mayusculas</th></tr>\n",
                            "<tr><td>1</td><td>LUIS</td></tr>\n",
                            "<tr><td>2</td><td>JUAN</td></tr>\n",
                            "<tr><td>3</td><td>LUIS</td></tr>\n",
                            "<tr><td>4</td><td>PEDRO</td></tr>\n",
                            "<tr><td>5</td><td>MIGUEL</td></tr>\n",
                            "<tr><td>6</td><td>LUIS</td></tr>\n",
                            "<tr><td>7</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>8</td><td>DAVID</td></tr>\n",
                            "<tr><td>9</td><td>SARA</td></tr>\n",
                            "<tr><td>10</td><td>ANA</td></tr>\n",
                            "<tr><td>11</td><td>MIGUEL</td></tr>\n",
                            "<tr><td>12</td><td>DAVID</td></tr>\n",
                            "<tr><td>13</td><td>LAURA</td></tr>\n",
                            "<tr><td>14</td><td>PEDRO</td></tr>\n",
                            "<tr><td>15</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>16</td><td>SARA</td></tr>\n",
                            "<tr><td>17</td><td>ANA</td></tr>\n",
                            "<tr><td>18</td><td>SARA</td></tr>\n",
                            "<tr><td>19</td><td>MAR&Iacute;A</td></tr>\n",
                            "<tr><td>20</td><td>PEDRO</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+--------------------+\n",
                            "| id|nombre_en_mayusculas|\n",
                            "+---+--------------------+\n",
                            "|  1|                LUIS|\n",
                            "|  2|                JUAN|\n",
                            "|  3|                LUIS|\n",
                            "|  4|               PEDRO|\n",
                            "|  5|              MIGUEL|\n",
                            "|  6|                LUIS|\n",
                            "|  7|               MARÍA|\n",
                            "|  8|               DAVID|\n",
                            "|  9|                SARA|\n",
                            "| 10|                 ANA|\n",
                            "| 11|              MIGUEL|\n",
                            "| 12|               DAVID|\n",
                            "| 13|               LAURA|\n",
                            "| 14|               PEDRO|\n",
                            "| 15|               MARÍA|\n",
                            "| 16|                SARA|\n",
                            "| 17|                 ANA|\n",
                            "| 18|                SARA|\n",
                            "| 19|               MARÍA|\n",
                            "| 20|               PEDRO|\n",
                            "+---+--------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.select(\"id\", f.upper(\"nombre\").alias(\"nombre_en_mayusculas\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### WithColumn\n",
                "\n",
                "Podemos añadir campos nuevos derivados a partir de otros campos utilizando el método `withColumn`. Este comando conservará todas las columnas de la tabla, y añadirá una adicional, con las transformaciones que le indiquemos.\n",
                "\n",
                "Este método opera fila a fila, es decir, aplicará las transformaciones correspondientes registro a registro.\n",
                "\n",
                "Por ejemplo, en nuestra tabla disponemos del campo `edad`, pero supongamos que nos interesa, para nuestra analítica, disponer de un campo con el año de nacimiento. En tal caso, podríamos concatenar dos funciones SQL: con la primera, `current_date`, extraemos la fecha actual, y sobre dicha fecha aplicamos la función `year` para extraer el año. Finalmente, a este año actual le restamos la edad que tiene el usuario para así calcular su año de nacimiento. Cada usuario dispondrá así de un año de nacimiento (transformación fila a fila)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th><th>a&ntilde;o_nacimiento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td><td>1976</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td><td>1998</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td><td>2000</td></tr>\n",
                            "<tr><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>RRHH</td><td>1989</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td><td>1993</td></tr>\n",
                            "<tr><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>IT</td><td>1980</td></tr>\n",
                            "<tr><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>IT</td><td>2001</td></tr>\n",
                            "<tr><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>Ventas</td><td>1968</td></tr>\n",
                            "<tr><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>Ventas</td><td>1979</td></tr>\n",
                            "<tr><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>Marketing</td><td>1971</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td><td>1978</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td><td>1997</td></tr>\n",
                            "<tr><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>Finanzas</td><td>2001</td></tr>\n",
                            "<tr><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>IT</td><td>1991</td></tr>\n",
                            "<tr><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>Finanzas</td><td>2002</td></tr>\n",
                            "<tr><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>RRHH</td><td>1974</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td><td>1971</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td><td>1996</td></tr>\n",
                            "<tr><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>RRHH</td><td>1998</td></tr>\n",
                            "<tr><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>IT</td><td>1997</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|año_nacimiento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|          1976|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|          1998|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|          2000|\n",
                            "|  4| Pedro|  35|79554.92|      false|        2023-11-29|        RRHH|          1989|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|          1993|\n",
                            "|  6|  Luis|  44|66505.58|      false|        2023-09-13|          IT|          1980|\n",
                            "|  7| María|  23|65070.76|      false|        2015-12-18|          IT|          2001|\n",
                            "|  8| David|  56|72059.12|      false|        2018-02-06|      Ventas|          1968|\n",
                            "|  9|  Sara|  45|74705.86|      false|        2023-01-02|      Ventas|          1979|\n",
                            "| 10|   Ana|  53|62691.89|      false|        2021-06-16|   Marketing|          1971|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|          1978|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|          1997|\n",
                            "| 13| Laura|  23|57455.18|      false|        2021-03-08|    Finanzas|          2001|\n",
                            "| 14| Pedro|  33|20602.28|      false|        2024-03-12|          IT|          1991|\n",
                            "| 15| María|  22|57444.64|      false|        2017-10-22|    Finanzas|          2002|\n",
                            "| 16|  Sara|  50|32029.18|      false|        2022-01-13|        RRHH|          1974|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|          1971|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|          1996|\n",
                            "| 19| María|  26|61548.89|      false|        2015-11-03|        RRHH|          1998|\n",
                            "| 20| Pedro|  27|59899.06|      false|        2015-02-25|          IT|          1997|\n",
                            "+---+------+----+--------+-----------+------------------+------------+--------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.withColumn(\"año_nacimiento\", f.year(f.current_date()) - f.col(\"edad\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Filter\n",
                "\n",
                "Podemos filtrar los datos de acuerdo a alguna condición especificada. Esta sentencia se corresponde con el comando `WHERE` en SQL. Por ejemplo, queremos obtener únicamente los datos de los empleados. \n",
                "\n",
                "Recordemos que en Python el operador de igualdad es `==`.\n",
                "\n",
                "Para poder realizar operaciones con columnas, necesitamos especificar que se trata de una columna del DataFrame haciendo uso de la función `col`, puesto que si no lo que estaríamos es comparando un string con un booleano (`\"es_empleado\" == True`), que será siempre igual a `False`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>departamento</th></tr>\n",
                            "<tr><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>Finanzas</td></tr>\n",
                            "<tr><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>Ventas</td></tr>\n",
                            "<tr><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>Finanzas</td></tr>\n",
                            "<tr><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>Finanzas</td></tr>\n",
                            "<tr><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>IT</td></tr>\n",
                            "<tr><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>RRHH</td></tr>\n",
                            "<tr><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>Finanzas</td></tr>\n",
                            "<tr><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>Ventas</td></tr>\n",
                            "<tr><td>23</td><td>Carla</td><td>50</td><td>73172.89</td><td>true</td><td>2015-08-21</td><td>IT</td></tr>\n",
                            "<tr><td>25</td><td>Sara</td><td>59</td><td>59973.55</td><td>true</td><td>2018-04-23</td><td>Marketing</td></tr>\n",
                            "<tr><td>29</td><td>Miguel</td><td>37</td><td>69922.06</td><td>true</td><td>2023-10-26</td><td>Finanzas</td></tr>\n",
                            "<tr><td>30</td><td>Luis</td><td>27</td><td>70247.43</td><td>true</td><td>2020-05-23</td><td>Finanzas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "| id|nombre|edad| salario|es_empleado|fecha_contratacion|departamento|\n",
                            "+---+------+----+--------+-----------+------------------+------------+\n",
                            "|  1|  Luis|  48|49281.69|       true|        2021-05-09|    Finanzas|\n",
                            "|  2|  Juan|  26|49055.36|       true|        2021-07-27|      Ventas|\n",
                            "|  3|  Luis|  24|73947.68|       true|        2023-03-28|    Finanzas|\n",
                            "|  5|Miguel|  31|62027.07|       true|        2022-10-27|    Finanzas|\n",
                            "| 11|Miguel|  46|70126.54|       true|        2018-03-14|          IT|\n",
                            "| 12| David|  27|53608.56|       true|        2014-11-09|        RRHH|\n",
                            "| 17|   Ana|  53| 21659.3|       true|        2018-01-19|    Finanzas|\n",
                            "| 18|  Sara|  28|30491.18|       true|        2015-12-13|      Ventas|\n",
                            "| 23| Carla|  50|73172.89|       true|        2015-08-21|          IT|\n",
                            "| 25|  Sara|  59|59973.55|       true|        2018-04-23|   Marketing|\n",
                            "| 29|Miguel|  37|69922.06|       true|        2023-10-26|    Finanzas|\n",
                            "| 30|  Luis|  27|70247.43|       true|        2020-05-23|    Finanzas|\n",
                            "+---+------+----+--------+-----------+------------------+------------+"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(f.col(\"es_empleado\") == True)\n",
                "\n",
                "# Si hacemos df.filter(\"es_empleado\" == True) obtendremos un error porque los tipos no son los esperados."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Agrupaciones\n",
                "\n",
                "Utilizando el comando group by, podemos agrupar nuestro dataset según los valores de una o varias columnas y posteriormente realizar una operación de agregación sobre cada conjunto, para así obtener estadísticas descriptivas de nuestros datos.\n",
                "\n",
                "Por ejemplo, podemos obtener el número de empleados en marketing, con lo cual debemos agrupar por departamento y realizar una operación de agregación de suma. Estas operaciones se denominan \"de agregación\" o \"de reducción\" porque actúan sobre un conjunto de filas (todas aquellas que comparten el mismo valor del grupo) y devuelven un único valor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>salario_total</th></tr>\n",
                            "<tr><td>Finanzas</td><td>524206.53515625</td></tr>\n",
                            "<tr><td>Ventas</td><td>421618.7890625</td></tr>\n",
                            "<tr><td>RRHH</td><td>292734.91015625</td></tr>\n",
                            "<tr><td>IT</td><td>355377.107421875</td></tr>\n",
                            "<tr><td>Marketing</td><td>122665.44140625</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+----------------+\n",
                            "|departamento|   salario_total|\n",
                            "+------------+----------------+\n",
                            "|    Finanzas| 524206.53515625|\n",
                            "|      Ventas|  421618.7890625|\n",
                            "|        RRHH| 292734.91015625|\n",
                            "|          IT|355377.107421875|\n",
                            "|   Marketing| 122665.44140625|\n",
                            "+------------+----------------+"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.groupBy(\"departamento\").agg(f.sum(\"salario\").alias(\"salario_total\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Combinaciones\n",
                "Naturalmente, la riqueza de PySpark es que podemos combinar filtros con agrupaciones, adición de columnas, cambios de tipos, etc para que nuestro dato final quede pulido.\n",
                "\n",
                "Al contrario que en Pandas, todas las operaciones de transformación en Spark son *lazy*, es decir, no se evalúan hasta que se pide una acción (resultado). Esto permite que el catalizador de Spark optimice toda la cadena de consultas de la manera más apropiada antes de ser ejecutadas.\n",
                "\n",
                "Veamos un ejemplo de consulta algo más avanzada: supongamos que queremos conocer cuál es el departamento del que más gente se ha ido a partir de 2017 para unos ciertos intervalos de meses: enero a mayo, junio a septiembre y octubre a diciembre. En este caso podemos comenzar aplicando unos filtros para quedarnos únicamente con registros de los que actualmente ya no son empleados y su fecha de contratación es igual o posterior a 2017. Después de aplicar dicho filtro, podemos añadir dos columnas transitorias para extraer el mes de la fecha de contratación y establecer los intervalos pedidos, utilizando la función `when`, que es esquivalente al `CASE` de SQL. Finalmente, agrupamos por estas categorías de mes y agregamos cogiendo la moda (el valor más repetido de un conjunto de datos)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>categoria_mes</th><th>departamento_mas_repetido</th></tr>\n",
                            "<tr><td>octubre-diciembre</td><td>RRHH</td></tr>\n",
                            "<tr><td>junio-septiembre</td><td>Marketing</td></tr>\n",
                            "<tr><td>enero-mayo</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-----------------+-------------------------+\n",
                            "|    categoria_mes|departamento_mas_repetido|\n",
                            "+-----------------+-------------------------+\n",
                            "|octubre-diciembre|                     RRHH|\n",
                            "| junio-septiembre|                Marketing|\n",
                            "|       enero-mayo|                   Ventas|\n",
                            "+-----------------+-------------------------+"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.filter(\n",
                "    (f.col(\"es_empleado\") == False) & (f.year(\"fecha_contratacion\") >= 2017)\n",
                ").withColumn(\"mes_contratacion\", f.month(\"fecha_contratacion\")).withColumn(\n",
                "    \"categoria_mes\",\n",
                "    f.when(f.col(\"mes_contratacion\").between(1, 5), f.lit(\"enero-mayo\"))\n",
                "    .when(f.col(\"mes_contratacion\").between(6, 9), f.lit(\"junio-septiembre\"))\n",
                "    .otherwise(f.lit(\"octubre-diciembre\")),\n",
                ").groupBy(\n",
                "    \"categoria_mes\"\n",
                ").agg(\n",
                "    f.mode(\"departamento\").alias(\"departamento_mas_repetido\")\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "La consulta equivalente en Spark SQL en este caso sería la siguiente"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>categoria_mes</th><th>departamento_mas_repetido</th></tr>\n",
                            "<tr><td>octubre-diciembre</td><td>RRHH</td></tr>\n",
                            "<tr><td>junio-septiembre</td><td>Marketing</td></tr>\n",
                            "<tr><td>enero-mayo</td><td>Ventas</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-----------------+-------------------------+\n",
                            "|    categoria_mes|departamento_mas_repetido|\n",
                            "+-----------------+-------------------------+\n",
                            "|octubre-diciembre|                     RRHH|\n",
                            "| junio-septiembre|                Marketing|\n",
                            "|       enero-mayo|                   Ventas|\n",
                            "+-----------------+-------------------------+"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "spark.sql(\n",
                "    \"\"\"\n",
                "    SELECT\n",
                "        CASE\n",
                "            WHEN MONTH(fecha_contratacion) BETWEEN 1 AND 5 THEN 'enero-mayo'\n",
                "            WHEN MONTH(fecha_contratacion) BETWEEN 6 AND 9 THEN 'junio-septiembre'\n",
                "            ELSE 'octubre-diciembre'\n",
                "        END AS categoria_mes,\n",
                "        MODE(departamento) AS departamento_mas_repetido\n",
                "\n",
                "    FROM empleados\n",
                "    WHERE\n",
                "        es_empleado = false AND\n",
                "        YEAR(fecha_contratacion) >= 2017\n",
                "    GROUP BY categoria_mes\n",
                "    \"\"\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como se puede comprobar, se obtienen exactamente los mismos resultados"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Joins\n",
                "Al igual que las operaciones de transformación, otro comando importante es el de JOIN, que nos permite establecer links entre campos de diferentes columnas, lo cual resulta fundamental para el análisis desde diferentes fuentes de datos.\n",
                "\n",
                "Un análisis detallado y extenso de los diferentes tipos de Joins en Pyspark puede verse [aquí](https://sparkbyexamples.com/pyspark/pyspark-join-explained-with-examples/).\n",
                "\n",
                "Esquemáticamente tenemos los siguientes tipos de JOINs:\n",
                "\n",
                "![tipos de joins](joins.png \"Tipos de Joins\")\n",
                "\n",
                "Por poner un ejemplo, creemos un segundo dataframe con información añadida de los departamentos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>departamento</th><th>descripcion</th></tr>\n",
                            "<tr><td>1</td><td>Finanzas</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>2</td><td>Ventas</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---+------------+------------------------------------------------------------------------+\n",
                            "| id|departamento|                                                             descripcion|\n",
                            "+---+------------+------------------------------------------------------------------------+\n",
                            "|  1|    Finanzas|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|  2|      Ventas|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "+---+------------+------------------------------------------------------------------------+"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "departamentos = spark.createDataFrame(\n",
                "    [\n",
                "        (\n",
                "            1,\n",
                "            \"Finanzas\",\n",
                "            \"Departamento encargado de elaborar informes financieros trimestrales\",\n",
                "        ),\n",
                "        (\n",
                "            2,\n",
                "            \"Ventas\",\n",
                "            \"Departamento encargado de contactar con proveedores y registrar el stock\",\n",
                "        ),\n",
                "    ], schema=\"id int, departamento string, descripcion string\"\n",
                ")\n",
                "display(departamentos)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Y ahora vamos a unir nuestra tabla de origen con esta tabla de información extendida por departamento. El campo de unión lógicamente será la columna `\"departamento\"`.\n",
                "\n",
                "Empecemos con un INNER JOIN. En este caso, únicamente se mostrarán los departamentos de Finanzas y Ventas, ya que son los únicos registros comunes a ambas tablas (el resto de departamentos no está presente en la tabla `departamentos`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>id</th><th>descripcion</th></tr>\n",
                            "<tr><td>Finanzas</td><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>22</td><td>Juan</td><td>26</td><td>39267.68</td><td>false</td><td>2022-02-16</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>26</td><td>Ana</td><td>25</td><td>22953.8</td><td>false</td><td>2018-05-11</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>29</td><td>Miguel</td><td>37</td><td>69922.06</td><td>true</td><td>2023-10-26</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>30</td><td>Luis</td><td>27</td><td>70247.43</td><td>true</td><td>2020-05-23</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>24</td><td>David</td><td>56</td><td>62486.47</td><td>false</td><td>2018-02-17</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>27</td><td>Carla</td><td>50</td><td>68186.09</td><td>false</td><td>2018-02-04</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>28</td><td>Miguel</td><td>51</td><td>64634.71</td><td>false</td><td>2018-05-29</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion| id|                                                             descripcion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+\n",
                            "|    Finanzas|  1|  Luis|  48|49281.69|       true|        2021-05-09|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  3|  Luis|  24|73947.68|       true|        2023-03-28|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  5|Miguel|  31|62027.07|       true|        2022-10-27|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 13| Laura|  23|57455.18|      false|        2021-03-08|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 15| María|  22|57444.64|      false|        2017-10-22|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 17|   Ana|  53| 21659.3|       true|        2018-01-19|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 22|  Juan|  26|39267.68|      false|        2022-02-16|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 26|   Ana|  25| 22953.8|      false|        2018-05-11|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 29|Miguel|  37|69922.06|       true|        2023-10-26|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas| 30|  Luis|  27|70247.43|       true|        2020-05-23|  1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas|  2|  Juan|  26|49055.36|       true|        2021-07-27|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  8| David|  56|72059.12|      false|        2018-02-06|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  9|  Sara|  45|74705.86|      false|        2023-01-02|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 18|  Sara|  28|30491.18|       true|        2015-12-13|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 24| David|  56|62486.47|      false|        2018-02-17|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 27| Carla|  50|68186.09|      false|        2018-02-04|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas| 28|Miguel|  51|64634.71|      false|        2018-05-29|  2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "+------------+---+------+----+--------+-----------+------------------+---+------------------------------------------------------------------------+"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"inner\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora haremos un LEFT JOIN. En este caso se mostrarán todos los registros de la tabla de origen, con todos los departamentos por tanto. Y si existe un departamento equivalente en la tabla derecha, se mostrará también su información adicional. En caso de no existir un match (cuando el departamento no sea el de ventas o finanzas), dicha información adicional será nula"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th><th>id</th><th>descripcion</th></tr>\n",
                            "<tr><td>Finanzas</td><td>1</td><td>Luis</td><td>48</td><td>49281.69</td><td>true</td><td>2021-05-09</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Finanzas</td><td>3</td><td>Luis</td><td>24</td><td>73947.68</td><td>true</td><td>2023-03-28</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>2</td><td>Juan</td><td>26</td><td>49055.36</td><td>true</td><td>2021-07-27</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Finanzas</td><td>5</td><td>Miguel</td><td>31</td><td>62027.07</td><td>true</td><td>2022-10-27</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>RRHH</td><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Ventas</td><td>8</td><td>David</td><td>56</td><td>72059.12</td><td>false</td><td>2018-02-06</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Ventas</td><td>9</td><td>Sara</td><td>45</td><td>74705.86</td><td>false</td><td>2023-01-02</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>Marketing</td><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>IT</td><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>13</td><td>Laura</td><td>23</td><td>57455.18</td><td>false</td><td>2021-03-08</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>RRHH</td><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>15</td><td>Mar&iacute;a</td><td>22</td><td>57444.64</td><td>false</td><td>2017-10-22</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>IT</td><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>RRHH</td><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>Finanzas</td><td>17</td><td>Ana</td><td>53</td><td>21659.3</td><td>true</td><td>2018-01-19</td><td>1</td><td>Departamento encargado de elaborar informes financieros trimestrales</td></tr>\n",
                            "<tr><td>Ventas</td><td>18</td><td>Sara</td><td>28</td><td>30491.18</td><td>true</td><td>2015-12-13</td><td>2</td><td>Departamento encargado de contactar con proveedores y registrar el stock</td></tr>\n",
                            "<tr><td>IT</td><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td><td>NULL</td><td>NULL</td></tr>\n",
                            "<tr><td>RRHH</td><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td><td>NULL</td><td>NULL</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion|  id|                                                             descripcion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "|    Finanzas|  1|  Luis|  48|49281.69|       true|        2021-05-09|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|    Finanzas|  3|  Luis|  24|73947.68|       true|        2023-03-28|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas|  2|  Juan|  26|49055.36|       true|        2021-07-27|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|    Finanzas|  5|Miguel|  31|62027.07|       true|        2022-10-27|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|        RRHH|  4| Pedro|  35|79554.92|      false|        2023-11-29|NULL|                                                                    NULL|\n",
                            "|          IT|  6|  Luis|  44|66505.58|      false|        2023-09-13|NULL|                                                                    NULL|\n",
                            "|          IT|  7| María|  23|65070.76|      false|        2015-12-18|NULL|                                                                    NULL|\n",
                            "|      Ventas|  8| David|  56|72059.12|      false|        2018-02-06|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|      Ventas|  9|  Sara|  45|74705.86|      false|        2023-01-02|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|   Marketing| 10|   Ana|  53|62691.89|      false|        2021-06-16|NULL|                                                                    NULL|\n",
                            "|          IT| 11|Miguel|  46|70126.54|       true|        2018-03-14|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 13| Laura|  23|57455.18|      false|        2021-03-08|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|        RRHH| 12| David|  27|53608.56|       true|        2014-11-09|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 15| María|  22|57444.64|      false|        2017-10-22|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|          IT| 14| Pedro|  33|20602.28|      false|        2024-03-12|NULL|                                                                    NULL|\n",
                            "|        RRHH| 16|  Sara|  50|32029.18|      false|        2022-01-13|NULL|                                                                    NULL|\n",
                            "|    Finanzas| 17|   Ana|  53| 21659.3|       true|        2018-01-19|   1|    Departamento encargado de elaborar informes financieros trimestrales|\n",
                            "|      Ventas| 18|  Sara|  28|30491.18|       true|        2015-12-13|   2|Departamento encargado de contactar con proveedores y registrar el stock|\n",
                            "|          IT| 20| Pedro|  27|59899.06|      false|        2015-02-25|NULL|                                                                    NULL|\n",
                            "|        RRHH| 19| María|  26|61548.89|      false|        2015-11-03|NULL|                                                                    NULL|\n",
                            "+------------+---+------+----+--------+-----------+------------------+----+------------------------------------------------------------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"left\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Por último, veamos el caso del LEFT ANTI JOIN. En este caso, se mostrarán únicamente los registros de la tabla origen que no tienen un match con los de la tabla de departamentos; es decir, aquellos registros del dataframe cuyo departamento no es ventas ni finanzas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>departamento</th><th>id</th><th>nombre</th><th>edad</th><th>salario</th><th>es_empleado</th><th>fecha_contratacion</th></tr>\n",
                            "<tr><td>RRHH</td><td>4</td><td>Pedro</td><td>35</td><td>79554.92</td><td>false</td><td>2023-11-29</td></tr>\n",
                            "<tr><td>IT</td><td>6</td><td>Luis</td><td>44</td><td>66505.58</td><td>false</td><td>2023-09-13</td></tr>\n",
                            "<tr><td>IT</td><td>7</td><td>Mar&iacute;a</td><td>23</td><td>65070.76</td><td>false</td><td>2015-12-18</td></tr>\n",
                            "<tr><td>Marketing</td><td>10</td><td>Ana</td><td>53</td><td>62691.89</td><td>false</td><td>2021-06-16</td></tr>\n",
                            "<tr><td>IT</td><td>11</td><td>Miguel</td><td>46</td><td>70126.54</td><td>true</td><td>2018-03-14</td></tr>\n",
                            "<tr><td>RRHH</td><td>12</td><td>David</td><td>27</td><td>53608.56</td><td>true</td><td>2014-11-09</td></tr>\n",
                            "<tr><td>IT</td><td>14</td><td>Pedro</td><td>33</td><td>20602.28</td><td>false</td><td>2024-03-12</td></tr>\n",
                            "<tr><td>RRHH</td><td>16</td><td>Sara</td><td>50</td><td>32029.18</td><td>false</td><td>2022-01-13</td></tr>\n",
                            "<tr><td>IT</td><td>20</td><td>Pedro</td><td>27</td><td>59899.06</td><td>false</td><td>2015-02-25</td></tr>\n",
                            "<tr><td>RRHH</td><td>19</td><td>Mar&iacute;a</td><td>26</td><td>61548.89</td><td>false</td><td>2015-11-03</td></tr>\n",
                            "<tr><td>RRHH</td><td>21</td><td>Luis</td><td>46</td><td>65993.36</td><td>false</td><td>2022-12-04</td></tr>\n",
                            "<tr><td>IT</td><td>23</td><td>Carla</td><td>50</td><td>73172.89</td><td>true</td><td>2015-08-21</td></tr>\n",
                            "<tr><td>Marketing</td><td>25</td><td>Sara</td><td>59</td><td>59973.55</td><td>true</td><td>2018-04-23</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------------+---+------+----+--------+-----------+------------------+\n",
                            "|departamento| id|nombre|edad| salario|es_empleado|fecha_contratacion|\n",
                            "+------------+---+------+----+--------+-----------+------------------+\n",
                            "|        RRHH|  4| Pedro|  35|79554.92|      false|        2023-11-29|\n",
                            "|          IT|  6|  Luis|  44|66505.58|      false|        2023-09-13|\n",
                            "|          IT|  7| María|  23|65070.76|      false|        2015-12-18|\n",
                            "|   Marketing| 10|   Ana|  53|62691.89|      false|        2021-06-16|\n",
                            "|          IT| 11|Miguel|  46|70126.54|       true|        2018-03-14|\n",
                            "|        RRHH| 12| David|  27|53608.56|       true|        2014-11-09|\n",
                            "|          IT| 14| Pedro|  33|20602.28|      false|        2024-03-12|\n",
                            "|        RRHH| 16|  Sara|  50|32029.18|      false|        2022-01-13|\n",
                            "|          IT| 20| Pedro|  27|59899.06|      false|        2015-02-25|\n",
                            "|        RRHH| 19| María|  26|61548.89|      false|        2015-11-03|\n",
                            "|        RRHH| 21|  Luis|  46|65993.36|      false|        2022-12-04|\n",
                            "|          IT| 23| Carla|  50|73172.89|       true|        2015-08-21|\n",
                            "|   Marketing| 25|  Sara|  59|59973.55|       true|        2018-04-23|\n",
                            "+------------+---+------+----+--------+-----------+------------------+"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.join(departamentos, how=\"leftanti\", on=\"departamento\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Caso práctico: Extracción de datos de Wallapop\n",
                "Vamos a construir un pequeño ejemplo de una ETL (Extraction Transform Load). Extraeremos datos en crudo desde la API REST de Wallapop, los guardamos en una carpeta de almacenamiento, los leemos con spark, realizamos algunas transformaciones y almacenamos la tabla resultante en nuestro catálogo de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    json_data = fetch_api(product=\"portátil\")\n",
                "    save_json(obj=json_data, path=\"data/wallapop.json\", indent=4)\n",
                "except Exception as e:\n",
                "    print(f\"Warning: No ha sido posible descargar los datos de la API: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos previsualizar cuál es la estructura de nuestro fichero JSON utilizando el comando externo `cat` de nuestra terminal (válido únicamente en sistemas Unix, con `jq` instalado).\n",
                "\n",
                "Si no está instalado `jq`, puede instalarse mediante `sudo apt update && sudo apt install jq -y`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1;39m{\n",
                        "  \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "    \u001b[0m\u001b[34;1m\"section\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "      \u001b[0m\u001b[34;1m\"payload\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "        \u001b[0m\u001b[34;1m\"order\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"most_relevance\"\u001b[0m\u001b[1;39m,\n",
                        "        \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Find what you want\"\u001b[0m\u001b[1;39m,\n",
                        "        \u001b[0m\u001b[34;1m\"items\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
                        "          \u001b[1;39m{\n",
                        "            \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"wzy4vyvp3vz5\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"user_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"p8j35wm4v7z9\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Funda Portatil\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"¿HAS VUELTO AL INSTITUTO O AL TRABAJO?\\nPues por aqui te dejo una funda perfecta para lo que necesitas! inluso para llevar documnetos tambien!\\nNo dejes que el portatil este tirado por ahi, cuidalo y protegelo con esta funda!\\n\\n*PRECIO NEGOCIABLE*\"\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"category_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m24200\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"price\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
                        "              \u001b[0m\u001b[34;1m\"amount\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m10\u001b[0m\u001b[1;39m,\n",
                        "              \u001b[0m\u001b[34;1m\"currency\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"EUR\"\u001b[0m\u001b[1;39m\n",
                        "            \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
                        "            \u001b[0m\u001b[34;1m\"images\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
                        "              \u001b[1;39m{\n",
                        "                \u001b[0m\u001b[34;1m\"average_color\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"13C1AC\"\u001b[0m\u001b[1;39m,\n"
                    ]
                }
            ],
            "source": [
                "%%sh\n",
                "cat data/wallapop.json | jq -C | head -20"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez determinada la estructura que tiene nuestro fichero JSON de información, notamos que los datos que queremos obtener se encuentran dentro de la ruta `data -> section -> payload -> items`. Dicha ruta se corresponde con un array (lista) de items, que son los productos de Wallapop; cada uno de ellos tiene unos campos, algunos simples como `id`, `user_id`, y otros compuestos como `price -> amount` o `price -> currency`.\n",
                "\n",
                "En primer lugar, observemos que si leemos el fichero JSON directamente no obtenemos una estructura muy amigable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "|                                              data|                                              meta|\n",
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "|{{{[{{none}, 24200, 1727614635913, ¿HAS VUELTO ...|{eyJhbGciOiJIUzI1NiJ9.eyJwYXJhbXMiOnsic2VhcmNoU...|\n",
                        "+--------------------------------------------------+--------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop = spark.read.json(\"data/wallapop.json\", multiLine=True)\n",
                "wallapop.show(truncate=50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esto es porque nos ha cogido las dos primeras claves más externas de nuestro fichero JSON, que son los campos `\"data\"` y `\"meta\"`.\n",
                "\n",
                "Observemos qué estructura hemos cargado haciendo un `printSchema` de nuestro DataFrame. De esta manera obtendremos información de los campos y sus tipos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- data: struct (nullable = true)\n",
                        " |    |-- section: struct (nullable = true)\n",
                        " |    |    |-- payload: struct (nullable = true)\n",
                        " |    |    |    |-- items: array (nullable = true)\n",
                        " |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |-- bump: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- type: string (nullable = true)\n",
                        " |    |    |    |    |    |-- category_id: long (nullable = true)\n",
                        " |    |    |    |    |    |-- created_at: long (nullable = true)\n",
                        " |    |    |    |    |    |-- description: string (nullable = true)\n",
                        " |    |    |    |    |    |-- favorited: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- id: string (nullable = true)\n",
                        " |    |    |    |    |    |-- images: array (nullable = true)\n",
                        " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |    |    |-- average_color: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- urls: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- big: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- medium: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |    |-- small: string (nullable = true)\n",
                        " |    |    |    |    |    |-- is_favoriteable: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- is_refurbished: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- location: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- city: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- country_code: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- latitude: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- longitude: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- postal_code: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- region: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- region2: string (nullable = true)\n",
                        " |    |    |    |    |    |-- modified_at: long (nullable = true)\n",
                        " |    |    |    |    |    |-- price: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- amount: double (nullable = true)\n",
                        " |    |    |    |    |    |    |-- currency: string (nullable = true)\n",
                        " |    |    |    |    |    |-- reserved: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- flag: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- shipping: struct (nullable = true)\n",
                        " |    |    |    |    |    |    |-- cost_configuration_id: string (nullable = true)\n",
                        " |    |    |    |    |    |    |-- item_is_shippable: boolean (nullable = true)\n",
                        " |    |    |    |    |    |    |-- user_allows_shipping: boolean (nullable = true)\n",
                        " |    |    |    |    |    |-- taxonomy: array (nullable = true)\n",
                        " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
                        " |    |    |    |    |    |    |    |-- icon: string (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- id: long (nullable = true)\n",
                        " |    |    |    |    |    |    |    |-- name: string (nullable = true)\n",
                        " |    |    |    |    |    |-- title: string (nullable = true)\n",
                        " |    |    |    |    |    |-- user_id: string (nullable = true)\n",
                        " |    |    |    |    |    |-- web_slug: string (nullable = true)\n",
                        " |    |    |    |-- order: string (nullable = true)\n",
                        " |    |    |    |-- title: string (nullable = true)\n",
                        " |    |    |-- type: string (nullable = true)\n",
                        " |    |-- tracking: struct (nullable = true)\n",
                        " |    |    |-- location: struct (nullable = true)\n",
                        " |    |    |    |-- country_code: string (nullable = true)\n",
                        " |    |    |    |-- latitude: double (nullable = true)\n",
                        " |    |    |    |-- longitude: double (nullable = true)\n",
                        " |    |    |-- variant: string (nullable = true)\n",
                        " |-- meta: struct (nullable = true)\n",
                        " |    |-- next_page: string (nullable = true)\n",
                        " |    |-- next_section_type: string (nullable = true)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.printSchema()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora, para navegar a través de nuestro fichero JSON, podemos utilizar la sintáxis por puntos; es decir, para obtener el campo deseado `\"items\"`, que contiene la información de todos los productos, debemos acceder mediante `data.section.payload.items`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|                                                                                               items|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|[{{none}, 24200, 1727614635913, ¿HAS VUELTO AL INSTITUTO O AL TRABAJO?\\nPues por aqui te dejo una...|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.select(\"data.section.payload.items\").show(truncate=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sin embargo, seguimos sin apreciar una estructura legible. Esto es porque se nos está mostrando un único registro (fila) que contiene toda la información de los productos. Lo que nos interesa es que cada elemento de esta lista se muestre en un registro a parte. Para ello se utiliza la función SQL `explode`, que coge un array de elementos y devuelve un registro por cada uno de esos elementos. Veámoslo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|                                                                                                 col|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "|{{none}, 24200, 1727614635913, ¿HAS VUELTO AL INSTITUTO O AL TRABAJO?\\nPues por aqui te dejo una ...|\n",
                        "|{{none}, 24200, 1727621784191, Portatil Android AIRIS KIRA N10040 en excelente estado excepto la ...|\n",
                        "|{{none}, 24200, 1727620753245, Portatil Compaq con windows 10 HOME.\\n\\nEspecificaciones: (ultima ...|\n",
                        "|{{none}, 24200, 1727608914555, portatil huawei d15\\nse a muerto placa base \\nse puede cambiar pla...|\n",
                        "|{{none}, 24200, 1727620311668, Portatil Samsung con Windows 10 PRO.\\n\\nEspecificaciones: (Ultima ...|\n",
                        "|{{none}, 24200, 1727616187851, Portátil HP                                                      -...|\n",
                        "|{{none}, 24200, 1727615988732, el portátil va perfectamente conectado a cargador. el cargador no ...|\n",
                        "|{{none}, 24200, 1727615300703, lote de portatiles 30€ , {false}, vjrqv4mywlzk, [{13C1AC, {https:/...|\n",
                        "|{{none}, 24200, 1727615200913, HP 15 ( Rt26ns) Windows 10 pro original, Disco solido Samsung 870 ...|\n",
                        "|{{none}, 24200, 1727615455765, Se vende Ordenador portatil Acer Aspire 6930.Con Windows 10 pro, 4...|\n",
                        "|{{none}, 24200, 1727625384113, cable cargador de portatil indicaciones en la foto, {false}, v6ggn...|\n",
                        "|{{none}, 24200, 1727621040394, SOPORTE REPLICADOR PUERTOS EXPANSION DOCK KENSINGTON 1500325A\\n\\nS...|\n",
                        "|{{none}, 24200, 1727604056345, ordenador como nuevo no se a usado mucho lo unico que hay que tene...|\n",
                        "|{{none}, 24200, 1727624211573, Funda de camuflaje de carbono para ordenador portátil. , {false}, ...|\n",
                        "|{{none}, 24200, 1727621426797, Nuevo. Tamaño 10x 5x 3 aproximadamente, {false}, qzme17xn7ljv, [{1...|\n",
                        "|{{none}, 24200, 1727612596766, portatil dell vostro 15 3568. 4 Gb de RAM Y 1T de disco ssdd en bu...|\n",
                        "|{{none}, 24200, 1727540113873, .., {false}, 8z8k98l90lz3, [{13C1AC, {https://cdn.wallapop.com/ima...|\n",
                        "|{{none}, 24200, 1727621822325, Soporte para tablet o portátil., {false}, 36e1g844y8jd, [{13C1AC, ...|\n",
                        "|{{none}, 24200, 1727609907480, grande \\ncon bastantes compartimentos, {false}, pzp23dwlo9j3, [{13...|\n",
                        "|{{zone}, 24200, 1706634689502, Vendo portátil Lenovo IdeaPad 3 en muy buen estado. El portátil ti...|\n",
                        "+----------------------------------------------------------------------------------------------------+\n",
                        "only showing top 20 rows\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "wallapop.select(f.explode(\"data.section.payload.items\")).show(truncate=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Bien, ya hemos avanzado, disponemos ahora de un registro por cada producto de la lista `items`, como queríamos. Sin embargo, se sigue mostrando toda la información en una misma columna. Eso lo solucionamos seleccionando los campos anidados deseados. Por ejemplo, supongamos que queremos coger el `id` del producto, el `user_id` del usuario y la fecha de creación del anuncio `created_at`. Una buena manera de operar sería crear una nueva columna llamada, por ejemplo, `\"data\"`, que contenga los registros explotados del campo de `\"items\"`, y luego utilizar este nuevo campo para obtener la info de los otros campos descendientes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>user_id</th><th>created_at</th></tr>\n",
                            "<tr><td>wzy4vyvp3vz5</td><td>p8j35wm4v7z9</td><td>1727614635913</td></tr>\n",
                            "<tr><td>nz04xroorrjo</td><td>xpzp19l94mz3</td><td>1727621784191</td></tr>\n",
                            "<tr><td>p614153vn265</td><td>kp618yw82dz5</td><td>1727620753245</td></tr>\n",
                            "<tr><td>3zl8x0n02p6x</td><td>7v6g14w1gn6e</td><td>1727608914555</td></tr>\n",
                            "<tr><td>mzn2mwqnd7zn</td><td>kp618yw82dz5</td><td>1727620311668</td></tr>\n",
                            "<tr><td>pj9mqn0e4o6e</td><td>wzvy25d3w4zl</td><td>1727616187851</td></tr>\n",
                            "<tr><td>0j24kno1pezy</td><td>pj9ynq345k6e</td><td>1727615988732</td></tr>\n",
                            "<tr><td>vjrqv4mywlzk</td><td>wzynrx809ej5</td><td>1727615300703</td></tr>\n",
                            "<tr><td>mzn2mwm912zn</td><td>8ejk8lrevpjx</td><td>1727615200913</td></tr>\n",
                            "<tr><td>nzx4vrg58ej2</td><td>nz0my851yejo</td><td>1727615455765</td></tr>\n",
                            "<tr><td>v6ggnoww156e</td><td>kp61om83g7j5</td><td>1727625384113</td></tr>\n",
                            "<tr><td>8z8k95n8v8z3</td><td>p8j3r9n3xyj9</td><td>1727621040394</td></tr>\n",
                            "<tr><td>0j24kn83xrzy</td><td>nzx5rg01n762</td><td>1727604056345</td></tr>\n",
                            "<tr><td>wzv4v2pr07zl</td><td>vjrd45k21l6k</td><td>1727624211573</td></tr>\n",
                            "<tr><td>qzme17xn7ljv</td><td>lqzm42koegzv</td><td>1727621426797</td></tr>\n",
                            "<tr><td>v6ggnovny76e</td><td>v9jdxk7mq4zk</td><td>1727612596766</td></tr>\n",
                            "<tr><td>8z8k98l90lz3</td><td>436ed7nn7kjd</td><td>1727540113873</td></tr>\n",
                            "<tr><td>36e1g844y8jd</td><td>08z85ydyrrz3</td><td>1727621822325</td></tr>\n",
                            "<tr><td>pzp23dwlo9j3</td><td>ke654r0kkgjo</td><td>1727609907480</td></tr>\n",
                            "<tr><td>wzy4n2xov5z5</td><td>vjrkk2lv04zk</td><td>1706634689502</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+------------+-------------+\n",
                            "|          id|     user_id|   created_at|\n",
                            "+------------+------------+-------------+\n",
                            "|wzy4vyvp3vz5|p8j35wm4v7z9|1727614635913|\n",
                            "|nz04xroorrjo|xpzp19l94mz3|1727621784191|\n",
                            "|p614153vn265|kp618yw82dz5|1727620753245|\n",
                            "|3zl8x0n02p6x|7v6g14w1gn6e|1727608914555|\n",
                            "|mzn2mwqnd7zn|kp618yw82dz5|1727620311668|\n",
                            "|pj9mqn0e4o6e|wzvy25d3w4zl|1727616187851|\n",
                            "|0j24kno1pezy|pj9ynq345k6e|1727615988732|\n",
                            "|vjrqv4mywlzk|wzynrx809ej5|1727615300703|\n",
                            "|mzn2mwm912zn|8ejk8lrevpjx|1727615200913|\n",
                            "|nzx4vrg58ej2|nz0my851yejo|1727615455765|\n",
                            "|v6ggnoww156e|kp61om83g7j5|1727625384113|\n",
                            "|8z8k95n8v8z3|p8j3r9n3xyj9|1727621040394|\n",
                            "|0j24kn83xrzy|nzx5rg01n762|1727604056345|\n",
                            "|wzv4v2pr07zl|vjrd45k21l6k|1727624211573|\n",
                            "|qzme17xn7ljv|lqzm42koegzv|1727621426797|\n",
                            "|v6ggnovny76e|v9jdxk7mq4zk|1727612596766|\n",
                            "|8z8k98l90lz3|436ed7nn7kjd|1727540113873|\n",
                            "|36e1g844y8jd|08z85ydyrrz3|1727621822325|\n",
                            "|pzp23dwlo9j3|ke654r0kkgjo|1727609907480|\n",
                            "|wzy4n2xov5z5|vjrkk2lv04zk|1706634689502|\n",
                            "+------------+------------+-------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "wallapop.withColumn(\"data\", f.explode(\"data.section.payload.items\")).select(\n",
                "    \"data.id\", \"data.user_id\", \"data.created_at\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fenomenal. Ahora, siguiendo esta misma operación, obtendremos un dataset completo tabular de los campos del JSON más relevantes. Observemos que para todos los campos seleccionados, se hace una conversión de tipos (método `cast`) y se asigna un alias (método `alias`). Esto es para que la tabla resultante sea consistente, y tenga siempre el mismo esquema de salida.\n",
                "\n",
                "Notemos también que a campos que representan fechas pero se muestran como números enteros (milisegundos desde 1970, esto se conoce como UNIX time), como `created_at` o `modified_at`, les aplicamos una conversión mediante la función `from_unixtime` para representarlos como una fecha legible"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- id: string (nullable = true)\n",
                        " |-- title: string (nullable = true)\n",
                        " |-- user_id: string (nullable = true)\n",
                        " |-- category_id: integer (nullable = true)\n",
                        " |-- created_at: timestamp (nullable = true)\n",
                        " |-- modified_at: timestamp (nullable = true)\n",
                        " |-- description: string (nullable = true)\n",
                        " |-- favorited: boolean (nullable = true)\n",
                        " |-- is_favoriteable: boolean (nullable = true)\n",
                        " |-- is_refurbished: boolean (nullable = true)\n",
                        " |-- latitude: double (nullable = true)\n",
                        " |-- longitude: double (nullable = true)\n",
                        " |-- postal_code: string (nullable = true)\n",
                        " |-- city: string (nullable = true)\n",
                        " |-- region: string (nullable = true)\n",
                        " |-- region2: string (nullable = true)\n",
                        " |-- country_code: string (nullable = true)\n",
                        " |-- amount: double (nullable = true)\n",
                        " |-- currency: string (nullable = true)\n",
                        " |-- reserved: string (nullable = true)\n",
                        " |-- item_is_shippable: boolean (nullable = true)\n",
                        " |-- user_allows_shipping: boolean (nullable = true)\n",
                        " |-- __timestamp: timestamp (nullable = false)\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>id</th><th>title</th><th>user_id</th><th>category_id</th><th>created_at</th><th>modified_at</th><th>description</th><th>favorited</th><th>is_favoriteable</th><th>is_refurbished</th><th>latitude</th><th>longitude</th><th>postal_code</th><th>city</th><th>region</th><th>region2</th><th>country_code</th><th>amount</th><th>currency</th><th>reserved</th><th>item_is_shippable</th><th>user_allows_shipping</th><th>__timestamp</th></tr>\n",
                            "<tr><td>wzy4vyvp3vz5</td><td>Funda Portatil</td><td>p8j35wm4v7z9</td><td>24200</td><td>2024-09-29 14:57:15</td><td>2024-09-29 14:57:26</td><td>&iquest;HAS VUELTO AL INSTITUTO O AL TRABAJO?\\nPues por aqui te dejo una funda perfecta para lo que nece...</td><td>false</td><td>true</td><td>false</td><td>40.42023478019115</td><td>-3.708753774008156</td><td>28001</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>10.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>nz04xroorrjo</td><td>Portatil Android</td><td>xpzp19l94mz3</td><td>24200</td><td>2024-09-29 16:56:24</td><td>2024-09-29 16:56:34</td><td>Portatil Android AIRIS KIRA N10040 en excelente estado excepto la bateria que dura muy poco.\\nEl ...</td><td>false</td><td>true</td><td>false</td><td>40.319447010985634</td><td>-3.7849696841867604</td><td>28913</td><td>Legan&eacute;s</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>15.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>p614153vn265</td><td>Portatil Compaq</td><td>kp618yw82dz5</td><td>24200</td><td>2024-09-29 16:39:13</td><td>2024-09-29 16:40:18</td><td>Portatil Compaq con windows 10 HOME.\\n\\nEspecificaciones: (ultima foto)\\n\\nVendo porque he actual...</td><td>false</td><td>true</td><td>false</td><td>40.48015422451968</td><td>-3.363764940208042</td><td>28807</td><td>Alcal&aacute; de Henares</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>90.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>3zl8x0n02p6x</td><td>Portatil</td><td>7v6g14w1gn6e</td><td>24200</td><td>2024-09-29 13:21:54</td><td>2024-09-29 13:22:04</td><td>portatil huawei d15\\nse a muerto placa base \\nse puede cambiar placa base y esta nuevo o para piezas</td><td>false</td><td>true</td><td>false</td><td>40.382014</td><td>-3.6199315</td><td>28031</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>150.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>mzn2mwqnd7zn</td><td>Portatil Samsung</td><td>kp618yw82dz5</td><td>24200</td><td>2024-09-29 16:31:51</td><td>2024-09-29 16:34:09</td><td>Portatil Samsung con Windows 10 PRO.\\n\\nEspecificaciones: (Ultima foto)\\n\\nVendo porque he compra...</td><td>false</td><td>true</td><td>false</td><td>40.48015422451968</td><td>-3.363764940208042</td><td>28807</td><td>Alcal&aacute; de Henares</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>100.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>pj9mqn0e4o6e</td><td>Port&aacute;til HP</td><td>wzvy25d3w4zl</td><td>24200</td><td>2024-09-29 15:23:07</td><td>2024-09-29 15:23:18</td><td>Port&aacute;til HP                                                      -Intel core i3                  ...</td><td>false</td><td>true</td><td>false</td><td>40.410466731190766</td><td>-3.712916009451285</td><td>28070</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>150.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>0j24kno1pezy</td><td>port&aacute;til apple</td><td>pj9ynq345k6e</td><td>24200</td><td>2024-09-29 15:19:48</td><td>2024-09-29 15:40:57</td><td>el port&aacute;til va perfectamente conectado a cargador. el cargador no le tengo se me perdi&oacute; para piez...</td><td>false</td><td>true</td><td>false</td><td>40.420906205278264</td><td>-3.7114915849860446</td><td>28070</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>50.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>vjrqv4mywlzk</td><td>Lote de portatiles</td><td>wzynrx809ej5</td><td>24200</td><td>2024-09-29 15:08:20</td><td>2024-09-29 15:08:30</td><td>lote de portatiles 30&euro; </td><td>false</td><td>true</td><td>false</td><td>40.37823562958887</td><td>-3.6226439521442733</td><td>28018</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>30.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>mzn2mwm912zn</td><td>Port&aacute;til Hp</td><td>8ejk8lrevpjx</td><td>24200</td><td>2024-09-29 15:06:40</td><td>2024-09-29 17:39:24</td><td>HP 15 ( Rt26ns) Windows 10 pro original, Disco solido Samsung 870 Evo 500GB reci&eacute;n cambiado, 12 G...</td><td>false</td><td>true</td><td>false</td><td>40.44739646310844</td><td>-3.608178209507684</td><td>28022</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>120.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>nzx4vrg58ej2</td><td>Ordenado portatil </td><td>nz0my851yejo</td><td>24200</td><td>2024-09-29 15:10:55</td><td>2024-09-29 15:11:06</td><td>Se vende Ordenador portatil Acer Aspire 6930.Con Windows 10 pro, 4G de ram, 2 disco duro de 250G ...</td><td>false</td><td>true</td><td>false</td><td>40.464718293586465</td><td>-3.4473387203610137</td><td>28851</td><td>Mercado Parque Corredor del Henares</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>150.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>v6ggnoww156e</td><td>Cargador ordenador portatil</td><td>kp61om83g7j5</td><td>24200</td><td>2024-09-29 17:56:24</td><td>2024-09-29 17:56:34</td><td>cable cargador de portatil indicaciones en la foto</td><td>false</td><td>true</td><td>false</td><td>40.36390161000174</td><td>-3.7087916765194797</td><td>28041</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>15.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>8z8k95n8v8z3</td><td>Soporte para port&aacute;til KESINGTON</td><td>p8j3r9n3xyj9</td><td>24200</td><td>2024-09-29 16:44:00</td><td>2024-09-29 16:45:12</td><td>SOPORTE REPLICADOR PUERTOS EXPANSION DOCK KENSINGTON 1500325A\\n\\nSoporte para port&aacute;til marca KESI...</td><td>false</td><td>true</td><td>false</td><td>40.412101277512114</td><td>-3.693854082774088</td><td>28009</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>39.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>0j24kn83xrzy</td><td>Portatil</td><td>nzx5rg01n762</td><td>24200</td><td>2024-09-29 12:00:56</td><td>2024-09-29 12:01:06</td><td>ordenador como nuevo no se a usado mucho lo unico que hay que tenerlo con el cable y viene con la...</td><td>false</td><td>true</td><td>false</td><td>40.19496873349664</td><td>-3.695411005478355</td><td>28342</td><td>Valdemoro</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>90.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>wzv4v2pr07zl</td><td>Vendo port&aacute;til 15&quot;</td><td>vjrd45k21l6k</td><td>24200</td><td>2024-09-29 17:36:51</td><td>2024-09-29 17:37:01</td><td>Funda de camuflaje de carbono para ordenador port&aacute;til. </td><td>false</td><td>true</td><td>false</td><td>40.40079034540403</td><td>-4.002430292964215</td><td>28690</td><td>Brunete</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>5.0</td><td>EUR</td><td>false</td><td>true</td><td>false</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>qzme17xn7ljv</td><td>Ziu. Altavoz portatil. </td><td>lqzm42koegzv</td><td>24200</td><td>2024-09-29 16:50:26</td><td>2024-09-29 16:50:36</td><td>Nuevo. Tama&ntilde;o 10x 5x 3 aproximadamente</td><td>false</td><td>true</td><td>false</td><td>40.5060876</td><td>-3.6688537</td><td>28050</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>4.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>v6ggnovny76e</td><td>Portatil dell</td><td>v9jdxk7mq4zk</td><td>24200</td><td>2024-09-29 14:23:16</td><td>2024-09-29 14:23:26</td><td>portatil dell vostro 15 3568. 4 Gb de RAM Y 1T de disco ssdd en buen estado, sin ara&ntilde;azos. </td><td>false</td><td>true</td><td>false</td><td>40.078032176289184</td><td>-3.745563890320141</td><td>45222</td><td>Borox</td><td>Castilla-La Mancha</td><td>Toledo</td><td>ES</td><td>180.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>8z8k98l90lz3</td><td>Monitor port&aacute;til </td><td>436ed7nn7kjd</td><td>24200</td><td>2024-09-28 18:15:13</td><td>2024-09-28 18:15:53</td><td>..</td><td>false</td><td>true</td><td>false</td><td>40.70957125584157</td><td>-3.134800389551024</td><td>19198</td><td>T&oacute;rtola de Henares</td><td>Castilla-La Mancha</td><td>Guadalajara</td><td>ES</td><td>75.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>36e1g844y8jd</td><td>Soporte port&aacute;til, tablet</td><td>08z85ydyrrz3</td><td>24200</td><td>2024-09-29 16:57:02</td><td>2024-09-29 16:57:12</td><td>Soporte para tablet o port&aacute;til.</td><td>false</td><td>true</td><td>false</td><td>40.95929031163188</td><td>-4.075683928670772</td><td>40197</td><td>San Crist&oacute;bal de Segovia</td><td>Castilla y Le&oacute;n</td><td>Segovia</td><td>ES</td><td>3.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>pzp23dwlo9j3</td><td>mochila para llevar el portatil</td><td>ke654r0kkgjo</td><td>24200</td><td>2024-09-29 13:38:27</td><td>2024-09-29 13:38:37</td><td>grande \\ncon bastantes compartimentos</td><td>false</td><td>true</td><td>false</td><td>40.430215922470055</td><td>-3.5467938692864847</td><td>28822</td><td>Coslada</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>7.5</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "<tr><td>wzy4n2xov5z5</td><td>Portatil Lenovo </td><td>vjrkk2lv04zk</td><td>24200</td><td>2024-01-30 18:11:29</td><td>2024-09-28 14:26:59</td><td>Vendo port&aacute;til Lenovo IdeaPad 3 en muy buen estado. El port&aacute;til tiene un procesador AMD Ryzen 7, ...</td><td>false</td><td>true</td><td>false</td><td>40.42189783312117</td><td>-3.705112155540614</td><td>28070</td><td>Madrid</td><td>Comunidad de Madrid</td><td>Madrid</td><td>ES</td><td>700.0</td><td>EUR</td><td>false</td><td>true</td><td>true</td><td>2024-09-29 17:59:40.825664</td></tr>\n",
                            "</table>\n",
                            "only showing top 20 rows\n"
                        ],
                        "text/plain": [
                            "+------------+-------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------------------------+-------------------+-----------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "|          id|                          title|     user_id|category_id|         created_at|        modified_at|                                                                                         description|favorited|is_favoriteable|is_refurbished|          latitude|          longitude|postal_code|                               city|             region|    region2|country_code|amount|currency|reserved|item_is_shippable|user_allows_shipping|               __timestamp|\n",
                            "+------------+-------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------------------------+-------------------+-----------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "|wzy4vyvp3vz5|                 Funda Portatil|p8j35wm4v7z9|      24200|2024-09-29 14:57:15|2024-09-29 14:57:26|¿HAS VUELTO AL INSTITUTO O AL TRABAJO?\\nPues por aqui te dejo una funda perfecta para lo que nece...|    false|           true|         false| 40.42023478019115| -3.708753774008156|      28001|                             Madrid|Comunidad de Madrid|     Madrid|          ES|  10.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|nz04xroorrjo|               Portatil Android|xpzp19l94mz3|      24200|2024-09-29 16:56:24|2024-09-29 16:56:34|Portatil Android AIRIS KIRA N10040 en excelente estado excepto la bateria que dura muy poco.\\nEl ...|    false|           true|         false|40.319447010985634|-3.7849696841867604|      28913|                            Leganés|Comunidad de Madrid|     Madrid|          ES|  15.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|p614153vn265|                Portatil Compaq|kp618yw82dz5|      24200|2024-09-29 16:39:13|2024-09-29 16:40:18|Portatil Compaq con windows 10 HOME.\\n\\nEspecificaciones: (ultima foto)\\n\\nVendo porque he actual...|    false|           true|         false| 40.48015422451968| -3.363764940208042|      28807|                  Alcalá de Henares|Comunidad de Madrid|     Madrid|          ES|  90.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|3zl8x0n02p6x|                       Portatil|7v6g14w1gn6e|      24200|2024-09-29 13:21:54|2024-09-29 13:22:04|portatil huawei d15\\nse a muerto placa base \\nse puede cambiar placa base y esta nuevo o para piezas|    false|           true|         false|         40.382014|         -3.6199315|      28031|                             Madrid|Comunidad de Madrid|     Madrid|          ES| 150.0|     EUR|   false|             true|               false|2024-09-29 17:59:40.514766|\n",
                            "|mzn2mwqnd7zn|               Portatil Samsung|kp618yw82dz5|      24200|2024-09-29 16:31:51|2024-09-29 16:34:09|Portatil Samsung con Windows 10 PRO.\\n\\nEspecificaciones: (Ultima foto)\\n\\nVendo porque he compra...|    false|           true|         false| 40.48015422451968| -3.363764940208042|      28807|                  Alcalá de Henares|Comunidad de Madrid|     Madrid|          ES| 100.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|pj9mqn0e4o6e|                    Portátil HP|wzvy25d3w4zl|      24200|2024-09-29 15:23:07|2024-09-29 15:23:18|Portátil HP                                                      -Intel core i3                  ...|    false|           true|         false|40.410466731190766| -3.712916009451285|      28070|                             Madrid|Comunidad de Madrid|     Madrid|          ES| 150.0|     EUR|   false|             true|               false|2024-09-29 17:59:40.514766|\n",
                            "|0j24kno1pezy|                 portátil apple|pj9ynq345k6e|      24200|2024-09-29 15:19:48|2024-09-29 15:40:57|el portátil va perfectamente conectado a cargador. el cargador no le tengo se me perdió para piez...|    false|           true|         false|40.420906205278264|-3.7114915849860446|      28070|                             Madrid|Comunidad de Madrid|     Madrid|          ES|  50.0|     EUR|   false|             true|               false|2024-09-29 17:59:40.514766|\n",
                            "|vjrqv4mywlzk|             Lote de portatiles|wzynrx809ej5|      24200|2024-09-29 15:08:20|2024-09-29 15:08:30|                                                                             lote de portatiles 30€ |    false|           true|         false| 40.37823562958887|-3.6226439521442733|      28018|                             Madrid|Comunidad de Madrid|     Madrid|          ES|  30.0|     EUR|   false|             true|               false|2024-09-29 17:59:40.514766|\n",
                            "|mzn2mwm912zn|                    Portátil Hp|8ejk8lrevpjx|      24200|2024-09-29 15:06:40|2024-09-29 17:39:24|HP 15 ( Rt26ns) Windows 10 pro original, Disco solido Samsung 870 Evo 500GB recién cambiado, 12 G...|    false|           true|         false| 40.44739646310844| -3.608178209507684|      28022|                             Madrid|Comunidad de Madrid|     Madrid|          ES| 120.0|     EUR|   false|             true|               false|2024-09-29 17:59:40.514766|\n",
                            "|nzx4vrg58ej2|             Ordenado portatil |nz0my851yejo|      24200|2024-09-29 15:10:55|2024-09-29 15:11:06|Se vende Ordenador portatil Acer Aspire 6930.Con Windows 10 pro, 4G de ram, 2 disco duro de 250G ...|    false|           true|         false|40.464718293586465|-3.4473387203610137|      28851|Mercado Parque Corredor del Henares|Comunidad de Madrid|     Madrid|          ES| 150.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|v6ggnoww156e|    Cargador ordenador portatil|kp61om83g7j5|      24200|2024-09-29 17:56:24|2024-09-29 17:56:34|                                                  cable cargador de portatil indicaciones en la foto|    false|           true|         false| 40.36390161000174|-3.7087916765194797|      28041|                             Madrid|Comunidad de Madrid|     Madrid|          ES|  15.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|8z8k95n8v8z3|Soporte para portátil KESINGTON|p8j3r9n3xyj9|      24200|2024-09-29 16:44:00|2024-09-29 16:45:12|SOPORTE REPLICADOR PUERTOS EXPANSION DOCK KENSINGTON 1500325A\\n\\nSoporte para portátil marca KESI...|    false|           true|         false|40.412101277512114| -3.693854082774088|      28009|                             Madrid|Comunidad de Madrid|     Madrid|          ES|  39.0|     EUR|   false|             true|               false|2024-09-29 17:59:40.514766|\n",
                            "|0j24kn83xrzy|                       Portatil|nzx5rg01n762|      24200|2024-09-29 12:00:56|2024-09-29 12:01:06|ordenador como nuevo no se a usado mucho lo unico que hay que tenerlo con el cable y viene con la...|    false|           true|         false| 40.19496873349664| -3.695411005478355|      28342|                          Valdemoro|Comunidad de Madrid|     Madrid|          ES|  90.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|wzv4v2pr07zl|             Vendo portátil 15\"|vjrd45k21l6k|      24200|2024-09-29 17:36:51|2024-09-29 17:37:01|                                             Funda de camuflaje de carbono para ordenador portátil. |    false|           true|         false| 40.40079034540403| -4.002430292964215|      28690|                            Brunete|Comunidad de Madrid|     Madrid|          ES|   5.0|     EUR|   false|             true|               false|2024-09-29 17:59:40.514766|\n",
                            "|qzme17xn7ljv|        Ziu. Altavoz portatil. |lqzm42koegzv|      24200|2024-09-29 16:50:26|2024-09-29 16:50:36|                                                              Nuevo. Tamaño 10x 5x 3 aproximadamente|    false|           true|         false|        40.5060876|         -3.6688537|      28050|                             Madrid|Comunidad de Madrid|     Madrid|          ES|   4.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|v6ggnovny76e|                  Portatil dell|v9jdxk7mq4zk|      24200|2024-09-29 14:23:16|2024-09-29 14:23:26|         portatil dell vostro 15 3568. 4 Gb de RAM Y 1T de disco ssdd en buen estado, sin arañazos. |    false|           true|         false|40.078032176289184| -3.745563890320141|      45222|                              Borox| Castilla-La Mancha|     Toledo|          ES| 180.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|8z8k98l90lz3|              Monitor portátil |436ed7nn7kjd|      24200|2024-09-28 18:15:13|2024-09-28 18:15:53|                                                                                                  ..|    false|           true|         false| 40.70957125584157| -3.134800389551024|      19198|                 Tórtola de Henares| Castilla-La Mancha|Guadalajara|          ES|  75.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|36e1g844y8jd|       Soporte portátil, tablet|08z85ydyrrz3|      24200|2024-09-29 16:57:02|2024-09-29 16:57:12|                                                                     Soporte para tablet o portátil.|    false|           true|         false| 40.95929031163188| -4.075683928670772|      40197|           San Cristóbal de Segovia|    Castilla y León|    Segovia|          ES|   3.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|pzp23dwlo9j3|mochila para llevar el portatil|ke654r0kkgjo|      24200|2024-09-29 13:38:27|2024-09-29 13:38:37|                                                               grande \\ncon bastantes compartimentos|    false|           true|         false|40.430215922470055|-3.5467938692864847|      28822|                            Coslada|Comunidad de Madrid|     Madrid|          ES|   7.5|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "|wzy4n2xov5z5|               Portatil Lenovo |vjrkk2lv04zk|      24200|2024-01-30 18:11:29|2024-09-28 14:26:59|Vendo portátil Lenovo IdeaPad 3 en muy buen estado. El portátil tiene un procesador AMD Ryzen 7, ...|    false|           true|         false| 40.42189783312117| -3.705112155540614|      28070|                             Madrid|Comunidad de Madrid|     Madrid|          ES| 700.0|     EUR|   false|             true|                true|2024-09-29 17:59:40.514766|\n",
                            "+------------+-------------------------------+------------+-----------+-------------------+-------------------+----------------------------------------------------------------------------------------------------+---------+---------------+--------------+------------------+-------------------+-----------+-----------------------------------+-------------------+-----------+------------+------+--------+--------+-----------------+--------------------+--------------------------+\n",
                            "only showing top 20 rows"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "wallapop = (\n",
                "    spark.read.json(\"data/wallapop.json\", multiLine=True, primitivesAsString=True)\n",
                "    .withColumn(\"data\", f.explode(\"data.section.payload.items\"))\n",
                "    .select(\n",
                "        f.col(\"data.id\").cast(\"string\").alias(\"id\"),\n",
                "        f.col(\"data.title\").cast(\"string\").alias(\"title\"),\n",
                "        f.col(\"data.user_id\").cast(\"string\").alias(\"user_id\"),\n",
                "        f.col(\"data.category_id\").cast(\"int\").alias(\"category_id\"),\n",
                "        f.from_unixtime((f.col(\"data.created_at\") / 1000))\n",
                "        .cast(\"timestamp\")\n",
                "        .alias(\"created_at\"),\n",
                "        f.from_unixtime(f.col(\"data.modified_at\") / 1000)\n",
                "        .cast(\"timestamp\")\n",
                "        .alias(\"modified_at\"),\n",
                "        f.col(\"data.description\").cast(\"string\").alias(\"description\"),\n",
                "        f.col(\"data.favorited.flag\").cast(\"boolean\").alias(\"favorited\"),\n",
                "        f.col(\"data.is_favoriteable.flag\").cast(\"boolean\").alias(\"is_favoriteable\"),\n",
                "        f.col(\"data.is_refurbished.flag\").cast(\"boolean\").alias(\"is_refurbished\"),\n",
                "        f.col(\"data.location.latitude\").cast(\"double\").alias(\"latitude\"),\n",
                "        f.col(\"data.location.longitude\").cast(\"double\").alias(\"longitude\"),\n",
                "        f.col(\"data.location.postal_code\").cast(\"string\").alias(\"postal_code\"),\n",
                "        f.col(\"data.location.city\").cast(\"string\").alias(\"city\"),\n",
                "        f.col(\"data.location.region\").cast(\"string\").alias(\"region\"),\n",
                "        f.col(\"data.location.region2\").cast(\"string\").alias(\"region2\"),\n",
                "        f.col(\"data.location.country_code\").cast(\"string\").alias(\"country_code\"),\n",
                "        f.col(\"data.price.amount\").cast(\"double\").alias(\"amount\"),\n",
                "        f.col(\"data.price.currency\").cast(\"string\").alias(\"currency\"),\n",
                "        f.col(\"data.reserved.flag\").alias(\"reserved\"),\n",
                "        f.col(\"data.shipping.item_is_shippable\")\n",
                "        .cast(\"boolean\")\n",
                "        .alias(\"item_is_shippable\"),\n",
                "        f.col(\"data.shipping.user_allows_shipping\")\n",
                "        .cast(\"boolean\")\n",
                "        .alias(\"user_allows_shipping\"),\n",
                "        f.current_timestamp().alias(\"__timestamp\"),\n",
                "    )\n",
                ")\n",
                "wallapop.printSchema()\n",
                "display(wallapop)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Genial, ya hemos leído y transformado nuestro set de datos inicialmente desestructurado en una tabla bien estructurada, con unos campos y tipos fijados.\n",
                "\n",
                "Ahora, para completar la ETL, almacenaremos esta tabla en el catálogo de datos de Spark. En este caso, al estar trabajando de manera local, dicho catálogo de datos estará localizado en esta misma ruta (`metastore_db/`, `spark-warehouse/`, `derby.log`), sin embargo, cuando trabajemos en un entorno corporativo, habitualmente el catálogo de datos se alojará en una arquitectura cloud, como AWS, Azure, GCP, Databricks, etc.\n",
                "\n",
                "Aunque no es necesario, es una buena práctica crear en primera instancia la tabla Delta sobre la que escribiremos nuestro dataset, con un schema concreto, metadatos, etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/09/29 17:59:41 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
                        "24/09/29 17:59:41 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
                        "24/09/29 17:59:43 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
                        "24/09/29 17:59:43 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore dadiego@127.0.1.1\n",
                        "24/09/29 17:59:43 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
                        "24/09/29 17:59:44 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`default`.`wallapop` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
                        "24/09/29 17:59:44 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
                        "24/09/29 17:59:45 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
                        "24/09/29 17:59:45 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
                        "24/09/29 17:59:45 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
                    ]
                }
            ],
            "source": [
                "dt = (\n",
                "    DeltaTable.createIfNotExists(spark)\n",
                "    .addColumns(wallapop.schema)\n",
                "    .tableName(\"wallapop\")\n",
                "    .comment(\"Tabla de productos de Wallapop\")\n",
                "    .execute()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Con el método `createIfNotExists` estamos indicando que cree únicamente la tabla en el catálogo de datos si esta no existía previamente.\n",
                "\n",
                "Una vez creada la tabla, insertaremos los datos de nuestro DataFrame mediante una operación `merge`. Para ello, identificamos en primer lugar cuáles son los campos que consituyen una clave primaria en la tabla, es decir, un identificador único de cada registro. En este caso, podríamos utilizar por ejemplo la combinación `\"id\"`, `\"user_id\"`; cuando estos campos coincidan entre la tabla fuente y la tabla destino, actualizaremos los registros en el destino, y cuando no coincidan, insertaremos los registros de la fuente en el destino. Esto lo podemos hacer utilizando los métodos del objeto `DeltaTable` dentro de la librería externa `delta-spark` que tenemos instalada en nuestro entorno virtual de Python."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/09/29 17:59:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
                        "                                                                                \r"
                    ]
                }
            ],
            "source": [
                "(\n",
                "    dt.alias(\"target\")\n",
                "    .merge(\n",
                "        wallapop.alias(\"source\"),\n",
                "        \"source.id = target.id AND source.user_id = target.user_id\",\n",
                "    )\n",
                "    .whenMatchedUpdateAll()\n",
                "    .whenNotMatchedInsertAll()\n",
                "    .execute()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ya hemos creado la tabla delta y hemos insertado los registros tabulados de la API de Wallapop en la misma. Ahora podemos consultar el catálogo mediante SQL.\n",
                "\n",
                "Primero, utilizaremos una función auxiliar de nuestro propio paquete de Python creado (`blackops`), llamada `get_detailed_tables_info`, para obtener información detallada de todas las tablas de nuestro catálogo de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/09/29 17:59:49 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>namespace</th><th>tableName</th><th></th><th>Catalog</th><th>Comment</th><th>Created By</th><th>Created Time</th><th>Database</th><th>InputFormat</th><th>Last Access</th><th>Location</th><th>OutputFormat</th><th>Owner</th><th>Partition Provider</th><th>Provider</th><th>Serde Library</th><th>Table</th><th>Type</th></tr>\n",
                            "<tr><td></td><td>empleados</td><td></td><td>NULL</td><td>NULL</td><td>Spark </td><td>Sun Sep 29 17:59:25 CEST 2024</td><td>NULL</td><td>NULL</td><td>UNKNOWN</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>empleados</td><td>VIEW</td></tr>\n",
                            "<tr><td>default</td><td>wallapop</td><td></td><td>spark_catalog</td><td>Tabla de productos de Wallapop</td><td>Spark 3.5.3</td><td>Sun Sep 29 17:59:45 CEST 2024</td><td>default</td><td>org.apache.hadoop.mapred.SequenceFileInputFormat</td><td>UNKNOWN</td><td>file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...</td><td>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td><td>dadiego</td><td>Catalog</td><td>delta</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td><td>wallapop</td><td>MANAGED</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+\n",
                            "|namespace|tableName|   |      Catalog|                       Comment| Created By|                 Created Time|Database|                                     InputFormat|Last Access|                                                                                            Location|                                             OutputFormat|  Owner|Partition Provider|Provider|                                     Serde Library|    Table|   Type|\n",
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+\n",
                            "|         |empleados|   |         NULL|                          NULL|     Spark |Sun Sep 29 17:59:25 CEST 2024|    NULL|                                            NULL|    UNKNOWN|                                                                                                NULL|                                                     NULL|   NULL|              NULL|    NULL|                                              NULL|empleados|   VIEW|\n",
                            "|  default| wallapop|   |spark_catalog|Tabla de productos de Wallapop|Spark 3.5.3|Sun Sep 29 17:59:45 CEST 2024| default|org.apache.hadoop.mapred.SequenceFileInputFormat|    UNKNOWN|file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...|org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat|dadiego|           Catalog|   delta|org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe| wallapop|MANAGED|\n",
                            "+---------+---------+---+-------------+------------------------------+-----------+-----------------------------+--------+------------------------------------------------+-----------+----------------------------------------------------------------------------------------------------+---------------------------------------------------------+-------+------------------+--------+--------------------------------------------------+---------+-------+"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "get_detailed_tables_info(spark)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos obtener información concreta de nuestra tabla recién creada, `wallapop`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th></tr>\n",
                            "<tr><td>delta</td><td>1215d8e6-5910-434c-979b-b9fd6d883f99</td><td>spark_catalog.default.wallapop</td><td>Tabla de productos de Wallapop</td><td>file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...</td><td>2024-09-29 17:59:43.896</td><td>2024-09-29 17:59:49.228</td><td>[]</td><td>[]</td><td>1</td><td>15467</td><td>{}</td><td>1</td><td>2</td><td>[appendOnly, invariants]</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
                            "|format|                                  id|                          name|                   description|                                                                                            location|              createdAt|           lastModified|partitionColumns|clusteringColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|           tableFeatures|\n",
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
                            "| delta|1215d8e6-5910-434c-979b-b9fd6d883f99|spark_catalog.default.wallapop|Tabla de productos de Wallapop|file:/home/dadiego/projects/ESIC/esic-bigdata-iv-blackops/notebooks/tema-2-etl/spark-warehouse/wa...|2024-09-29 17:59:43.896|2024-09-29 17:59:49.228|              []|               []|       1|      15467|        {}|               1|               2|[appendOnly, invariants]|\n",
                            "+------+------------------------------------+------------------------------+------------------------------+----------------------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dt.detail()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "También podemos obtener una traza histórica de las veces que esta tabla se ha modificado, lo cual es enormemente útil de cara a disponer de un gobierno del dato escalable y robusto"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr>\n",
                            "<tr><td>1</td><td>2024-09-29 17:59:49.228</td><td>NULL</td><td>NULL</td><td>MERGE</td><td>{predicate -&gt; [&quot;((id#906 = id#1212) AND (user_id#908 = user_id#1214))&quot;], matchedPredicates -&gt; [{&quot;...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>0</td><td>Serializable</td><td>false</td><td>{numTargetRowsCopied -&gt; 0, numTargetRowsDeleted -&gt; 0, numTargetFilesAdded -&gt; 1, numTargetBytesAdd...</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.0</td></tr>\n",
                            "<tr><td>0</td><td>2024-09-29 17:59:44.065</td><td>NULL</td><td>NULL</td><td>CREATE TABLE</td><td>{partitionBy -&gt; [], clusterBy -&gt; [], description -&gt; Tabla de productos de Wallapop, isManaged -&gt; ...</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>Serializable</td><td>true</td><td>{}</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.0</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
                            "|version|              timestamp|userId|userName|   operation|                                                                                 operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                    operationMetrics|userMetadata|                         engineInfo|\n",
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
                            "|      1|2024-09-29 17:59:49.228|  NULL|    NULL|       MERGE|{predicate -> [\"((id#906 = id#1212) AND (user_id#908 = user_id#1214))\"], matchedPredicates -> [{\"...|NULL|    NULL|     NULL|          0|  Serializable|        false|{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdd...|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.0|\n",
                            "|      0|2024-09-29 17:59:44.065|  NULL|    NULL|CREATE TABLE|{partitionBy -> [], clusterBy -> [], description -> Tabla de productos de Wallapop, isManaged -> ...|NULL|    NULL|     NULL|       NULL|  Serializable|         true|                                                                                                  {}|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.0|\n",
                            "+-------+-----------------------+------+--------+------------+----------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dt.history()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vemos como en el histórico aparecen las dos operaciones que hemos ejecutado sobre esta tabla Delta: la operación de creación de la tabla, y la operación de merge para insertar los nuevos datos.\n",
                "\n",
                "Podemos también ejecutar cualquier operación SQL con esta tabla del catálogo. Por ejemplo, veamos una tabla resumen de cuántos productos existen por comunidad y código postal, ordenada de mayor a menor cantidad de productos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table border='1'>\n",
                            "<tr><th>region</th><th>postal_code</th><th>n_products</th></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28070</td><td>5</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28980</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28001</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28807</td><td>2</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28822</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28041</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28043</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28700</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28342</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28924</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28230</td><td>1</td></tr>\n",
                            "<tr><td>Castilla y Le&oacute;n</td><td>40197</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28033</td><td>1</td></tr>\n",
                            "<tr><td>Comunidad de Madrid</td><td>28009</td><td>1</td></tr>\n",
                            "<tr><td>Castilla-La Mancha</td><td>19198</td><td>1</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "+-------------------+-----------+----------+\n",
                            "|             region|postal_code|n_products|\n",
                            "+-------------------+-----------+----------+\n",
                            "|Comunidad de Madrid|      28070|         5|\n",
                            "|Comunidad de Madrid|      28980|         2|\n",
                            "|Comunidad de Madrid|      28001|         2|\n",
                            "|Comunidad de Madrid|      28807|         2|\n",
                            "|Comunidad de Madrid|      28822|         1|\n",
                            "|Comunidad de Madrid|      28041|         1|\n",
                            "|Comunidad de Madrid|      28043|         1|\n",
                            "|Comunidad de Madrid|      28700|         1|\n",
                            "|Comunidad de Madrid|      28342|         1|\n",
                            "|Comunidad de Madrid|      28924|         1|\n",
                            "|Comunidad de Madrid|      28230|         1|\n",
                            "|    Castilla y León|      40197|         1|\n",
                            "|Comunidad de Madrid|      28033|         1|\n",
                            "|Comunidad de Madrid|      28009|         1|\n",
                            "| Castilla-La Mancha|      19198|         1|\n",
                            "+-------------------+-----------+----------+"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "spark.sql(\n",
                "    \"select region, postal_code, count(*) as n_products from wallapop group by region, postal_code order by n_products desc limit 15\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
